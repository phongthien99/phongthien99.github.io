---
title: "A Practical Guide to Avro and Schema Registry in Kafka"
date: "2025-09-14T00:00:00Z"
draft: false
tags:
  - kafka
  - avro
  - schema-registry
categories:
  - Tutorial
author: "phongthien"
---

# A Practical Guide to Avro and Schema Registry in Kafka

## 1. Äáº·t váº¥n Ä‘á»

Trong há»‡ thá»‘ng **event streaming** vá»›i Kafka, dá»¯ liá»‡u Ä‘Æ°á»£c truyá»n dÆ°á»›i dáº¡ng message giá»¯a producer vÃ  consumer. Má»™t váº¥n Ä‘á» lá»›n xuáº¥t hiá»‡n khi **dá»¯ liá»‡u thay Ä‘á»•i cáº¥u trÃºc (schema evolution)**:

- Producer thÃªm/bá»›t field trong message.
- Consumer cÅ© chÆ°a Ä‘Æ°á»£c nÃ¢ng cáº¥p ká»‹p thá»i.
- Nguy cÆ¡ consumer khÃ´ng Ä‘á»c Ä‘Æ°á»£c dá»¯ liá»‡u, gÃ¢y lá»—i toÃ n há»‡ thá»‘ng.

VÃ­ dá»¥: Producer ban Ä‘áº§u gá»­i `{id, name}`, sau Ä‘Ã³ nÃ¢ng cáº¥p thÃªm `email`. Náº¿u consumer chÆ°a biáº¿t field má»›i thÃ¬ pháº£i lÃ m sao?


## 2. CÃ¡ch giáº£i quyáº¿t

### 2.1. Avro lÃ  gÃ¬?

**Apache Avro** lÃ  má»™t **serialization framework** mÃ£ nguá»“n má»Ÿ, tá»‘i Æ°u cho viá»‡c lÆ°u trá»¯ vÃ  truyá»n táº£i dá»¯ liá»‡u:

- **Dá»±a trÃªn schema**: Ä‘á»‹nh nghÄ©a báº±ng JSON.
- **Hiá»‡u nÄƒng cao**: nhá»‹ phÃ¢n, nhá» gá»n hÆ¡n JSON/XML.
- **Äa ngÃ´n ngá»¯**: sinh code cho Java, Go, Python, C#â€¦
- **Há»— trá»£ schema evolution**: thÃªm/bá»›t field váº«n Ä‘á»c Ä‘Æ°á»£c dá»¯ liá»‡u cÅ© náº¿u cÃ³ `default`.

VÃ­ dá»¥ schema Avro:

```json
{
  "type": "record",
  "name": "User",
  "fields": [
    {"name": "id", "type": "int"},
    {"name": "name", "type": "string"},
    {"name": "email", "type": ["null","string"], "default": null}
  ]
}

```

### 2.2. Lá»£i Ã­ch khi sá»­ dá»¥ng Avro trong Kafka

- **Hiá»‡u nÄƒng & tiáº¿t kiá»‡m**: dá»¯ liá»‡u nhá»‹ phÃ¢n gá»n nháº¹, giáº£m chi phÃ­ lÆ°u trá»¯ vÃ  bÄƒng thÃ´ng.
- **Äáº£m báº£o tÃ­nh nháº¥t quÃ¡n**: táº¥t cáº£ dá»¯ liá»‡u Ä‘á»u theo schema Ä‘Ã£ Ä‘á»‹nh nghÄ©a.
- **Há»— trá»£ nÃ¢ng cáº¥p linh hoáº¡t**: dá»… dÃ ng thÃªm/bá»›t field mÃ  khÃ´ng phÃ¡ vá»¡ há»‡ thá»‘ng.
- **NgÃ´n ngá»¯ trung láº­p**: dá»… dÃ ng tÃ­ch há»£p microservices viáº¿t báº±ng nhiá»u ngÃ´n ngá»¯ khÃ¡c nhau.
- **Káº¿t há»£p Schema Registry**: chá»‰ cáº§n gá»­i schema ID thay vÃ¬ toÃ n bá»™ schema, giÃºp quáº£n lÃ½ táº­p trung vÃ  version hÃ³a rÃµ rÃ ng.

### 2.3. Schema Registry

Schema Registry lÃ  má»™t service trung tÃ¢m dÃ¹ng Ä‘á»ƒ:

- LÆ°u trá»¯ vÃ  quáº£n lÃ½ **version schema**.
- Äáº£m báº£o **tÃ­nh tÆ°Æ¡ng thÃ­ch** khi schema thay Ä‘á»•i.
- GiÃºp producer vÃ  consumer giao tiáº¿p an toÃ n thÃ´ng qua schema ID.

### 2.4. CÃ¡c cháº¿ Ä‘á»™ tÆ°Æ¡ng thÃ­ch (Compatibility Modes)

Khi cáº­p nháº­t schema, Schema Registry sáº½ kiá»ƒm tra tÃ­nh tÆ°Æ¡ng thÃ­ch dá»±a trÃªn mode Ä‘Ã£ cáº¥u hÃ¬nh. CÃ³ 7 cháº¿ Ä‘á»™ chÃ­nh:

| Compatibility Type | Changes allowed | Check against which schemas | Upgrade first |
| --- | --- | --- | --- |
| **BACKWARD** | Delete fields, Add optional fields | Last version | Consumers |
| **BACKWARD_TRANSITIVE** | Delete fields, Add optional fields | All previous versions | Consumers |
| **FORWARD** | Add fields, Delete optional fields | Last version | Producers |
| **FORWARD_TRANSITIVE** | Add fields, Delete optional fields | All previous versions | Producers |
| **FULL** | Add optional fields, Delete optional fields | Last version | Any order |
| **FULL_TRANSITIVE** | Add optional fields, Delete optional fields | All previous versions | Any order |
| **NONE** | Táº¥t cáº£ thay Ä‘á»•i Ä‘á»u Ä‘Æ°á»£c cháº¥p nháº­n | KhÃ´ng kiá»ƒm tra | Tuá»³ |

### Ã nghÄ©a thá»±c táº¿:

- **BACKWARD**: phá»• biáº¿n nháº¥t trong streaming (consumer upgrade cháº­m hÆ¡n producer).
- **BACKWARD_TRANSITIVE**: an toÃ n hÆ¡n, Ä‘áº£m báº£o schema má»›i tÆ°Æ¡ng thÃ­ch vá»›i toÃ n bá»™ lá»‹ch sá»­ schema.
- **FORWARD**: phÃ¹ há»£p vá»›i batch/ETL (producer upgrade cháº­m hÆ¡n consumer).
- **FULL** vÃ  **FULL_TRANSITIVE**: dÃ¹ng khi há»‡ thá»‘ng yÃªu cáº§u **tÆ°Æ¡ng thÃ­ch 2 chiá»u tuyá»‡t Ä‘á»‘i**, upgrade producer hoáº·c consumer theo báº¥t ká»³ thá»© tá»± nÃ o.
- **NONE**: chá»‰ nÃªn dÃ¹ng trong **dev/test**, vÃ¬ dá»… gÃ¢y crash consumer.



## 3. Thá»±c hiá»‡n

### 3.1. Khá»Ÿi cháº¡y Kafka + Schema Registry

VÃ­ dá»¥ Docker Compose:

```yaml
version: '2'
services:
  kafka:
    image: 'confluentinc/cp-kafka:7.6.0'
    container_name: kafka
    networks:
      dev-net:
        aliases:
          - kafka.remote
    ports:
      - '9092:9092'
    environment:
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_NODE_ID: 1
      KAFKA_LISTENERS: 'PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka.remote:9092'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka.remote:9093'
      
      
  schema-registry:
    image: 'confluentinc/cp-schema-registry:latest'
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:9092'
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:8081'

```

### 3.3. Code máº«u Golang

### Producer (gá»­i Avro message vá»›i schema ID)

```go
package main

import (
    "context"
    "fmt"
    "log"

    "github.com/segmentio/kafka-go"
    "github.com/riferrei/srclient" // Schema Registry client
    avro "github.com/hamba/avro/v2"
)

func main() {
    // Táº¡o client schema registry
    client := srclient.CreateSchemaRegistryClient("http://localhost:8081")

    schema, err := client.GetLatestSchema("user-value")
    if err != nil {
        log.Fatal(err)
    }

    codec, err := avro.Parse(schema.Schema())
    if err != nil {
        log.Fatal(err)
    }

    // Serialize dá»¯ liá»‡u
    user := map[string]interface{}{
        "id":    1,
        "name":  "Alice",
        "email": "alice@example.com",
    }

    value, err := avro.Marshal(codec, user)
    if err != nil {
        log.Fatal(err)
    }

    // Prefix magic byte (0) + schema ID (4 bytes)
    encoded := make([]byte, 5+len(value))
    encoded[0] = 0
    encoded[1] = byte(schema.ID() >> 24)
    encoded[2] = byte(schema.ID() >> 16)
    encoded[3] = byte(schema.ID() >> 8)
    encoded[4] = byte(schema.ID())
    copy(encoded[5:], value)

    // Kafka producer
    w := &kafka.Writer{
        Addr:  kafka.TCP("localhost:9092"),
        Topic: "user-topic",
    }

    err = w.WriteMessages(context.Background(),
        kafka.Message{Value: encoded},
    )
    if err != nil {
        log.Fatal(err)
    }
    fmt.Println("Sent user:", user)
}

```

### Consumer (deserialize theo schema tá»« Registry)

```go
package main

import (
    "context"
    "fmt"
    "log"

    "github.com/segmentio/kafka-go"
    "github.com/riferrei/srclient"
    avro "github.com/hamba/avro/v2"
)

func main() {
    client := srclient.CreateSchemaRegistryClient("http://localhost:8081")

    r := kafka.NewReader(kafka.ReaderConfig{
        Brokers: []string{"localhost:9092"},
        GroupID: "user-group",
        Topic:   "user-topic",
    })

    for {
        m, err := r.ReadMessage(context.Background())
        if err != nil {
            log.Fatal(err)
        }

        schemaID := int(m.Value[1])<<24 | int(m.Value[2])<<16 | int(m.Value[3])<<8 | int(m.Value[4])
        schema, err := client.GetSchema(schemaID)
        if err != nil {
            log.Fatal(err)
        }

        codec, err := avro.Parse(schema.Schema())
        if err != nil {
            log.Fatal(err)
        }

        payload := m.Value[5:]
        var result map[string]interface{}
        if err := avro.Unmarshal(codec, payload, &result); err != nil {
            log.Fatal(err)
        }

        fmt.Println("Received user:", result)
    }
}

```


## 4. Káº¿t luáº­n

Viá»‡c káº¿t há»£p **Avro + Schema Registry** trong Kafka mang láº¡i nhiá»u lá»£i Ã­ch:

- **Avro**: serialization hiá»‡u quáº£, nhá» gá»n, há»— trá»£ schema evolution.
- **Schema Registry**: quáº£n lÃ½ schema táº­p trung, Ä‘áº£m báº£o compatibility.
- GiÃºp há»‡ thá»‘ng **nÃ¢ng cáº¥p dáº§n dáº§n**, khÃ´ng cáº§n update Ä‘á»“ng loáº¡t táº¥t cáº£ service.

ðŸ‘‰ Lá»±a chá»n **compatibility mode** phÃ¹ há»£p lÃ  chÃ¬a khÃ³a:

- **BACKWARD / BACKWARD_TRANSITIVE**: event streaming, upgrade consumer cháº­m.
- **FORWARD / FORWARD_TRANSITIVE**: batch/ETL.
- **FULL / FULL_TRANSITIVE**: yÃªu cáº§u á»•n Ä‘á»‹nh tuyá»‡t Ä‘á»‘i.
- **NONE**: chá»‰ nÃªn dÃ¹ng trong dev/test.
