[{"content":"Standardizing Adapter Lifecycle in Frameworks with the Template Method Pattern 1. Đặt vấn đề Trong một framework nền tảng, ta thường cần hỗ trợ nhiều loại adapter khác nhau — chẳng hạn HTTP, gRPC, Kafka, hay Cron.\nDù mục đích của chúng khác nhau (xử lý request, tiêu thụ message, lên lịch job…), nhưng tất cả đều có chu trình vòng đời tương tự:\n1 Start → ... → Stop Cụ thể:\nMỗi adapter cần khởi động (OnStart) khi ứng dụng chạy. Và dừng lại (OnStop) khi ứng dụng shutdown. Uber Fx cung cấp cơ chế fx.Lifecycle giúp đăng ký các hook này:\n1 2 3 4 lc.Append(fx.Hook{ OnStart: func(ctx context.Context) error { ... }, OnStop: func(ctx context.Context) error { ... }, }) Tuy nhiên, khi framework mở rộng để hỗ trợ nhiều adapter, ta bắt đầu nhận thấy một vấn đề kiến trúc phổ biến:\nCác adapter là những thành phần khác nhau, nhưng lại có nhiều điểm tương đồng đáng kể\nmà không có cơ chế chứng minh hoặc tận dụng được khả năng tái sử dụng giao diện hay xử lý chung.\nKết quả là:\n❌ Mỗi adapter tự viết lại lifecycle giống nhau. ❌ Code lặp lại 60–70% (boilerplate Fx hook). ❌ Framework không có khung chuẩn để điều phối adapter. ❌ Nếu muốn thay đổi logic chung (ví dụ thêm logging, metrics\u0026hellip;), phải sửa ở tất cả adapter. Nói cách khác, các adapter có chung cấu trúc hoạt động, nhưng framework chưa nắm quyền điều phối vòng đời,\nvà điều đó khiến việc mở rộng hoặc bảo trì tốn rất nhiều effort.\nTình huống này cũng phổ biến trong các hệ thống nhiều adapter — nơi từng nhóm phát triển có thể tự định nghĩa lifecycle riêng,\nkhiến framework trở nên rời rạc, thiếu tính thống nhất, và khó chứng minh khả năng tái sử dụng.\n2. Giải pháp: Template Method Pattern Template Method Pattern là mẫu thiết kế cho phép:\nXác định bộ khung (template) của một quy trình trong lớp cha. Cho phép lớp con ghi đè các bước cụ thể mà không thay đổi khung tổng thể. Nói cách khác: lớp cha quyết định “quy trình diễn ra thế nào”,\ncòn lớp con chỉ cần mô tả “chi tiết từng bước”.\nÁp dụng vào bài toán adapter:\nLớp cha (template) quy định vòng đời chuẩn gồm OnStart và OnStop. Các adapter con (HTTP, gRPC, Kafka, …) chỉ cần triển khai logic riêng trong hai bước đó. Uber Fx (hoặc thư viện tương tự) chỉ đóng vai trò điều phối lifecycle, chứ không can thiệp vào cấu trúc template. 3. Thực hiện a. Định nghĩa interface lifecycle Trước hết, ta mô hình hóa giao diện vòng đời chung cho mọi adapter:\n1 2 3 4 type AdapterLifecycle interface { OnStart(ctx context.Context) error OnStop(ctx context.Context) error } Tất cả adapter (HTTP, gRPC, Kafka, \u0026hellip;) đều tuân theo giao diện này.\nb. Xây dựng lớp template BaseAdapter Lớp này chịu trách nhiệm định nghĩa khung lifecycle chung,\nvà tự động đăng ký vào hệ thống (ví dụ Uber Fx):\n1 2 3 4 5 6 7 8 9 10 type BaseAdapter[T any] struct { Config T } func (b *BaseAdapter[T]) RegisterLifecycle(lc fx.Lifecycle, impl AdapterLifecycle) { lc.Append(fx.Hook{ OnStart: impl.OnStart, OnStop: impl.OnStop, }) } Ở đây:\nRegisterLifecycle() là template method – quy định quy trình cố định cho mọi adapter. OnStart / OnStop là các bước mở rộng mà lớp con có thể tùy biến. fx.Lifecycle chỉ là cơ chế điều phối, không ảnh hưởng đến cấu trúc template. c. Cụ thể hóa adapter – Sub Class Mỗi adapter chỉ cần kế thừa BaseAdapter và định nghĩa logic riêng của mình:\n1 2 3 4 5 6 7 8 9 10 11 12 13 type HTTPAdapter struct { BaseAdapter[Config] } func (a *HTTPAdapter) OnStart(ctx context.Context) error { fmt.Println(\u0026#34;Starting HTTP server...\u0026#34;) return nil } func (a *HTTPAdapter) OnStop(ctx context.Context) error { fmt.Println(\u0026#34;Stopping HTTP server...\u0026#34;) return nil } Và đăng ký adapter thông qua template:\n1 2 3 4 5 func ForRoot(cfg Config) fx.Option { return fx.Invoke(func(lc fx.Lifecycle, adapter *HTTPAdapter) { adapter.RegisterLifecycle(lc, adapter) }) } Kết quả:\nToàn bộ adapter tuân theo vòng đời chuẩn. Chỉ cần định nghĩa phần riêng (OnStart/OnStop). Không còn phải copy-paste code lifecycle. 4. Kết luận Việc sử dụng Template Method Pattern giúp framework duy trì :\nFramework layer nắm quyền điều phối vòng đời (template). Adapter layer chỉ định nghĩa phần thực thi đặc thù. Logic chung (logging, metrics, tracing) có thể thêm một lần, áp dụng cho toàn hệ thống. Điều này biến lifecycle trở thành một phần có thể kiểm soát, mở rộng và bảo trì tập trung,\nthay vì nằm rải rác trong từng adapter cụ thể.\nKhi framework mở rộng với nhiều adapter khác nhau, việc mỗi adapter tự triển khai vòng đời riêng sẽ nhanh chóng dẫn đến trùng lặp, khó mở rộng và tốn effort bảo trì.\nBằng cách áp dụng Template Method Pattern, ta chuẩn hóa được quy trình Start → Stop,\ntách biệt phần cố định (template lifecycle) khỏi phần tùy biến (logic adapter),\ngiúp framework:\nDễ mở rộng thêm adapter mới. Giảm 60–70% code lặp. Quản lý lifecycle thống nhất. Giữ cấu trúc sạch, tuân theo Clean Architecture. ","date":"2025-11-01T00:40:00+08:00","permalink":"https://phongthien99.github.io/posts/standardizing-adapter-lifecycle-in-frameworks-with-the-template-method-pattern/","title":"Standardizing Adapter Lifecycle in Frameworks with the Template Method Pattern"},{"content":"Đặt vấn đề Trong phát triển ứng dụng web hiện đại, các hệ thống phức tạp thường được chia thành nhiều module độc lập. Tuy nhiên, triển khai toàn bộ ứng dụng dưới dạng mono frontend gây khó khăn trong việc mở rộng, bảo trì và tối ưu hiệu năng. Các thay đổi nhỏ trong một module có thể ảnh hưởng đến toàn bộ hệ thống, đồng thời việc tải tất cả module cho mọi người dùng dẫn đến lãng phí tài nguyên.\nMulti-Zone ra đời nhằm giải quyết các vấn đề này bằng cách tách ứng dụng thành các khu vực (zone) độc lập, cho phép triển khai, cập nhật và vận hành từng zone mà không ảnh hưởng đến các phần còn lại. Giải pháp này giúp tối ưu trải nghiệm người dùng, tăng khả năng mở rộng, phân tách trách nhiệm rõ ràng và hỗ trợ phát triển, vận hành độc lập giữa các nhóm.\nGiải pháp và lựa chọn công nghệ Để đáp ứng yêu cầu xây dựng ứng dụng multi-zone, team lựa chọn Next.js làm framework chính nhờ tính phổ biến, cộng đồng lớn và hỗ trợ tốt cho nhiều mô hình triển khai. Next.js cung cấp khả năng SSR (Server-Side Rendering) và multi-zone, giúp tối ưu hiệu năng và quản lý routing linh hoạt.\nTuy nhiên, với yêu cầu triển khai động dựa trên cấu hình mà không cần build lại và có thể sử dụng Nginx hoặc server tĩnh để phục vụ ứng dụng, việc chỉ dùng Next.js sẽ gặp hạn chế vì multi-zone của Next.js mặc định gắn với SSR.\nĐể giải quyết, team quyết định tích hợp thêm Qiankun, một framework micro frontend, giúp:\nTriển khai các ứng dụng con độc lập, có thể load dynamic theo cấu hình runtime. Cho phép tách biệt zone, triển khai trên server tĩnh hoặc Nginx mà không cần build lại toàn bộ ứng dụng. Dễ dàng quản lý routing và chia sẻ thư viện giữa các zone, đồng thời giữ được khả năng mở rộng và bảo trì. Giải pháp Next.js + Qiankun + Nginx + Dynamic Config Để tăng tính linh hoạt, hệ thống kết hợp dynamic config thông qua file env.js:\nFile env.js chứa thông tin runtime của các micro app như tên, URL và entry point, cho phép shell app load các micro app theo cấu hình mà không cần rebuild. Shell App (Next.js) đóng vai trò khung chính, quản lý layout, routing và có thể sử dụng SSR/SSG. Micro App triển khai độc lập, mỗi micro app là một zone trong kiến trúc multi-zone. Qiankun chịu trách nhiệm load các micro app runtime, quản lý sandbox, shared library và isolation giữa các micro app. Nginx phục vụ static files của shell app và micro app, đồng thời cung cấp cơ chế dynamic mapping thông qua file config để triển khai linh hoạt theo môi trường. Giải pháp này đảm bảo:\nDynamic deployment: Thêm, xóa, hoặc cập nhật micro app mà không cần rebuild shell app. Độc lập triển khai: Micro app build và deploy riêng, tách biệt với shell app. Tối ưu resource và hiệu năng: Nginx phục vụ static files, giảm tải server Node. Dễ quản lý cấu hình runtime: Cho phép triển khai khác nhau theo môi trường (dev, staging, prod) bằng các file config riêng. Kết luận Kết hợp Next.js, Qiankun và Nginx với cơ chế dynamic config mang lại giải pháp linh hoạt cho kiến trúc multi-zone.\nNext.js cung cấp nền tảng mạnh mẽ với SSR/SSG, routing và quản lý layout. Qiankun cho phép triển khai micro frontend ở cấp ứng dụng/zone, load dynamic theo runtime, tách biệt các module và chia sẻ thư viện. Nginx đảm bảo triển khai static, nhẹ nhàng và linh hoạt, kết hợp với file env.js để load cấu hình runtime mà không cần build lại shell app. Giải pháp này giúp team phát triển độc lập, dễ bảo trì, tối ưu trải nghiệm người dùng và quản lý cấu hình runtime hiệu quả. Đây là hướng đi phù hợp cho các dự án lớn, cần mở rộng theo từng module và triển khai linh hoạt trên nhiều môi trường, đồng thời giảm thiểu rủi ro khi cập nhật hoặc thay đổi từng phần của hệ thống.\n","date":"2025-10-26T23:09:00+07:00","permalink":"https://phongthien99.github.io/posts/multi-zone-in-modern-web-development-solution-with-next.js-qiankun-and-nginx/","title":"Multi-Zone in Modern Web Development: Solution with Next.js, Qiankun, and Nginx"},{"content":"Context Engineering – A Method for Designing Efficient AI Agent Systems with SpecKit 1. Bối cảnh: Vì sao phát triển phần mềm với AI Agent lại khó đến vậy? AI Agents như Claude Code, GitHub Copilot, hay các LLM-based assistant đang dần trở thành đồng đội trong lập trình. Tuy nhiên, nếu bạn từng làm việc với chúng trong dự án thật, có lẽ bạn đã gặp những vấđề quen thuộc:\nMất ngữ cảnh (Context Loss): AI quên kiến trúc, quy tắc coding, hoặc quyết định kỹ thuật đã thống nhất.\nHallucination \u0026amp; sai lệch: AI gợi ý sai công nghệ (ví dụ: đề xuất Redux dù project đang dùng React Query).\nThiếu truy vết (Traceability): Không rõ vì sao một quyết định kỹ thuật được đưa ra.\nTốn token (Token Inefficiency): Mỗi lần làm việc lại phải \u0026ldquo;nạp\u0026rdquo; toàn bộ context — tốn kém và chậm.\nTrong dự án next-solid, nhóm triển khai 5 features. Nhưng khi đến feature thứ 3, AI Agent lại quên rằng project dùng @tanstack/react-query — và đề xuất Redux. Lỗi nhỏ, nhưng hậu quả lớn: mất thời gian, sai hướng, và giảm niềm tin vào AI.\nNguyên nhân?\n👉 Không có hệ thống quản lý ngữ cảnh có cấu trúc, truy vết và tự kiểm chứng.\n2. Giải pháp: Context Engineering Context Engineering là một phương pháp để thiết kế, quản lý, và duy trì ngữ cảnh (context) cho AI Agents một cách có hệ thống.\nCông thức nền tảng:\n1 Context Engineering = Prompt Engineering + Knowledge Design + Memory Management + Reasoning Alignment Bốn trụ cột của Context Engineering Prompt Engineering – thiết kế prompts có cấu trúc, reusable và có validation gates.\nKnowledge Design – tổ chức kiến thức dự án thành artifacts có schema rõ ràng.\nMemory Management – lưu trữ và truy xuất context hiệu quả, tránh lãng phí token.\nReasoning Alignment – đảm bảo AI suy luận đúng hướng với triết lý dự án.\n3. SpecKit – Framework hiện thực hóa Context Engineering Để áp dụng Context Engineering vào thực tế, chúng tôi xây dựng SpecKit – một framework gồm các slash commands giúp AI làm việc có tổ chức và tự kiểm soát hơn.\nCấu trúc thư mục chính: 1 2 3 4 5 6 7 8 9 .claude/commands/ ├── speckit.specify.md # Tạo spec từ mô tả tự nhiên ├── speckit.clarify.md # Làm rõ yêu cầu mơ hồ ├── speckit.plan.md # Lập kế hoạch và technical design ├── speckit.tasks.md # Sinh tasks theo thứ tự phụ thuộc ├── speckit.implement.md # Triển khai có checkpoint ├── speckit.analyze.md # Kiểm tra consistency giữa artifacts ├── speckit.checklist.md # Sinh checklist kiểm thử └── speckit.constitution.md # Bộ nguyên tắc dự án (memory layer) Workflow tổng quát 1 2 3 4 5 6 7 8 9 10 11 User mô tả → /specify → spec.md (+ checklist) ↓ /clarify → resolved spec.md ↓ /plan → plan.md + research.md + contracts/ ↓ /tasks → tasks.md (theo dependencies) ↓ /analyze → báo cáo consistency ↓ /implement → triển khai + validation checkpoints 4. Bên trong Context Engineering – Cách SpecKit hiện thực 4 trụ cột 1️⃣ Prompt Engineering – Prompts có cấu trúc, có kiểm chứng Mỗi slash command chỉ làm một nhiệm vụ duy nhất.\nVí dụ /specify chỉ tạo spec, /plan chỉ lập kế hoạch. Điều này giúp phân tách trách nhiệm rõ ràng và dễ kiểm soát chất lượng. SpecKit còn dùng kỹ thuật Progressive Disclosure – chỉ nạp đúng context cần cho mỗi giai đoạn.\n→ Giảm 60–70% lượng token tiêu thụ mỗi vòng.\nCuối mỗi phase có Validation Gates: checklist tự động kiểm tra chất lượng spec, completeness, readiness trước khi qua bước tiếp theo.\n2️⃣ Knowledge Design – Kiến thức có cấu trúc, có schema SpecKit chia artifacts thành 3 tầng:\nTier 1 – Project Memory: CLAUDE.md (AI context hiện tại) + constitution.md (nguyên tắc dự án).\nTier 2 – Feature Artifacts: mỗi feature có spec.md, plan.md, tasks.md, research.md, contracts/, data-model.md.\nTier 3 – Templates: lưu schema chuẩn cho mọi loại artifact.\nMọi file đều tuân theo schema định nghĩa trước, giúp AI hiểu và truy xuất chính xác thay vì phải \u0026ldquo;đoán\u0026rdquo;.\n3️⃣ Memory Management – Lưu trữ và truy xuất hiệu quả SpecKit thiết kế memory theo 4 cấp độ:\nLevel Loại bộ nhớ Vai trò 1 Session Memory Tạm thời, phục vụ conversation hiện tại 2 Feature Memory Lưu từng feature, có version control 3 Project Memory Ghi nhận state toàn dự án 4 Template Memory Đảm bảo consistency và reuse Nhờ đó, AI chỉ cần đọc những phần liên quan, không phải \u0026ldquo;nuốt\u0026rdquo; toàn bộ 5000 tokens của project mỗi lần.\n4️⃣ Reasoning Alignment – Căn chỉnh suy luận bằng \u0026ldquo;Constitution\u0026rdquo; SpecKit định nghĩa bộ nguyên tắc trong file constitution.md.\nVí dụ:\n1 2 3 4 ## Principle VI: Clean Architecture with SOLID - 4 layers: Presentation, Application, Domain, Infrastructure - Repository pattern bắt buộc - Hooks chỉ phụ thuộc interface, không phụ thuộc implementation Mỗi lần AI lên plan, SpecKit chạy Constitution Check – nếu có vi phạm, quy trình dừng lại ngay.\nVí dụ: feature 003 ban đầu dùng Redux → bị chặn vì \u0026ldquo;Redux không nằm trong approved dependencies\u0026rdquo;.\nKết quả: dùng lại React Query, đảm bảo consistency.\n5. Kết quả: Khi AI làm việc như một kỹ sư thật Sau khi áp dụng Context Engineering với SpecKit:\nLợi ích Mô tả Consistency 5 features cùng tuân theo Clean Architecture, không sai lệch. Traceability Mọi quyết định đều có rationale rõ ràng trong research.md. Quality 3 tầng validation – từ nội dung đến tiêu chí chấp nhận. Efficiency Giảm token usage mỗi iteration. Scalability Dễ mở rộng dự án, dễ cập nhật principles và templates. 6. Kết luận AI Agents không chỉ cần \u0026ldquo;prompt hay\u0026rdquo; – mà cần context tốt.\nVà để có context tốt, chúng ta phải kỹ sư hóa cách AI hiểu và ghi nhớ.\nContext Engineering chính là bước tiến đó.\nCòn SpecKit là công cụ để biến lý thuyết ấy thành hành động — giúp AI phát triển phần mềm một cách có cấu trúc, có kỷ luật, và có trí nhớ.\n✳️ Tóm lại: Prompt Engineering giúp AI hiểu, nhưng Context Engineering giúp AI hành động nhất quán.\n","date":"2025-10-18T00:00:00+08:00","permalink":"https://phongthien99.github.io/posts/context-engineering-a-method-for-designing-efficient-ai-agent-systems-with-speckit/","title":"Context Engineering – A Method for Designing Efficient AI Agent Systems with SpecKit"},{"content":"Automated Versioning and Changelog Management for Helm Charts in a Monorepo with Release It 1. Đặt vấn đề Trong các dự án monorepo, nơi chứa nhiều Helm chart triển khai cho từng service hoặc module khác nhau (ví dụ: demo-umbrella-chart, whoami, api-gateway\u0026hellip;), việc quản lý version và release cho từng chart riêng lẻ thường rất phức tạp.\nNếu thực hiện thủ công, bạn sẽ cần:\nSửa version trong Chart.yaml. Sinh changelog. Tạo Git tag tương ứng. Đảm bảo chart hợp lệ (helm lint). Với hàng chục chart trong cùng repo, việc này dễ sai sót, tốn thời gian, và khó tích hợp vào pipeline CI/CD.\n2. Giải pháp Sử dụng công cụ Release It để tự động hóa quy trình release cho từng chart độc lập.\nMỗi Helm chart sẽ có:\nMột file cấu hình riêng .release-it.json (hoặc dùng script sinh động). Cấu hình plugin để: Tự động cập nhật version trong Chart.yaml. Sinh changelog tự động (CHANGELOG.md). Tạo tag Git riêng biệt theo tên chart. Các hook để lint chart, commit file, và in log kết quả. Cách này giúp:\nMỗi chart có chu kỳ release riêng biệt. Dễ mở rộng khi thêm chart mới. Dễ tích hợp CI/CD (GitHub Actions, GitLab CI, Jenkins,…). 3. Thực hiện 3.1 Cấu trúc thư mục monorepo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ├── demo-umbrella-chart │ ├── CHANGELOG.md │ ├── Chart.lock │ ├── charts │ │ ├── mariadb-18.0.3.tgz │ │ └── redis-19.0.2.tgz │ ├── Chart.yaml │ ├── templates │ └── values.yaml ├── whoami │ ├── charts │ ├── Chart.yaml │ ├── templates │ └── values.yaml ├── RELEASE.md ├── package.json ├── pnpm-lock.yaml Mỗi thư mục con như demo-umbrella-chart hay whoami đại diện cho một Helm chart độc lập.\n3.2 Cấu hình release-it tổng quát cho từng chart Tạo file:\n\u0026lt;chart-name\u0026gt;/.release-it.json\nVí dụ:\ndemo-umbrella-chart/.release-it.json hoặc whoami/.release-it.json\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 { \u0026#34;npm\u0026#34;: { \u0026#34;publish\u0026#34;: false}, \u0026#34;git\u0026#34;: { \u0026#34;tagName\u0026#34;: \u0026#34;\u0026lt;chart-name\u0026gt;/v${version}\u0026#34;, \u0026#34;tagMatch\u0026#34;: \u0026#34;\u0026lt;chart-name\u0026gt;/v*\u0026#34;, \u0026#34;commitMessage\u0026#34;: \u0026#34;chore(\u0026lt;chart-name\u0026gt;): release v${version}\u0026#34;, \u0026#34;tagAnnotation\u0026#34;: \u0026#34;Release \u0026lt;chart-name\u0026gt; v${version}\u0026#34;, \u0026#34;getLatestTagFromAllRefs\u0026#34;: true, \u0026#34;requireCleanWorkingDir\u0026#34;: false, \u0026#34;preset\u0026#34;: \u0026#34;angular\u0026#34; }, \u0026#34;github\u0026#34;: { \u0026#34;release\u0026#34;: false, \u0026#34;releaseName\u0026#34;: \u0026#34;\u0026lt;chart-name\u0026gt; v${version}\u0026#34;, \u0026#34;releaseNotes\u0026#34;: \u0026#34;echo \u0026#39;See CHANGELOG.md for details\u0026#39;\u0026#34; }, \u0026#34;hooks\u0026#34;: { \u0026#34;before:init\u0026#34;: [ \u0026#34;echo \u0026#39;🚀 Starting release for \u0026lt;chart-name\u0026gt;\u0026#39;\u0026#34;, \u0026#34;helm lint ./\u0026lt;chart-name\u0026gt;\u0026#34; ], \u0026#34;after:bump\u0026#34;: [ \u0026#34;git add ./\u0026lt;chart-name\u0026gt;/Chart.yaml\u0026#34; ], \u0026#34;after:git:release\u0026#34;: \u0026#34;echo \u0026#39;✅ \u0026lt;chart-name\u0026gt; v${version} released successfully\u0026#39;\u0026#34; }, \u0026#34;plugins\u0026#34;: { \u0026#34;@release-it/bumper\u0026#34;: { \u0026#34;in\u0026#34;: { \u0026#34;file\u0026#34;: \u0026#34;./\u0026lt;chart-name\u0026gt;/Chart.yaml\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;version\u0026#34; }, \u0026#34;out\u0026#34;: { \u0026#34;file\u0026#34;: \u0026#34;./\u0026lt;chart-name\u0026gt;/Chart.yaml\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;version\u0026#34; } }, \u0026#34;@release-it/conventional-changelog\u0026#34;: { \u0026#34;preset\u0026#34;: \u0026#34;angular\u0026#34;, \u0026#34;infile\u0026#34;: \u0026#34;./\u0026lt;chart-name\u0026gt;/CHANGELOG.md\u0026#34;, \u0026#34;header\u0026#34;: \u0026#34;# Changelog\\n\\nAll notable changes to \u0026lt;chart-name\u0026gt; will be documented in this file.\u0026#34;, \u0026#34;gitRawCommitsOpts\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;./\u0026lt;chart-name\u0026gt;\u0026#34; } } } } 🔧 Ghi chú:\nThay \u0026lt;chart-name\u0026gt; bằng tên thật của chart (vd: demo-umbrella-chart, whoami). Mỗi chart có thể copy cấu hình này và chỉ cần đổi tên là dùng được. @release-it/bumper sẽ tự động sửa version trong Chart.yaml. @release-it/conventional-changelog tạo CHANGELOG.md dựa trên commit Angular style. 3.3 Quy trình release Chạy lệnh sau cho chart cụ thể:\n1 2 npx release-it --config ./\u0026lt;chart-name\u0026gt;/.release-it.json Ví dụ:\n1 npx release-it --config ./demo-umbrella-chart/.release-it.json Release It sẽ:\nLint chart (helm lint). Sinh CHANGELOG.md dựa trên commit. Tăng version trong Chart.yaml. Commit và tạo tag demo-umbrella-chart/vX.Y.Z. Hiển thị log hoàn tất release. 4. Kết luận Việc áp dụng Release It cho từng Helm chart trong monorepo giúp:\n✅ Chuẩn hóa quy trình release — mọi chart đều có cấu hình thống nhất.\n✅ Tách biệt version control — mỗi chart có tag riêng (\u0026lt;chart-name\u0026gt;/vX.Y.Z).\n✅ Tự động hóa 100% — từ lint, version bump, đến changelog và tag Git.\n✅ Dễ mở rộng — chỉ cần copy file cấu hình, đổi \u0026lt;chart-name\u0026gt; là xong.\n✅ Dễ tích hợp CI/CD, đảm bảo release luôn ổn định và lặp lại được.\n","date":"2025-10-12T00:40:00+08:00","permalink":"https://phongthien99.github.io/posts/automated-versioning-and-changelog-management-for-helm-charts-in-a-monorepo-with-release-it/","title":"Automated Versioning and Changelog Management for Helm Charts in a Monorepo with Release It"},{"content":"Evolutionary Architecture: Integrating C4 Model, ADR, and Version Control 🧩 1. Đặt vấn đề Trong vòng đời phát triển phần mềm, kiến trúc luôn thay đổi.\nMột hệ thống có thể:\nBắt đầu từ monolith, Chuyển sang microservices, Rồi tiến hóa thành cloud-native với hạ tầng tự động (IaC). Mỗi thay đổi đó đều là một quyết định kiến trúc.\nNếu không được ghi lại và quản lý có hệ thống, đội ngũ sẽ gặp các vấn đề sau:\nKhông rõ hệ thống hiện tại khác gì so với trước đây. Không biết vì sao các quyết định kiến trúc được đưa ra. Không thể kiểm tra, khôi phục hay audit lịch sử kiến trúc. Điều này dẫn đến hiện tượng “architecture drift” — kiến trúc ban đầu dần bị sai lệch so với định hướng thiết kế.\nĐể tránh tình trạng đó, giải pháp là kết hợp:\nC4 Model – mô tả kiến trúc trực quan, ADR (Architecture Decision Record) – ghi lại lý do thay đổi, Version Control (Git) – quản lý lịch sử tiến hóa kiến trúc. ⚙️ 2. Giải pháp: Hệ thống quản lý kiến trúc có phiên bản 🔹 2.1. C4 Model – Trực quan hóa kiến trúc ở 4 cấp độ C4 Model, được giới thiệu bởi Simon Brown, là một cách tiếp cận mô hình hóa kiến trúc giúp mọi người trong nhóm — từ kỹ sư đến quản lý — đều có thể hiểu được hệ thống ở đúng mức độ chi tiết cần thiết.\nTên gọi C4 xuất phát từ bốn cấp độ mô tả kiến trúc:\n1. System Context (Ngữ cảnh hệ thống) Mục tiêu: Mô tả hệ thống đang nói đến là gì và nó tương tác với ai hoặc hệ thống nào khác. Người đọc: Quản lý dự án, Product Owner, Business Analyst, hoặc bất kỳ ai cần hiểu tổng thể. Trả lời câu hỏi: Hệ thống của chúng ta phục vụ ai và giao tiếp với hệ thống nào? Thể hiện: Các tác nhân bên ngoài (người dùng, hệ thống khác) và mối quan hệ giữa chúng với hệ thống chính. 2. Container (Các khối triển khai chính) Mục tiêu: Mô tả hệ thống được chia thành những phần lớn nào — chẳng hạn như web app, API service, database, queue, hoặc worker. Người đọc: Kiến trúc sư, kỹ sư DevOps, tech lead. Trả lời câu hỏi: Hệ thống gồm những ứng dụng hay dịch vụ nào và chúng giao tiếp ra sao? Thể hiện: Các container phần mềm chính, công nghệ sử dụng, và mối quan hệ giữa chúng. 3. Component (Các thành phần bên trong container) Mục tiêu: Cho biết cấu trúc bên trong của từng container, ví dụ một API có những module nào (controller, service, repository, client\u0026hellip;). Người đọc: Nhà phát triển và kiến trúc sư hệ thống. Trả lời câu hỏi: Bên trong một service hoặc ứng dụng gồm những phần nào và chúng đảm nhiệm trách nhiệm gì? 4. Code (Chi tiết ở mức lớp hoặc hàm) Mục tiêu: Mô tả cấu trúc chi tiết của code — cách các class, function hoặc package tương tác. Người đọc: Nhà phát triển trực tiếp làm việc với codebase. Trả lời câu hỏi: Cấu trúc code thực tế phản ánh kiến trúc ở mức nào? Cấp độ Mục tiêu Người đọc chính Trả lời câu hỏi System Context Toàn cảnh hệ thống và mối quan hệ bên ngoài PO, BA, Business Hệ thống phục vụ ai, tương tác với ai Container Phân rã hệ thống thành các dịch vụ chính Architect, DevOps Có những ứng dụng và công nghệ nào Component Cấu trúc bên trong một container Developer, Architect Có những module nào và vai trò ra sao Code Cấu trúc chi tiết của code Developer Class, hàm, thư viện tương tác thế nào 💡 Khi mô hình được viết dưới dạng diagram as code (như Mermaid hoặc Structurizr DSL), các file này có thể được version hóa trong Git, giúp theo dõi và so sánh dễ dàng giữa các phiên bản kiến trúc.\n🔹 2.2. ADR – Ghi lại lý do của mỗi quyết định kiến trúc ADR (Architecture Decision Record) là cách ghi nhận vì sao một quyết định kỹ thuật được đưa ra tại một thời điểm cụ thể.\nMỗi ADR nên trả lời được ba câu hỏi:\nBối cảnh: Tại sao cần thay đổi? Quyết định: Giải pháp được chọn là gì? Hệ quả: Tác động của quyết định này (tích cực hoặc tiêu cực) là gì? Ví dụ:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 003 - Chuyển từ REST sang Event-driven Architecture Ngày: 2025-07-01 Trạng thái: Superseded by ADR-005 Người đề xuất: Giang Bối cảnh: REST API không đáp ứng khối lượng giao dịch cao trong giờ cao điểm. Quyết định: Chuyển sang mô hình Event-driven sử dụng SNS + SQS. Hệ quả: + Tăng throughput, giảm độ trễ. - Tăng độ phức tạp trong kiểm thử và giám sát. Khi một quyết định mới thay thế quyết định cũ, bạn chỉ cần cập nhật trạng thái:\n1 Status: Superseded by ADR-005 Toàn bộ lịch sử thay đổi được lưu giữ rõ ràng và có thể tra cứu bất kỳ lúc nào.\n🔹 2.3. Version Control – Theo dõi tiến hóa kiến trúc Lưu C4 Model và ADR trong Git giúp quản lý kiến trúc như code:\nHành động Cách thực hiện Xem lại kiến trúc cũ git log docs/c4/container.mmd So sánh giữa hai phiên bản git diff v1.2 v1.3 docs/adr/ Quay lại kiến trúc cũ git checkout \u0026lt;commit-id\u0026gt; docs/c4/ Gắn liên kết giữa code và quyết định Commit message: feat(payment): implement SNS flow (ADR-003) Một cấu trúc dự án có thể như sau:\n1 2 3 4 5 6 7 8 9 10 11 main ├── docs/ │ ├── c4/ │ │ ├── system-context.mmd │ │ ├── container.mmd │ │ └── component.mmd │ └── adr/ │ ├── 001-use-rest-api.md │ ├── 002-use-postgresql.md │ └── 003-move-to-event-driven.md └── src/ Mỗi commit nên bao gồm thay đổi code + ADR + diagram, đảm bảo rằng kiến trúc, quyết định và hiện thực luôn đồng bộ.\n🧪 3. Thực hành: Quy trình đề xuất Khi có thay đổi lớn:\nViết ADR mô tả lý do, cập nhật C4 diagram tương ứng.\nCommit chuẩn:\n1 2 git add docs/adr/004-use-step-functions.md docs/c4/container.mmd src/ git commit -m \u0026#34;ADR-004: Replace Lambda chain with Step Functions\u0026#34; Gắn tag kiến trúc:\n1 git tag arch-v1.0 Tích hợp CI/CD:\nTự động render biểu đồ, xuất ADR sang wiki hoặc documentation portal, và triển khai tài liệu kiến trúc mới nhất.\n🧭 4. Kết luận Khi kết hợp C4 Model, ADR, và Version Control, bạn tạo ra một kiến trúc có thể sống (living architecture) – nơi mà:\nThành phần Vai trò 🧩 C4 Model Giúp hiểu kiến trúc hiện tại 🧾 ADR Ghi lại lý do và bối cảnh quyết định 🕓 Version Control (Git) Theo dõi và khôi phục lịch sử thay đổi 🔁 Code thay đổi → Kiến trúc thay đổi → Quyết định được ghi lại → Lịch sử được bảo tồn.\nNhờ đó, đội ngũ có thể:\nDễ dàng audit và review kiến trúc, Giúp người mới nhanh chóng hiểu lịch sử kỹ thuật, Và đảm bảo kiến trúc tiến hóa có kiểm soát, thay vì trôi dạt theo thời gian. ","date":"2025-10-04T00:40:00+08:00","permalink":"https://phongthien99.github.io/posts/evolutionary-architecture-integrating-c4-model-adr-and-version-control/","title":"Evolutionary Architecture: Integrating C4 Model, ADR, and Version Control"},{"content":"Hybrid Helm Chart: Combining Dependency Charts and Embedded Subcharts 1. Đặt vấn đề Helm cho phép tổ chức chart thành nhiều thành phần nhỏ, gọi là subchart. Có hai cách phổ biến để sử dụng subchart:\nDependency Chart (theo tài liệu Helm): Khai báo trong Chart.yaml → dependencies. Được tải về từ một Helm repository hoặc OCI registry. Ví dụ: Redis, PostgreSQL từ Bitnami. Embedded Subchart (subchart nhúng / nội bộ): Chart con được viết thủ công và đặt trực tiếp trong thư mục charts/ của chart chính. Dùng để quản lý dịch vụ nội bộ hoặc microservice riêng của ứng dụng. Trong thực tế, nhiều dự án vừa cần tận dụng Dependency Chart (tái sử dụng chart cộng đồng chuẩn), vừa cần viết Embedded Subchart (dịch vụ nội bộ đặc thù).\n👉 Vấn đề đặt ra: làm sao kết hợp cả Dependency Chart và Embedded Subchart trong một release duy nhất để triển khai đồng bộ?\n2. Giải pháp Sử dụng mô hình Hybrid Helm Chart:\nChart chính đóng vai trò Umbrella chart. Kết hợp cả: Dependency Chart: khai báo trong dependencies, fetch từ repo ngoài. Embedded Subchart: viết thủ công và đặt trong charts/. Với mô hình này:\nTận dụng được chart ngoài (hạ tầng như DB, Cache, MQ). Đồng thời tổ chức dịch vụ nội bộ thành chart con, quản lý dễ dàng. Tất cả được triển khai tập trung trong một release Helm. 3. Thực hiện 3.1. Cấu trúc thư mục ví dụ 1 2 3 4 5 6 7 8 9 10 11 my-hybrid-app/ ├── Chart.yaml ├── values.yaml ├── charts/ │ ├── redis-17.11.3.tgz # Dependency Chart (fetch từ Bitnami repo) │ └── api/ # Embedded Subchart (microservice nội bộ) │ ├── Chart.yaml │ ├── values.yaml │ └── templates/ │ ├── deployment.yaml │ └── service.yaml redis → Dependency Chart, fetch từ repo ngoài. api → Embedded Subchart, nằm inline trong charts/. 3.2. Chart.yaml (chart chính) 1 2 3 4 5 6 7 8 apiVersion: v2 name: my-hybrid-app version: 0.1.0 dependencies: - name: redis version: 17.11.3 repository: \u0026#34;https://charts.bitnami.com/bitnami\u0026#34; 3.3. values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 # Config cho Dependency Chart (redis) redis: architecture: standalone auth: enabled: false # Config cho Embedded Subchart (api) api: replicaCount: 2 image: myregistry/my-api:1.0.0 service: type: ClusterIP port: 8080 Theo Helm docs: khi deploy, Helm sẽ merge values.yaml của chart chính với subchart theo key (redis:, api:).\n3.4. Quy trình triển khai Bước 1: Cập nhật dependency Tải Dependency Chart từ repo ngoài:\n1 helm dependency update ./my-hybrid-app Bước 2: Đóng gói chart Đóng gói chart chính thành .tgz:\n1 helm package ./my-hybrid-app Kết quả tạo file:\n1 my-hybrid-app-0.1.0.tgz Trong package sẽ có cả Dependency Chart (redis-17.11.3.tgz) và Embedded Subchart (charts/api/). Lưu ý: phải chạy helm dependency update trước, nếu không Dependency Chart sẽ thiếu trong package. Bước 3: Cài đặt hoặc nâng cấp release Triển khai trực tiếp từ source:\n1 helm upgrade --install my-hybrid ./my-hybrid-app -f values.yaml Hoặc từ package .tgz:\n1 helm upgrade --install my-hybrid my-hybrid-app-0.1.0.tgz -f values.yaml 👉 Kubernetes sẽ triển khai cả Redis (Dependency Chart) và API (Embedded Subchart) chỉ trong một release.\n4. Kết luận Hybrid Helm Chart là mô hình kết hợp cả Dependency Chart (chart ngoài từ repo/OCI) và Embedded Subchart (chart nội bộ inline).\nGiải quyết vấn đề: tái sử dụng chart chuẩn + triển khai dịch vụ custom. Ưu điểm: quản lý release tập trung, dễ mở rộng, tận dụng chart cộng đồng mà vẫn linh hoạt. Ứng dụng: phù hợp cho hệ thống microservices có cả hạ tầng chuẩn (DB, cache, message broker) và nhiều service riêng. ","date":"2025-10-01T00:00:00Z","permalink":"https://phongthien99.github.io/posts/hybrid-helm-chart-combining-dependency-charts-and-embedded-subcharts/","title":"Hybrid Helm Chart: Combining Dependency Charts and Embedded Subcharts"},{"content":"Umbrella Chart in Kubernetes 1. Đặt vấn đề Trong các ứng dụng Kubernetes hiện đại, một dự án thường không chỉ bao gồm một service đơn lẻ mà là tập hợp nhiều thành phần:\nWeb frontend Backend API Database Cache (Redis, Memcached…) Message broker (RabbitMQ, Kafka…) Khi triển khai bằng Helm, nếu tạo một chart riêng cho từng service, sẽ gặp một số khó khăn:\nPhải deploy từng chart riêng → mất thời gian, dễ sai sót. Quản lý cấu hình chung (password, hostname, phiên bản) khó khăn. Không dễ quản lý dependency giữa các service. Vấn đề đặt ra:\nLàm sao gom nhiều Helm Chart con thành một đơn vị triển khai duy nhất, đồng bộ, dễ quản lý cấu hình?\n2. Giải quyết: Umbrella Chart Umbrella Chart là Helm Chart “parent” dùng để gom nhiều Helm Chart con lại thành một gói triển khai duy nhất.\nĐặc điểm chính: Modularity (Tính module hóa) Mỗi chart con là một module riêng: MariaDB, Redis, Frontend. Umbrella chart gom lại thành một module cấp cao. Abstraction (Trừu tượng hóa) Che giấu chi tiết triển khai của chart con. Người dùng chỉ cần deploy umbrella chart và config các giá trị chung. Encapsulation (Đóng gói) Chart con có templates và values riêng. Umbrella chart expose một interface duy nhất (values.yaml) để cấu hình. Reusability (Tái sử dụng) Chart con có thể dùng lại nhiều umbrella chart hoặc dự án khác. Parameterization (Tham số hóa) Forward values (import-values hoặc global) → giống truyền tham số vào hàm. Ví dụ: password, replicas, image tag. 3. Thực hành: Tạo Umbrella Chart Bước 1: Tạo Umbrella Chart 1 2 helm create my-umbrella rm -rf my-umbrella/templates/* Bước 2: Khai báo dependency trong Chart.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 apiVersion: v2 name: my-umbrella version: 0.1.0 dependencies: - name: mariadb version: 18.0.3 repository: \u0026#34;https://charts.bitnami.com/bitnami\u0026#34; import-values: - child: \u0026#34;\u0026#34; parent: mariadb - name: redis version: 19.0.2 repository: \u0026#34;https://charts.bitnami.com/bitnami\u0026#34; import-values: - child: \u0026#34;\u0026#34; parent: redis Bước 3: Config values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mariadb: auth: rootPassword: \u0026#34;rootpass123\u0026#34; username: \u0026#34;myuser\u0026#34; password: \u0026#34;mypassword\u0026#34; database: \u0026#34;mydb\u0026#34; primary: persistence: enabled: false redis: auth: password: \u0026#34;redisSecret123\u0026#34; replica: replicaCount: 2 Bước 4: Update dependency 1 helm dependency update my-umbrella Bước 5: Render template hoặc deploy 1 2 helm template myapp ./my-umbrella helm install myapp ./my-umbrella Khi deploy, MariaDB và Redis sẽ nhận config từ umbrella chart mà không cần chỉnh từng chart con. 4. Kết luận Umbrella Chart giúp: Quản lý nhiều chart con trong một release. Forward giá trị chung dễ dàng. Triển khai đồng bộ, giảm sai sót. Khi nào nên dùng: Ứng dụng gồm nhiều service liên quan. Muốn deploy nhiều chart con đồng thời. Muốn maintain cấu hình tập trung. ","date":"2025-09-27T00:00:00Z","permalink":"https://phongthien99.github.io/posts/umbrella-chart-in-kubernetes/","title":"Umbrella Chart in Kubernetes"},{"content":"Security and Artifact Management with Nexus Repository 1. Đặt vấn đề Trong phát triển phần mềm hiện đại, hầu hết dự án đều phụ thuộc vào rất nhiều thư viện bên thứ ba. Điều này kéo theo nhiều rủi ro:\nBảo mật Lấy dependency trực tiếp từ internet (Maven Central, npmjs.org, PyPI, …) dễ gặp package chứa mã độc. Không có kiểm soát: bất kỳ ai cũng có thể thêm/sử dụng artifact mà không bị giám sát. Quản lý artifact Các gói nội bộ (internal library, SDK) cần một nơi tập trung để chia sẻ trong team. Artifact version nhiều, dễ trùng lặp hoặc thất lạc. CI/CD cần nguồn tin cậy để lấy/gửi artifact, tránh “mất gói” hoặc “dùng nhầm version”. 👉 Vì vậy cần một trung tâm artifact tập trung, an toàn, dễ quản lý.\n2. Giải pháp: Nexus Repository Nexus Repository Manager (Nexus 3) là giải pháp phổ biến:\nBảo mật Hỗ trợ xác thực người dùng, phân quyền chi tiết. Proxy external repository (Maven Central, npmjs.org, Docker Hub, …) và cache lại → ngăn gói độc hại, giảm phụ thuộc internet. Quản lý artifact tập trung Lưu trữ artifact nội bộ (hosted). Proxy repo bên ngoài (proxy). Gom nhiều repo thành một entry duy nhất cho developer dùng (group). Chính sách cleanup tự động xoá version cũ. Tích hợp CI/CD Dễ push/pull artifact trong Jenkins, GitLab CI, GitHub Actions. 3. Triển khai Nexus bằng Docker 3.1. Cấu hình docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 services: nexus: image: sonatype/nexus3 container_name: nexus restart: always volumes: - \u0026#34;nexus-data:/sonatype-work\u0026#34; networks: default: aliases: - nexus-8081.remote - nexus-8085.remote volumes: nexus-data: {} networks: default: external: name: traefik-ingress 👉 Giải thích:\nVolumes nexus-data lưu toàn bộ cấu hình, artifact. Network alias giúp client gọi được Nexus qua nexus-8081.remote. Nếu dùng Traefik, có thể expose qua domain https://nexus.company.com. Chạy dịch vụ:\n1 docker compose up -d Đăng nhập lần đầu: cat nexus-data/admin.password.\n4. Kết nối Maven với Nexus (qua Proxy) Để mọi dependency đều đi qua Nexus thay vì internet, cần chỉnh file ~/.m2/settings.xml.\n4.1. File cấu hình rút gọn 1 2 3 4 5 6 7 8 9 \u0026lt;settings\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;nexus\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;*\u0026lt;/mirrorOf\u0026gt; \u0026lt;url\u0026gt;http://nexus-8081.remote:8080/repository/maven-public/\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; \u0026lt;/settings\u0026gt; 👉 Ý nghĩa:\nmirrorOf=\u0026quot;*\u0026quot;: tất cả repository đều được redirect qua Nexus. maven-public: là Group repo trong Nexus (gom Maven Central + repo nội bộ). Developer chỉ cần 1 URL duy nhất, không quan tâm repo ngoài. 4.2. Example thử nghiệm pull artifact Tạo một project Maven mới từ archetype:\n1 2 3 4 5 mvn archetype:generate \\ -DgroupId=com.demo \\ -DartifactId=nexus-test \\ -DarchetypeArtifactId=maven-archetype-quickstart \\ -DinteractiveMode=false 👉 Maven sẽ:\nGửi request dependency đến http://nexus-8081.remote:8080/repository/maven-public/. Nexus kiểm tra cache: Nếu có sẵn → trả về ngay. Nếu chưa có → proxy ra Maven Central, tải artifact, cache lại, rồi trả về. Lần sau build lại, artifact sẽ lấy trực tiếp từ cache trong Nexus, không ra internet nữa.\n5. Kết luận Việc bảo mật và quản lý artifact là cực kỳ quan trọng khi hệ thống phụ thuộc nhiều package bên ngoài. Nexus Repository cung cấp giải pháp tập trung: Proxy \u0026amp; cache external repo → an toàn, nhanh hơn. Lưu trữ artifact nội bộ, dễ quản lý version. Hỗ trợ phân quyền \u0026amp; tích hợp tốt với CI/CD. 👉 Với cấu hình settings.xml rút gọn, team có thể ngay lập tức chuyển toàn bộ Maven build sang dùng Nexus mà không cần thay đổi nhiều.\n","date":"2025-09-25T00:21:26Z","permalink":"https://phongthien99.github.io/posts/security-and-artifact-management-with-nexus-repository/","title":"Security and Artifact Management with Nexus Repository"},{"content":"Migrating Data from MySQL to PostgreSQL with Debezium CDC 1. Đặt vấn đề Nhiều doanh nghiệp bắt đầu với MySQL nhờ dễ triển khai và phổ biến. Khi dữ liệu lớn hơn, PostgreSQL trở thành lựa chọn ưu việt nhờ khả năng mở rộng, chuẩn SQL mạnh mẽ và tính năng phong phú.\nThách thức: Làm sao di chuyển dữ liệu từ MySQL sang PostgreSQL mà không ảnh hưởng hệ thống đang hoạt động?\nDump \u0026amp; restore không khả thi với cơ sở dữ liệu lớn. Cần đảm bảo toàn vẹn dữ liệu, đồng bộ liên tục, kiểm thử trước cutover. CDC (Change Data Capture) là giải pháp, cho phép snapshot + đồng bộ realtime.\n2. Giải pháp Sử dụng Debezium + Kafka + JDBC Sink Connector:\nSnapshot ban đầu: Debezium chụp toàn bộ dữ liệu MySQL và push vào Kafka topic → PostgreSQL. CDC streaming: Debezium theo dõi binlog MySQL, push các thay đổi realtime sang PostgreSQL. Cutover: Chỉ cần switch connection ứng dụng sang PostgreSQL, downtime gần như bằng 0. Lưu ý:\nSnapshot dữ liệu lớn cần cấu hình hợp lý (snapshot.mode=initial). Chuẩn hóa schema giữa MySQL và PostgreSQL (TINYINT(1) → BOOLEAN, AUTO_INCREMENT → SEQUENCE). 3. Thử nghiệm 3.1. Docker Compose 3.1.1 Kafka + Schema Registry + AKHQ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 version: \u0026#39;3.8\u0026#39; services: kafka: image: confluentinc/cp-kafka:7.6.0 container_name: kafka hostname: kafka networks: traefik-ingress: aliases: - kafka.remote ports: - 9093:9093 - 9092:9092 environment: KAFKA_PROCESS_ROLES: broker,controller KAFKA_NODE_ID: 1 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka.remote:9092 KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka.remote:9093 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1 KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1 KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0 CLUSTER_ID: yZmtfI8tQ1mNvY2dH0Ttng KAFKA_NUM_PARTITIONS: 3 KAFKA_DEFAULT_REPLICATION_FACTOR: 1 schema-registry: image: confluentinc/cp-schema-registry:7.0.1 container_name: schema-registry hostname: schema-registry networks: traefik-ingress: aliases: - schema-registry.remote environment: SCHEMA_REGISTRY_HOST_NAME: schema-registry.remote SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081 SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka.remote:9092 ports: - \u0026#34;8081:8081\u0026#34; akhq: image: tchiotludo/akhq:0.26.0 container_name: akhq hostname: akhq networks: traefik-ingress: aliases: - akhq.remote environment: AKHQ_CONFIGURATION: | akhq: server: access-log: true connections: kafka-cluster: properties: bootstrap.servers: \u0026#34;kafka.remote:9092\u0026#34; schema-registry: url: \u0026#34;http://schema-registry.remote:8081\u0026#34; ports: - \u0026#34;9082:8080\u0026#34; networks: traefik-ingress: external: true 3.1.2 Kafka Connect 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 version: \u0026#39;3.7\u0026#39; services: kafka-connect: image: debezium/connect:2.7.3.Final container_name: kafka-connect environment: BOOTSTRAP_SERVERS: \u0026#34;kafka.remote:9092\u0026#34; HOST_NAME: kafka-connect ADVERTISED_HOST_NAME: kafka-connect GROUP_ID: debezium-connect-cluster OFFSET_STORAGE_TOPIC: \u0026#34;debezium-connect-offsets\u0026#34; CONFIG_STORAGE_TOPIC: \u0026#34;debezium-connect-configs\u0026#34; STATUS_STORAGE_TOPIC: \u0026#34;debezium-connect-status\u0026#34; CONFIG_STORAGE_REPLICATION_FACTOR: 1 OFFSET_STORAGE_REPLICATION_FACTOR: 1 STATUS_STORAGE_REPLICATION_FACTOR: 1 CONNECT_PLUGIN_PATH: /kafka/connect networks: - traefik-ingress networks: traefik-ingress: external: true 3.1.3 MySQL \u0026amp; PostgreSQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 version: \u0026#39;3.8\u0026#39; services: mysql: image: mysql:8.0 command: --default-authentication-plugin=mysql_native_password --server-id=1 --log-bin=mysql-bin --binlog-format=ROW --binlog-row-image=FULL container_name: source-mysql environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: appdb MYSQL_USER: appuser MYSQL_PASSWORD: apppass ports: - \u0026#34;3306:3306\u0026#34; restart: unless-stopped volumes: - mysql_data:/var/lib/mysql postgres: image: postgres:15 container_name: target-postgres environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: postgres POSTGRES_DB: appdb restart: unless-stopped volumes: - postgres_data:/var/lib/postgresql/data volumes: mysql_data: postgres_data: networks: default: external: name: traefik-ingress 3.2. Tạo Connector và Sink Debezium / Kafka Connect cung cấp REST API để tạo connector.\n3.2.1 Tạo Source Connector (MySQL → Kafka) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 curl -X POST http://localhost:8083/connectors \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;mysql-source-json\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;connector.class\u0026#34;: \u0026#34;io.debezium.connector.mysql.MySqlConnector\u0026#34;, \u0026#34;tasks.max\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;database.hostname\u0026#34;: \u0026#34;source-mysql\u0026#34;, \u0026#34;database.port\u0026#34;: \u0026#34;3306\u0026#34;, \u0026#34;database.user\u0026#34;: \u0026#34;appuser\u0026#34;, \u0026#34;database.password\u0026#34;: \u0026#34;apppass\u0026#34;, \u0026#34;database.server.id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;topic.prefix\u0026#34;: \u0026#34;mysql-appdb\u0026#34;, \u0026#34;database.include.list\u0026#34;: \u0026#34;appdb\u0026#34;, \u0026#34;table.include.list\u0026#34;: \u0026#34;appdb.customers\u0026#34;, \u0026#34;snapshot.mode\u0026#34;: \u0026#34;initial\u0026#34;, \u0026#34;schema.history.internal.kafka.bootstrap.servers\u0026#34;: \u0026#34;kafka.remote:9092\u0026#34;, \u0026#34;schema.history.internal.kafka.topic\u0026#34;: \u0026#34;schema-changes.appdb\u0026#34;, \u0026#34;key.converter\u0026#34;: \u0026#34;org.apache.kafka.connect.json.JsonConverter\u0026#34;, \u0026#34;key.converter.schemas.enable\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;value.converter\u0026#34;: \u0026#34;org.apache.kafka.connect.json.JsonConverter\u0026#34;, \u0026#34;value.converter.schemas.enable\u0026#34;: \u0026#34;true\u0026#34; } }\u0026#39; 3.2.2 Tạo Sink Connector (Kafka → PostgreSQL) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 curl -X POST http://localhost:8083/connectors \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;postgres-sink-json\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;connector.class\u0026#34;: \u0026#34;io.debezium.connector.jdbc.JdbcSinkConnector\u0026#34;, \u0026#34;tasks.max\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;topics\u0026#34;: \u0026#34;mysql-appdb.appdb.customers\u0026#34;, \u0026#34;connection.url\u0026#34;: \u0026#34;jdbc:postgresql://postgres:5432/appdb\u0026#34;, \u0026#34;connection.username\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;connection.password\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;insert.mode\u0026#34;: \u0026#34;upsert\u0026#34;, \u0026#34;delete.enabled\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;primary.key.mode\u0026#34;: \u0026#34;record_key\u0026#34;, \u0026#34;primary.key.fields\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;schema.evolution\u0026#34;: \u0026#34;basic\u0026#34;, \u0026#34;table.name.format\u0026#34;: \u0026#34;customers_sink\u0026#34;, \u0026#34;key.converter\u0026#34;: \u0026#34;org.apache.kafka.connect.json.JsonConverter\u0026#34;, \u0026#34;key.converter.schemas.enable\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;value.converter\u0026#34;: \u0026#34;org.apache.kafka.connect.json.JsonConverter\u0026#34;, \u0026#34;value.converter.schemas.enable\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;transforms\u0026#34;: \u0026#34;unwrap\u0026#34;, \u0026#34;transforms.unwrap.type\u0026#34;: \u0026#34;io.debezium.transforms.ExtractNewRecordState\u0026#34;, \u0026#34;transforms.unwrap.drop.tombstones\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;transforms.unwrap.delete.handling.mode\u0026#34;: \u0026#34;rewrite\u0026#34; } }\u0026#39; Sau khi gọi API, Debezium sẽ bắt đầu snapshot dữ liệu và CDC streaming, đồng bộ liên tục từ MySQL sang PostgreSQL.\n1. Thêm dữ liệu mới (INSERT) 1 2 3 INSERT INTO customers (name, email) VALUES (\u0026#39;Charlie\u0026#39;, \u0026#39;charlie@example.com\u0026#39;), (\u0026#39;David\u0026#39;, \u0026#39;david@example.com\u0026#39;); Sau vài giây, kiểm tra PostgreSQL: 1 SELECT * FROM customers_sink; Bạn sẽ thấy 2 record mới được thêm vào, đúng với dữ liệu MySQL. 2. Cập nhật dữ liệu (UPDATE) 1 2 3 UPDATE customers SET email = \u0026#39;alice.smith@example.com\u0026#39; WHERE name = \u0026#39;Alice\u0026#39;; Kiểm tra PostgreSQL: 1 SELECT * FROM customers_sink WHERE name = \u0026#39;Alice\u0026#39;; Email trong PostgreSQL cũng sẽ được cập nhật tương ứng. unwrap SMT đảm bảo rằng chỉ after state được ghi, không cần xử lý thủ công. 3. Xóa dữ liệu (DELETE) 1 DELETE FROM customers WHERE name = \u0026#39;Bob\u0026#39;; Kiểm tra PostgreSQL: 1 SELECT * FROM customers_sink; 4. Kết luận Downtime gần như bằng 0 nhờ snapshot + CDC. Toàn vẹn dữ liệu được đảm bảo trong suốt quá trình di chuyển. Quá trình cutover chỉ là switch connection, không ảnh hưởng người dùng. ","date":"2025-09-21T00:00:00Z","permalink":"https://phongthien99.github.io/posts/migrating-data-from-mysql-to-postgresql-with-debezium-cdc/","title":"Migrating Data from MySQL to PostgreSQL with Debezium CDC"},{"content":"A Practical Guide to Avro and Schema Registry in Kafka 1. Đặt vấn đề Trong hệ thống event streaming với Kafka, dữ liệu được truyền dưới dạng message giữa producer và consumer. Một vấn đề lớn xuất hiện khi dữ liệu thay đổi cấu trúc (schema evolution):\nProducer thêm/bớt field trong message. Consumer cũ chưa được nâng cấp kịp thời. Nguy cơ consumer không đọc được dữ liệu, gây lỗi toàn hệ thống. Ví dụ: Producer ban đầu gửi {id, name}, sau đó nâng cấp thêm email. Nếu consumer chưa biết field mới thì phải làm sao?\n2. Cách giải quyết 2.1. Avro là gì? Apache Avro là một serialization framework mã nguồn mở, tối ưu cho việc lưu trữ và truyền tải dữ liệu:\nDựa trên schema: định nghĩa bằng JSON. Hiệu năng cao: nhị phân, nhỏ gọn hơn JSON/XML. Đa ngôn ngữ: sinh code cho Java, Go, Python, C#… Hỗ trợ schema evolution: thêm/bớt field vẫn đọc được dữ liệu cũ nếu có default. Ví dụ schema Avro:\n1 2 3 4 5 6 7 8 9 { \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;User\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;int\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;name\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;type\u0026#34;: [\u0026#34;null\u0026#34;,\u0026#34;string\u0026#34;], \u0026#34;default\u0026#34;: null} ] } 2.2. Lợi ích khi sử dụng Avro trong Kafka Hiệu năng \u0026amp; tiết kiệm: dữ liệu nhị phân gọn nhẹ, giảm chi phí lưu trữ và băng thông. Đảm bảo tính nhất quán: tất cả dữ liệu đều theo schema đã định nghĩa. Hỗ trợ nâng cấp linh hoạt: dễ dàng thêm/bớt field mà không phá vỡ hệ thống. Ngôn ngữ trung lập: dễ dàng tích hợp microservices viết bằng nhiều ngôn ngữ khác nhau. Kết hợp Schema Registry: chỉ cần gửi schema ID thay vì toàn bộ schema, giúp quản lý tập trung và version hóa rõ ràng. 2.3. Schema Registry Schema Registry là một service trung tâm dùng để:\nLưu trữ và quản lý version schema. Đảm bảo tính tương thích khi schema thay đổi. Giúp producer và consumer giao tiếp an toàn thông qua schema ID. 2.4. Các chế độ tương thích (Compatibility Modes) Khi cập nhật schema, Schema Registry sẽ kiểm tra tính tương thích dựa trên mode đã cấu hình. Có 7 chế độ chính:\nCompatibility Type Changes allowed Check against which schemas Upgrade first BACKWARD Delete fields, Add optional fields Last version Consumers BACKWARD_TRANSITIVE Delete fields, Add optional fields All previous versions Consumers FORWARD Add fields, Delete optional fields Last version Producers FORWARD_TRANSITIVE Add fields, Delete optional fields All previous versions Producers FULL Add optional fields, Delete optional fields Last version Any order FULL_TRANSITIVE Add optional fields, Delete optional fields All previous versions Any order NONE Tất cả thay đổi đều được chấp nhận Không kiểm tra Tuỳ Ý nghĩa thực tế: BACKWARD: phổ biến nhất trong streaming (consumer upgrade chậm hơn producer). BACKWARD_TRANSITIVE: an toàn hơn, đảm bảo schema mới tương thích với toàn bộ lịch sử schema. FORWARD: phù hợp với batch/ETL (producer upgrade chậm hơn consumer). FULL và FULL_TRANSITIVE: dùng khi hệ thống yêu cầu tương thích 2 chiều tuyệt đối, upgrade producer hoặc consumer theo bất kỳ thứ tự nào. NONE: chỉ nên dùng trong dev/test, vì dễ gây crash consumer. 3. Thực hiện 3.1. Khởi chạy Kafka + Schema Registry Ví dụ Docker Compose:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 version: \u0026#39;2\u0026#39; services: kafka: image: \u0026#39;confluentinc/cp-kafka:7.6.0\u0026#39; container_name: kafka networks: dev-net: aliases: - kafka.remote ports: - \u0026#39;9092:9092\u0026#39; environment: KAFKA_PROCESS_ROLES: \u0026#39;broker,controller\u0026#39; KAFKA_NODE_ID: 1 KAFKA_LISTENERS: \u0026#39;PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093\u0026#39; KAFKA_ADVERTISED_LISTENERS: \u0026#39;PLAINTEXT://kafka.remote:9092\u0026#39; KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: \u0026#39;CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT\u0026#39; KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER KAFKA_CONTROLLER_QUORUM_VOTERS: \u0026#39;1@kafka.remote:9093\u0026#39; schema-registry: image: \u0026#39;confluentinc/cp-schema-registry:latest\u0026#39; environment: SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: \u0026#39;kafka:9092\u0026#39; SCHEMA_REGISTRY_HOST_NAME: schema-registry SCHEMA_REGISTRY_LISTENERS: \u0026#39;http://0.0.0.0:8081\u0026#39; 3.3. Code mẫu Golang Producer (gửi Avro message với schema ID) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github.com/segmentio/kafka-go\u0026#34; \u0026#34;github.com/riferrei/srclient\u0026#34; // Schema Registry client avro \u0026#34;github.com/hamba/avro/v2\u0026#34; ) func main() { // Tạo client schema registry client := srclient.CreateSchemaRegistryClient(\u0026#34;http://localhost:8081\u0026#34;) schema, err := client.GetLatestSchema(\u0026#34;user-value\u0026#34;) if err != nil { log.Fatal(err) } codec, err := avro.Parse(schema.Schema()) if err != nil { log.Fatal(err) } // Serialize dữ liệu user := map[string]interface{}{ \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;alice@example.com\u0026#34;, } value, err := avro.Marshal(codec, user) if err != nil { log.Fatal(err) } // Prefix magic byte (0) + schema ID (4 bytes) encoded := make([]byte, 5+len(value)) encoded[0] = 0 encoded[1] = byte(schema.ID() \u0026gt;\u0026gt; 24) encoded[2] = byte(schema.ID() \u0026gt;\u0026gt; 16) encoded[3] = byte(schema.ID() \u0026gt;\u0026gt; 8) encoded[4] = byte(schema.ID()) copy(encoded[5:], value) // Kafka producer w := \u0026amp;kafka.Writer{ Addr: kafka.TCP(\u0026#34;localhost:9092\u0026#34;), Topic: \u0026#34;user-topic\u0026#34;, } err = w.WriteMessages(context.Background(), kafka.Message{Value: encoded}, ) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Sent user:\u0026#34;, user) } Consumer (deserialize theo schema từ Registry) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github.com/segmentio/kafka-go\u0026#34; \u0026#34;github.com/riferrei/srclient\u0026#34; avro \u0026#34;github.com/hamba/avro/v2\u0026#34; ) func main() { client := srclient.CreateSchemaRegistryClient(\u0026#34;http://localhost:8081\u0026#34;) r := kafka.NewReader(kafka.ReaderConfig{ Brokers: []string{\u0026#34;localhost:9092\u0026#34;}, GroupID: \u0026#34;user-group\u0026#34;, Topic: \u0026#34;user-topic\u0026#34;, }) for { m, err := r.ReadMessage(context.Background()) if err != nil { log.Fatal(err) } schemaID := int(m.Value[1])\u0026lt;\u0026lt;24 | int(m.Value[2])\u0026lt;\u0026lt;16 | int(m.Value[3])\u0026lt;\u0026lt;8 | int(m.Value[4]) schema, err := client.GetSchema(schemaID) if err != nil { log.Fatal(err) } codec, err := avro.Parse(schema.Schema()) if err != nil { log.Fatal(err) } payload := m.Value[5:] var result map[string]interface{} if err := avro.Unmarshal(codec, payload, \u0026amp;result); err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Received user:\u0026#34;, result) } } 4. Kết luận Việc kết hợp Avro + Schema Registry trong Kafka mang lại nhiều lợi ích:\nAvro: serialization hiệu quả, nhỏ gọn, hỗ trợ schema evolution. Schema Registry: quản lý schema tập trung, đảm bảo compatibility. Giúp hệ thống nâng cấp dần dần, không cần update đồng loạt tất cả service. 👉 Lựa chọn compatibility mode phù hợp là chìa khóa:\nBACKWARD / BACKWARD_TRANSITIVE: event streaming, upgrade consumer chậm. FORWARD / FORWARD_TRANSITIVE: batch/ETL. FULL / FULL_TRANSITIVE: yêu cầu ổn định tuyệt đối. NONE: chỉ nên dùng trong dev/test. ","date":"2025-09-14T00:00:00Z","permalink":"https://phongthien99.github.io/posts/a-practical-guide-to-avro-and-schema-registry-in-kafka/","title":"A Practical Guide to Avro and Schema Registry in Kafka"},{"content":"Fake Domain trong Docker: Case Study với Kafka 1. Đặt vấn đề Trong môi trường development, chúng ta thường chạy nhiều service bằng Docker: database, message broker, API… để mô phỏng gần giống production. Các service này cần kết nối với nhau, đồng thời developer cũng muốn dùng tool từ máy host (máy thật) để test trực tiếp.\nVấn đề thường gặp:\nNếu container A gọi container B bằng localhost, thì localhost chỉ trỏ tới chính container A, không phải container B. Nếu dùng tên container (ví dụ kafka), thì trong Docker network hoạt động tốt, nhưng từ máy host thì hostname này không resolve được. Nếu dùng IP container, thì mỗi lần restart container, IP có thể thay đổi → config dễ bị hỏng. Kết quả là developer thường phải duy trì hai cấu hình khác nhau: một cho client chạy trong Docker network, một cho client chạy trên host. 👉 Giải pháp là sử dụng fake domain alias:\nDocker cho phép gán alias cho container trong network. Các container cùng network gọi service qua alias này. Trên host, ta ánh xạ alias đó về 127.0.0.1 trong file /etc/hosts. Nhờ vậy:\nContainer và host cùng dùng một domain để kết nối. Config được thống nhất, giảm lỗi. Developer dev/test thuận tiện hơn, không phải chỉnh sửa config nhiều lần. 2. Case Study: Kafka trong Docker 2.1. Cấu hình Kafka với fake domain alias Ví dụ trong docker-compose.yml:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 kafka: image: confluentinc/cp-kafka:7.6.0 container_name: kafka networks: dev-net: aliases: - kafka.remote # fake domain ports: - 9092:9092 environment: KAFKA_PROCESS_ROLES: broker,controller KAFKA_NODE_ID: 1 KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka.remote:9092 KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka.remote:9093 Ở đây:\nKafka quảng bá (advertise) địa chỉ kafka.remote:9092. Trong network dev-net, các container khác có thể gọi kafka.remote:9092 mà không cần IP. 2.2. Kết nối từ máy host Máy host không biết kafka.remote là gì, nên nếu chạy client Kafka từ host sẽ bị lỗi.\nGiải pháp: thêm alias vào /etc/hosts:\n1 127.0.0.1 kafka.remote Khi đó:\nContainer trong network: gọi Kafka bằng kafka.remote:9092. Host thật: cũng gọi Kafka bằng kafka.remote:9092. Ví dụ:\n1 2 3 4 5 # Từ container khác kafka-console-producer.sh --bootstrap-server kafka.remote:9092 --topic test # Từ host kafka-console-consumer.sh --bootstrap-server kafka.remote:9092 --topic test --from-beginning 👉 Cả hai trường hợp đều dùng chung config kafka.remote:9092.\n3. Kết luận Trong môi trường dev, vấn đề hostname giữa container và host thường gây rắc rối khi kết nối đến các service như Kafka. Sử dụng fake domain alias là một giải pháp đơn giản nhưng hiệu quả:\nContainer và host dùng cùng một domain. Config thống nhất, giảm lỗi khi chuyển đổi môi trường. Dev/test thuận tiện, gần giống với production (nơi thường dùng domain thay vì IP). Đây là một thủ thuật nhỏ nhưng cực kỳ hữu ích để giữ cho môi trường development gọn gàng, nhất quán và thân thiện với developer.\n","date":"2025-09-11T10:17:00+08:00","permalink":"https://phongthien99.github.io/posts/fake-domain-trong-docker-case-study-v%E1%BB%9Bi-kafka/","title":"Fake Domain trong Docker: Case Study với Kafka"},{"content":"1. Đặt vấn đề Trong các hệ thống phân tán hiện đại, Kafka thường được sử dụng như một nền tảng trung gian để xử lý dữ liệu theo thời gian thực. Khi triển khai CDC (Change Data Capture) nhằm đồng bộ dữ liệu giữa hai cơ sở dữ liệu, việc hiểu rõ các khái niệm Topic, Partition, Offset, Consumer Group và Key Message là cực kỳ quan trọng. Những thành phần này quyết định đến hiệu năng, khả năng mở rộng và tính toàn vẹn dữ liệu.\n2. Định nghĩa các khái niệm quan trọng 2.1 Kafka Topic Là danh mục (channel) nơi producer gửi message và consumer đọc message. Mỗi topic được chia nhỏ thành nhiều partition để hỗ trợ song song (parallelism). 2.2 Partition Mỗi partition là một log file append-only được lưu trên broker. Partition giúp Kafka scale: nhiều consumer có thể xử lý song song dữ liệu từ nhiều partition khác nhau. Message trong 1 partition được đảm bảo thứ tự (ordering). Tổng throughput của topic = tổng throughput của các partition. 2.3 Offset Offset là chỉ số tuần tự gắn với mỗi message trong một partition. Ví dụ: Partition P0 có message với offset 0,1,2… Consumer khi đọc sẽ ghi nhớ offset để biết mình đã xử lý đến đâu. 2.4 Consumer Group Consumer group = tập hợp nhiều consumer cùng đọc 1 topic. Kafka phân chia mỗi partition chỉ cho 1 consumer duy nhất trong group. Nếu số consumer = số partition → mỗi consumer đọc 1 partition. Nếu số consumer \u0026gt; số partition → có consumer sẽ idle (ngồi chơi). 2.5 Key trong message Kafka Key là giá trị tùy chọn gắn với mỗi message. Kafka dùng key để quyết định message sẽ vào partition nào. Cùng key → luôn cùng partition → đảm bảo thứ tự. Key quan trọng khi cần grouping theo entity (vd: user_id, order_id). 3. Case Study: CDC trong hệ thống Order Service của E-commerce Giả sử một hệ thống Order Service trong E-commerce cần đồng bộ dữ liệu đơn hàng từ Database A sang Database B qua Kafka:\nKhi đơn hàng được tạo/cập nhật/xóa, Debezium sẽ capture sự kiện và đẩy vào Kafka Topic orders. Key message = order_id → đảm bảo toàn bộ sự kiện liên quan đến cùng một đơn hàng đều nằm trong cùng một partition. Consumer Group “DB-Sync” (chạy ở Database B) sẽ nhận dữ liệu và áp dụng thay đổi tương ứng. Lợi ích:\nĐảm bảo tính toàn vẹn khi đồng bộ dữ liệu. Hỗ trợ scale-out bằng cách tăng số partition và số consumer group. Vẫn giữ được thứ tự update cho cùng một bản ghi. 4. Biểu đồ minh họa Quan hệ Topic - Partition - Consumer Group 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @startuml title Quan hệ Topic - Partition - Consumer Group skinparam componentStyle rectangle skinparam shadowing false skinparam rectangle { BorderColor #555 RoundCorner 12 } rectangle \u0026#34;Topic: customers\u0026#34; as Topic { rectangle \u0026#34;Partition P0\\nOffsets: 0..n\u0026#34; as P0 rectangle \u0026#34;Partition P1\\nOffsets: 0..n\u0026#34; as P1 rectangle \u0026#34;Partition P2\\nOffsets: 0..n\u0026#34; as P2 } package \u0026#34;Consumer Group A\u0026#34; as CGA { rectangle \u0026#34;Consumer A1\u0026#34; as A1 rectangle \u0026#34;Consumer A2\u0026#34; as A2 } package \u0026#34;Consumer Group B\u0026#34; as CGB { rectangle \u0026#34;Consumer B1\u0026#34; as B1 rectangle \u0026#34;Consumer B2\u0026#34; as B2 rectangle \u0026#34;Consumer B3\u0026#34; as B3 } P0 -right-\u0026gt; A1 : read P1 -right-\u0026gt; A2 : read P2 -right-\u0026gt; A2 : read P0 -right-\u0026gt; B1 : read P1 -right-\u0026gt; B2 : read P2 -right-\u0026gt; B3 : read note bottom of Topic - Message có **Key** (thường = Primary Key/Unique Key) - Partition = hash(Key) % numPartitions - Ordering chỉ được đảm bảo **trong 1 partition** end note note right of A2 Điều kiện: - Mỗi partition chỉ có 1 consumer **trong cùng group** - Consumer \u0026gt; Partition → consumer thừa không đọc - Consumer \u0026lt; Partition → consumer có thể đọc nhiều partition end note @enduml Luồng message CDC với Key và Offset 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @startuml title Luồng CDC: Producer -\u0026gt; Topic/Partition -\u0026gt; Consumer (với Key \u0026amp; Offset) actor App as Producer participant \u0026#34;Topic: customers\\nPartition P1\u0026#34; as P1 participant \u0026#34;Consumer A2\\n(Group A)\u0026#34; as A2 == Publish == Producer -\u0026gt; P1 : Produce message\\nKey = customer_id=123\\nValue = {... after ...} activate P1 P1 -\u0026gt; P1 : Ghi log append-only\\nAssign Offset = 1024 deactivate P1 note over P1 Ví dụ: - Key: 123 -\u0026gt; hash(Key) -\u0026gt; P1 - Offset tăng dần: ...1023, **1024**, 1025... end note == Consume == P1 -\u0026gt; A2 : Deliver record @Offset=1024 activate A2 A2 -\u0026gt; A2 : Xử lý \u0026amp; commit offset=1024 deactivate A2 == Tiếp theo == Producer -\u0026gt; P1 : Key=123 (update tiếp)\\n-\u0026gt; vẫn vào P1 activate P1 P1 -\u0026gt; P1 : Offset=1025 deactivate P1 P1 -\u0026gt; A2 : Deliver @Offset=1025 A2 -\u0026gt; A2 : Commit offset=1025 note right of A2 Consumer nhớ offset (commit) -\u0026gt; restart vẫn tiếp tục từ 1026 end note @enduml 5. Kết luận Trong CDC với Kafka:\nKey message đóng vai trò then chốt trong việc đảm bảo dữ liệu cùng bản ghi được xử lý tuần tự. Partition quyết định khả năng song song. Consumer Group đảm bảo tính cân bằng tải và mở rộng quy mô. Offset là cơ chế quan trọng giúp consumer có thể tiếp tục đọc từ đúng vị trí khi xảy ra restart. Điều kiện quan trọng: số lượng consumer trong group không nên vượt quá số partition, và key cần được chọn đúng (primary/unique key) để đảm bảo tính toàn vẹn. Việc thiết kế đúng số lượng partition, cơ chế consumer group, và key trong message là nền tảng cho một hệ thống CDC đáng tin cậy và hiệu quả.\n","date":"2025-08-30T10:17:00+08:00","permalink":"https://phongthien99.github.io/posts/kafka-topic-partition-offset-consumer-group-and-message-key-in-change-data-capture-cdc/","title":"Kafka Topic, Partition, Offset, Consumer Group, and Message Key in Change Data Capture (CDC)"},{"content":"1. Đặt vấn đề Trong các dự án Golang lớn, thường gặp tình huống:\nModule mới cần sử dụng một struct hoặc interface đã tồn tại trong module cũ. Nếu import trực tiếp module cũ: module mới sẽ phụ thuộc mạnh vào module cũ → tight coupling, khó bảo trì. Nếu di chuyển struct/interface vào shared module: phải sửa code cũ → dễ gây rủi ro phá vỡ logic đã ổn định. Câu hỏi đặt ra:\nLàm sao để module mới dùng lại struct và interface của module cũ thông qua một shared module, mà không thay đổi code cũ, đồng thời giảm phức tạp và dễ maintain?\n2. Giải pháp: Type Alias trong Shared Module Golang hỗ trợ type alias, cho phép tạo bí danh cho struct hoặc interface từ module cũ. Kết hợp với shared module, ta có thể giải quyết vấn đề:\n1 2 3 4 5 6 7 8 9 10 // shared/types.go package shared import oldmodule \u0026#34;project/module_old\u0026#34; // Alias cho struct type User = oldmodule.User // Alias cho interface type UserRepository = oldmodule.UserRepository Module mới chỉ cần import shared: 1 2 3 4 5 6 7 import \u0026#34;project/shared\u0026#34; func UseSharedTypes(repo shared.UserRepository) { var u shared.User u.Name = \u0026#34;Alice\u0026#34; repo.Save(u) // Gọi phương thức qua interface alias } Lợi ích: Module mới không cần biết module cũ. Code cũ không bị ảnh hưởng. Nếu struct/interface gốc thay đổi tên hoặc di chuyển, chỉ cần cập nhật alias trong shared module. Có thể mở rộng bằng wrapper function:\n1 2 3 func NewUser(name string) shared.User { return shared.User{Name: name} } Giúp module mới thêm logic khởi tạo object mà không sửa module cũ. 3. Giản hóa sự phức tạp Sử dụng alias cho struct và interface giúp:\nGiảm phụ thuộc trực tiếp giữa module mới và module cũ → tránh tight coupling. Dễ dàng refactor hoặc mở rộng → thay đổi struct/interface gốc chỉ cần sửa alias trong shared module. Chuẩn hóa truy cập các type chung → developer dễ nhìn, maintain hơn. Giảm code lặp lại, tránh copy/paste struct hoặc interface. Nhờ đó, module mới có thể dùng lại cả struct lẫn interface cũ một cách an toàn, rõ ràng và linh hoạt.\n4. Tuân thủ và vi phạm nguyên tắc Tuân thủ:\nDRY (Don\u0026rsquo;t Repeat Yourself): Tránh copy struct/interface, tái sử dụng thông qua alias. Encapsulation \u0026amp; Separation of Concerns: Module mới không cần biết chi tiết module cũ. Maintainability: Thay đổi struct/interface gốc không phá vỡ module mới. Có thể vi phạm:\nLeak abstraction: Alias quá nhiều hoặc không rõ ràng → dễ nhầm lẫn giữa alias và struct/interface gốc. Single Responsibility Principle (SRP): Shared module chứa quá nhiều alias → module trở nên “quá tải”. Overuse: Lạm dụng alias cho mọi struct/interface → giảm readability, khó trace code. 5. Kết luận Sử dụng type alias trong shared module cho cả struct và interface là một giải pháp hiệu quả để:\nCho phép module mới sử dụng struct và interface của module cũ mà không phá vỡ code hiện tại. Giảm sự phức tạp trong quản lý module, chuẩn hóa điểm truy cập các type chung. Duy trì tính maintainable và mở rộng được dự án, đồng thời tuân thủ nhiều nguyên tắc cơ bản của lập trình module. ","date":"2025-08-24T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/golang-module-design-simplifying-struct-and-interface-reuse/","title":"Golang Module Design: Simplifying Struct and Interface Reuse"},{"content":"From Manual to Automated: Enhancing Nginx Test Workflows Problem Statement Trong quá trình phát triển và vận hành hệ thống sử dụng Nginx làm reverse proxy, việc thêm, sửa hoặc xóa các cấu hình location, rewrite, hoặc proxy_pass có thể:\nẢnh hưởng không mong muốn đến các routing khác (ví dụ: route /admin/ bị chặn khi thêm /admin/api) Gây lỗi ẩn khó phát hiện do trùng khớp thứ tự location hoặc rewrite không đúng như mong đợi Thiếu công cụ kiểm thử tự động nên việc đảm bảo tính đúng đắn phụ thuộc nhiều vào manual test hoặc sản phẩm thật Hệ quả:\nRegression: thay đổi một route ảnh hưởng đến các route khác Solution Để giải quyết những vấn đề trên, chúng ta cần một bộ test tự động mạnh mẽ để kiểm thử routing của Nginx. Mục tiêu là đảm bảo các routing mới không ảnh hưởng đến các route hiện có, đồng thời có thể diễn giải và in ra cây routing logic giúp kiểm tra độ ưu tiên và khớp location một cách chính xác. Bộ test này cũng phải tái sử dụng được cho nhiều phiên bản cấu hình Nginx khác nhau trong các quy trình CI/CD, staging, hoặc kiểm tra pull request.\nĐề xuất kỹ thuật:\nSử dụng testcontainers kết hợp Ginkgo/Gomega: Đây là sự kết hợp lý tưởng để mô phỏng hệ thống Nginx với cấu hình cụ thể. Mỗi test case sẽ khởi tạo một Nginx container với file nginx.conf tương ứng, gửi các HTTP request và kiểm tra response có đúng như kỳ vọng. Xây dựng bộ test matrix (routing path → backend mong muốn): Cách tiếp cận này giúp dễ dàng mở rộng khi có thêm route mới, đồng thời kiểm tra hiệu quả các trường hợp xung đột, rewrite sai, hoặc khớp sai thứ tự. Implementation Định nghĩa routing và Test Case Routing cần test:\n1 2 3 4 5 6 7 8 9 10 11 12 server { listen 80; location /web { proxy_pass http://whoami.com; } location /api/ { rewrite ^/api/(.*)$ /$1 break; proxy_pass http://whoami.com; } } Bảng Test Case:\nTest Case ID Input URL Expected URI nhận tại backend Ghi chú TC001 /web GET /web proxy_pass giữ nguyên URI TC002 /api/demo GET /demo rewrite + proxy_pass TC003 /api/test/x GET /test/x rewrite sâu hơn TC004 /api/ GET / rewrite /api/ → / Mã nguồn Ginkgo test: nginx_test.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 package nginx_test import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; . \u0026#34;github.com/onsi/ginkgo/v2\u0026#34; . \u0026#34;github.com/onsi/gomega\u0026#34; \u0026#34;github.com/testcontainers/testcontainers-go\u0026#34; \u0026#34;github.com/testcontainers/testcontainers-go/network\u0026#34; \u0026#34;github.com/testcontainers/testcontainers-go/wait\u0026#34; ) var ( ctx context.Context net *testcontainers.DockerNetwork whoamiC testcontainers.Container nginxC testcontainers.Container ) var _ = BeforeSuite(func() { log.Print(\u0026#34;Setting up test environment...\u0026#34;) ctx = context.Background() // Tạo Docker network dùng chung var err error net, err = network.New(ctx) Expect(err).NotTo(HaveOccurred()) // Tạo container whoami whoamiReq := testcontainers.ContainerRequest{ Image: \u0026#34;traefik/whoami:latest\u0026#34;, Name: \u0026#34;whoami\u0026#34;, Hostname: \u0026#34;whoami.com\u0026#34;, ExposedPorts: []string{\u0026#34;80/tcp\u0026#34;}, Networks: []string{net.Name}, WaitingFor: wait.ForHTTP(\u0026#34;/\u0026#34;).WithPort(\u0026#34;80/tcp\u0026#34;).WithStartupTimeout(10 * time.Second), } whoamiC, err = testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{ ContainerRequest: whoamiReq, Started: true, }) Expect(err).NotTo(HaveOccurred()) // Tạo container nginx nginxReq := testcontainers.ContainerRequest{ Image: \u0026#34;nginx:latest\u0026#34;, ExposedPorts: []string{\u0026#34;80/tcp\u0026#34;}, Networks: []string{net.Name}, WaitingFor: wait.ForHTTP(\u0026#34;/\u0026#34;).WithPort(\u0026#34;80/tcp\u0026#34;).WithStartupTimeout(10 * time.Second), Files: []testcontainers.ContainerFile{ { HostFilePath: \u0026#34;nginx.conf\u0026#34;, // Đường dẫn đến file cấu hình nginx trên máy local ContainerFilePath: \u0026#34;/etc/nginx/nginx.conf\u0026#34;, FileMode: 0644, }, }, } nginxC, err = testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{ ContainerRequest: nginxReq, Started: true, }) Expect(err).NotTo(HaveOccurred()) }) var _ = Describe(\u0026#34;Nginx Reverse Proxy to Whoami\u0026#34;, func() { testCases := []struct { name string path string expectedURI string expectSuccess bool }{ {\u0026#34;proxy_pass without rewrite\u0026#34;, \u0026#34;/web\u0026#34;, \u0026#34;GET /web\u0026#34;, true}, {\u0026#34;rewrite + proxy_pass 1\u0026#34;, \u0026#34;/api/demo\u0026#34;, \u0026#34;GET /demo\u0026#34;, true}, {\u0026#34;rewrite + proxy_pass 2\u0026#34;, \u0026#34;/api/test/x\u0026#34;, \u0026#34;GET /test/x\u0026#34;, true}, {\u0026#34;rewrite + proxy_pass root\u0026#34;, \u0026#34;/api/\u0026#34;, \u0026#34;GET /\u0026#34;, true}, } for _, tc := range testCases { tc := tc // capture range variable It(fmt.Sprintf(\u0026#34;should handle route %s → %s\u0026#34;, tc.path, tc.expectedURI), func() { host, _ := nginxC.Host(ctx) port, _ := nginxC.MappedPort(ctx, \u0026#34;80\u0026#34;) url := fmt.Sprintf(\u0026#34;http://%s:%s%s\u0026#34;, host, port.Port(), tc.path) resp, err := http.Get(url) Expect(err).NotTo(HaveOccurred()) defer resp.Body.Close() body, _ := io.ReadAll(resp.Body) log.Printf(\u0026#34;Response for %s: %s\u0026#34;, tc.path, string(body)) if tc.expectSuccess { Expect(resp.StatusCode).To(Equal(200)) Expect(string(body)).To(ContainSubstring(tc.expectedURI)) Expect(string(body)).To(ContainSubstring(\u0026#34;Hostname: whoami.com\u0026#34;)) } else { Expect(string(body)).NotTo(ContainSubstring(\u0026#34;Hostname: whoami.com\u0026#34;)) } }) } }) var _ = AfterSuite(func() { log.Print(\u0026#34;Tearing down test environment...\u0026#34;) if whoamiC != nil { whoamiC.Terminate(ctx) } if nginxC != nil { nginxC.Terminate(ctx) } if net != nil { net.Remove(ctx) } }) func TestNginx(t *testing.T) { RegisterFailHandler(Fail) RunSpecs(t, \u0026#34;Nginx Suite\u0026#34;) } Để chạy bộ test này, bạn chỉ cần lưu cấu hình Nginx vào file nginx.conf cùng cấp với file nginx_test.go và chạy lệnh trong terminal:\n1 go test -v Conclusion Việc kiểm thử cấu hình Nginx một cách tự động là một bước tiến quan trọng trong việc đảm bảo sự ổn định và chính xác của hệ thống. Bằng cách kết hợp Testcontainers và Ginkgo/Gomega, chúng ta đã xây dựng được một bộ khung mạnh mẽ, cho phép:\nTự động hóa kiểm thử: Giảm thiểu đáng kể rủi ro gây ra bởi các thay đổi cấu hình thủ công. Phát hiện sớm lỗi: Các vấn đề về routing, rewrite, hoặc xung đột cấu hình sẽ được nhận diện ngay trong giai đoạn phát triển hoặc CI/CD. Kiểm soát phức tạp: Giúp quản lý hiệu quả hơn các cấu hình Nginx ngày càng phức tạp, đặc biệt trong các hệ thống microservices. ","date":"2025-07-18T00:00:00Z","permalink":"https://phongthien99.github.io/posts/from-manual-to-automated-enhancing-nginx-test-workflows/","title":"From Manual to Automated: Enhancing Nginx Test Workflows"},{"content":"Sharing JS Code Made Easy with pnpm Workspaces \u0026amp; Git Submodules 🎯 Đặt Vấn Đề: Hãy tưởng tượng bạn có nhiều dự án front-end (ví dụ: một ứng dụng web chính, một cổng admin, một landing page riêng) và nhiều dự án back-end (API Gateway, microservices). Tất cả những dự án này đều cần dùng chung một số thành phần như:\nUI Components: Các thành phần giao diện tái sử dụng (button, modal, form input…). Utility Functions: Các hàm tiện ích (validation, format ngày giờ, helpers gọi API…). Type Definitions: Các định nghĩa kiểu TypeScript chung (interfaces, enums…). Business Logic: Các module xử lý nghiệp vụ lõi. Nếu không có chiến lược quản lý tốt, bạn sẽ gặp phải những vấn đề sau:\nSao chép mã nguồn (Code Duplication): Phải copy-paste code giữa nhiều dự án. Khi sửa bug hay update logic, phải sửa nhiều nơi, dễ sót hoặc gây lỗi mới. Khó khăn khi cập nhật (Difficult Updates): Mỗi lần cần cập nhật thư viện chung, phải update thủ công từng dự án, dễ quên và dễ phá vỡ. Quản lý phiên bản phức tạp (Version Management): Làm sao đảm bảo tất cả dự án chạy ổn định với các version phù hợp? 💡 Giải Pháp: Kết Hợp pnpm workspace và git submodule Để giải quyết triệt để, chúng ta có thể kết hợp pnpm workspace và git submodule.\n🟢 pnpm workspace Cho phép quản lý nhiều package (dự án con hoặc thư viện) trong cùng một repo hoặc các folder con. 🔵 git submodule Cho phép nhúng một repository Git khác vào như một thư mục con, nhưng vẫn giữ commit và lịch sử riêng. Bạn có thể lock từng dự án vào một commit cụ thể của shared lib. Tách biệt rõ ràng trách nhiệm giữa repo chính và repo thư viện. ⚙️ Cơ Chế Hoạt Động Tạo repo riêng cho shared libraries, ví dụ: shared-libs. Trong mỗi dự án chính, thêm shared-libs làm submodule nếu cần dùng . Cấu hình pnpm workspace để nhận diện các package con bên trong shared-libs. Các dự án sử dụng thư viện bằng cách khai báo trực tiếp trong package.json. 🚀 Thực Hiện Chi Tiết Bước 1️⃣: Thêm shared-libs vào dự án chính bằng git submodule 1 2 3 git submodule add https://github.com/your-org/shared-libs lib/shared-libs git submodule update --init --recursive 📁 Sau bước này, thư mục lib/shared-libs chứa toàn bộ mã nguồn thư viện dùng chung.\nBước 2️⃣: Cấu hình pnpm workspace Tại thư mục gốc dự án chính, thêm file pnpm-workspace.yaml (hoặc chỉnh sửa nếu đã có):\n1 2 3 packages: - \u0026#39;lib/shared-libs/packages/*\u0026#39; ✅ pnpm sẽ tự nhận diện các package bên trong lib/shared-libs/packages như các package nội bộ.\nBước 3️⃣: Khai báo dependency trong package.json Mở file package.json của dự án chính, chỉnh dependencies (hoặc devDependencies) như sau:\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;name\u0026#34;: \u0026#34;web-app\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;private\u0026#34;: true, \u0026#34;dependencies\u0026#34;: { \u0026#34;@shared/utils\u0026#34;: \u0026#34;workspace:*\u0026#34;, \u0026#34;@shared/ui-components\u0026#34;: \u0026#34;workspace:*\u0026#34; } } 🔥 Dòng \u0026ldquo;workspace:*\u0026rdquo; có nghĩa: pnpm sẽ liên kết trực tiếp package nội bộ (không dùng bản publish trên npm), tiện cho phát triển song song.\nBước 4️⃣: Cài đặt Sau khi chỉnh xong package.json, chạy:\n1 2 pnpm install Bước 5️⃣: Làm việc với submodule Clone dự án mới 1 2 3 4 git clone \u0026lt;your-main-project-url\u0026gt; git submodule update --init --recursive pnpm install Khi cần cập nhật shared-libs 1 2 3 4 5 cd lib/shared-libs git pull origin main cd ../.. git add lib/shared-libs git commit -m \u0026#34;Update shared-libs to latest commit\u0026#34; 🛠️ Một số lệnh hữu ích với git submodule Lệnh Mục đích git submodule Liệt kê submodule hiện có git submodule update --init Khởi tạo và đồng bộ submodule sau khi clone git submodule add \u0026lt;repo\u0026gt; \u0026lt;path\u0026gt; Thêm submodule mới cd lib/shared-libs \u0026amp;\u0026amp; git pull Lấy version mới nhất của submodule git add lib/shared-libs \u0026amp;\u0026amp; git commit Commit thay đổi submodule 🏁 Kết Luận 💥 Lợi Ích Khi Kết Hợp ✅ Giảm trùng lặp mã nguồn — không còn copy-paste.\n✅ Quản lý dependency chính xác — mỗi dự án lock commit submodule riêng, không bị vỡ.\n✅ Phát triển nhanh \u0026amp; debug dễ — sửa code shared-libs, dự án chính thấy ngay.\n✅ Quản lý phiên bản rõ ràng — submodule tách biệt, chủ động cập nhật.\nViệc kết hợp pnpm workspace và git submodule mang đến một giải pháp cực kỳ mạnh mẽ và thực dụng để quản lý thư viện dùng chung giữa nhiều dự án JavaScript/TypeScript.\n✅ Không chỉ giúp giảm rủi ro, tiết kiệm thời gian, mà còn tối ưu chi phí build, test và deploy.\nDù có thể cần thêm chút công sức ban đầu để thiết lập, nhưng về lâu dài đây là giải pháp rất đáng giá cho những hệ thống lớn, nhiều repo, nhiều nhóm cùng phát triển.\n","date":"2025-07-13T00:00:00Z","permalink":"https://phongthien99.github.io/posts/sharing-js-code-made-easy-with-pnpm-workspaces-git-submodules/","title":"Sharing JS Code Made Easy with pnpm Workspaces \u0026 Git Submodules"},{"content":"Streamlining Deployment with GitLab CI/CD 🧩 1. Đặt Vấn Đề Trong quá trình phát triển phần mềm, việc kiểm thử và debug nhanh các job CI/CD là rất quan trọng. Tuy nhiên, GitLab CI/CD thường gặp một số vấn đề khi test local bằng gitlab-runner exec:\n❌ gitlab-runner exec không hỗ trợ include: hoặc extends: từ file ngoài ❌ Pipeline thực tế quá phức tạp, chứa nhiều môi trường như dev, prod, staging ❌ Không dễ test nhanh từng job do phải khai báo phân tán, phụ thuộc nhiều nơi 💡 2. Giải Pháp Vấn đề Giải pháp Không test local được Gom job + biến vào 1 file duy nhất để test Quản lý nhiều môi trường Mỗi môi trường tách riêng vars-*.yml Tái sử dụng script Dùng .job-base làm template job Giữ file .gitlab-ci.yml gọn Chỉ include file tổng .ci/include.yml 🛠️ 3. Thực Hiện 📁 3.1. Cấu trúc thư mục 1 2 3 4 5 6 7 8 9 10 11 .gitlab-ci.yml .ci/ ├─ job-template.yml ├─ vars-local.yml ├─ vars-dev.yml ├─ vars-prod.yml ├─ workflow-dev.yml ├─ workflow-prod.yml ├─ include.yml 📝 Ghi chú: Chúng ta tách cấu hình CI/CD thành các thành phần nhỏ gọn và rõ ràng:\nTemplate dùng chung Biến theo từng môi trường Workflow cụ thể cho từng môi trường File gom tổng cho chạy thực tế \u0026amp; chạy local 🧱 3.2. Định nghĩa job template .ci/job-template.yml 1 2 3 4 5 6 7 8 9 10 .job-base: stage: test tags: - dind script: - echo \u0026#34;ENV=$ENV\u0026#34; - echo \u0026#34;API_URL=$API_URL\u0026#34; variables: ENV: \u0026#34;local\u0026#34; API_URL: \u0026#34;http://localhost:3000\u0026#34; 📌 Ghi chú: Đây là template chính, định nghĩa các bước và biến mặc định.\nMọi job thực tế sẽ extends từ .job-base.\n⚙️ 3.3. Biến môi trường .ci/vars-dev.yml 1 2 3 4 .variables-dev: variables: ENV: \u0026#34;dev\u0026#34; API_URL: \u0026#34;https://api.dev.example.com\u0026#34; .ci/vars-local.yml 1 2 3 4 .variables-local: variables: ENV: \u0026#34;local\u0026#34; API_URL: \u0026#34;http://localhost:3000\u0026#34; .ci/vars-prod.yml 1 2 3 4 .variables-prod: variables: ENV: \u0026#34;prod\u0026#34; API_URL: \u0026#34;https://api.prod.example.com\u0026#34; 📌 Ghi chú: Tách biến theo từng môi trường giúp:\nKhông bị nhầm biến khi deploy Dễ test từng môi trường độc lập Linh hoạt mở rộng về sau (thêm qa, uat, v.v.) 🔁 3.4. Định nghĩa các job .ci/workflow-dev.yml 1 2 job-dev: extends: [.job-base, .variables-dev] .ci/workflow-prod.yml 1 2 job-prod: extends: [.job-base, .variables-prod] 📌 Ghi chú: Mỗi job được build bằng cách kế thừa job-base và biến riêng môi trường.\nGiúp cấu hình đơn giản, không lặp lại.\n📦 3.5. File include.yml 1 2 3 4 5 6 include: - local: \u0026#34;.ci/job-template.yml\u0026#34; - local: \u0026#34;.ci/vars-dev.yml\u0026#34; - local: \u0026#34;.ci/vars-prod.yml\u0026#34; - local: \u0026#34;.ci/workflow-dev.yml\u0026#34; - local: \u0026#34;.ci/workflow-prod.yml\u0026#34; 📌 Ghi chú: Gom tất cả file cần thiết cho pipeline GitLab CI chạy thực tế trên server.\nFile .gitlab-ci.yml chỉ cần include file này là đủ.\n🧪 3.7. Chạy test local 1 2 gitlab-runner exec shell .job-base --cicd-config-file .ci/job-template.yml 🛠️ Ghi chú:\nLệnh này sẽ chạy job .job-base bằng cấu hình trong file .ci/job-template.yml.\nCó thể chỉnh sửa nhanh script, biến, v.v. để test mà không ảnh hưởng pipeline thật.\n✅ 4. Kết Luận ✅ Ưu điểm đạt được ✔️ Dễ test local: → Test được từng job thông qua giá trị của biến môi trường (variable). ✔️ Quản lý môi trường rõ ràng: → Mỗi môi trường (dev, staging, prod,\u0026hellip;) có file biến riêng (vars-*.yml). ✔️ Dễ bảo trì \u0026amp; mở rộng: → Dùng job-base như template để tránh lặp lại, dễ mở rộng khi thêm job mới. ✔️ CI gọn nhẹ: → File .gitlab-ci.yml chính chỉ cần include một file tổng hợp. 🔧 Nguyên lý kỹ thuật phần mềm \u0026amp; Ứng dụng trong GitLab CI/CD Function/Module Reuse (Tái sử dụng hàm/module): → job-base hoạt động như một hàm dùng lại, các job chỉ cần extends để kế thừa cấu trúc. Encapsulation (Đóng gói): → Biến môi trường được đóng gói theo từng môi trường riêng biệt (vars-dev.yml, vars-prod.yml), giúp tránh rò rỉ hoặc ghi đè sai lệch. Composition over Inheritance (Thành phần hơn kế thừa): → Kết hợp job-base + file biến (.variables-*) cho phép tái sử dụng linh hoạt hơn là copy/paste hoặc kế thừa toàn bộ job. Separation of Concerns (Phân tách trách nhiệm): → Tách biệt từng thành phần CI/CD: Template job (job-template.yml) Biến môi trường (vars-*.yml) Luồng chính (.gitlab-ci.yml) → Mỗi file chỉ đảm nhận một vai trò duy nhất, dễ đọc và dễ debug. Unit Test / Test độc lập hàm: → Có thể test từng job độc lập trong job-template.yml như cách viết và test unit test trong lập trình. ","date":"2025-06-21T01:00:00Z","permalink":"https://phongthien99.github.io/posts/streamlining-deployment-with-gitlab-ci/cd/","title":"Streamlining Deployment with GitLab CI/CD"},{"content":"Guide to Running GitLab Runner Locally for Building and Testing CI/CD Pipelines Đặt Vấn Đề Trong quá trình phát triển phần mềm, việc kiểm thử và triển khai ứng dụng thường xuyên là điều không thể thiếu. Tuy nhiên, việc đợi pipeline CI/CD chạy trên GitLab server có thể mất thời gian, đặc biệt khi cần thử nghiệm nhanh các thay đổi nhỏ trong cấu hình hoặc script. Điều này làm giảm hiệu quả làm việc và gây khó khăn trong việc debug.\nGiải Pháp Chạy GitLab Runner ngay trên máy local là một giải pháp hiệu quả. Điều này cho phép bạn kiểm thử các job CI/CD một cách nhanh chóng mà không cần push code lên GitLab, từ đó tiết kiệm thời gian và giảm thiểu rủi ro phát sinh khi deploy lên môi trường thật.\nThực Hiện Bước 1: Cài Đặt GitLab Runner Đối với hệ điều hành Ubuntu, bạn có thể cài đặt GitLab Runner bằng cách chạy:\n1 2 3 curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash sudo apt-get install gitlab-runner=15.11.1 ⚠️ Lưu ý: Bạn có thể chọn phiên bản mới nhất hoặc giữ cố định một phiên bản ổn định tùy theo yêu cầu dự án.\nBước 2: Viết File gitlab-ci.yaml Đây là file định nghĩa pipeline. Dưới đây là ví dụ một job đơn giản dùng để build Docker image:\n1 2 3 4 5 6 7 8 9 10 image: docker:dind stages: - build build-image: stage: build tags: - shel script: - echo \u0026#34;Build image\u0026#34; Bước 4: Chạy GitLab Runner Local Khi đã có đầy đủ file cấu hình, bạn chỉ cần chạy lệnh sau để thực thi pipeline ngay trên máy:\n1 2 gitlab-runner exec docker build-image Lệnh này sẽ chạy job build-image bằng executor docker – tức là trực tiếp trên môi trường máy bạn, không cần đăng ký runner hay kết nối với GitLab server.\nKết Luận Việc chạy GitLab Runner cục bộ là một công cụ cực kỳ hữu ích trong quá trình phát triển phần mềm hiện đại. Nó giúp bạn kiểm thử nhanh pipeline, tiết kiệm thời gian debug, đảm bảo cấu hình chính xác trước khi đưa code lên môi trường CI/CD chính thức. Hãy tận dụng tính năng này để tối ưu hóa quy trình phát triển và nâng cao chất lượng phần mềm của bạn.\n","date":"2025-06-21T00:00:00Z","permalink":"https://phongthien99.github.io/posts/guide-to-running-gitlab-runner-locally-for-building-and-testing-ci/cd-pipelines/","title":"Guide to Running GitLab Runner Locally for Building and Testing CI/CD Pipelines"},{"content":"Hosting a Debian Repository on S3 using Reprepro and AWS CLI I. Đặt vấn đề Trong quá trình phát triển phần mềm, đặc biệt với hệ thống backend hoặc hạ tầng đóng gói nội bộ, việc phát hành các gói .deb nhanh chóng và có thể truy cập qua apt là một lợi thế rất lớn. Tuy nhiên, việc dựng hạ tầng riêng (như NGINX, APT server\u0026hellip;) có thể phức tạp, tốn chi phí và không dễ mở rộng.\nMột giải pháp hiệu quả, đơn giản hơn là: host repository Debian trực tiếp trên Amazon S3 và sử dụng reprepro để quản lý metadata.\nII. Cách giải quyết Chúng ta sẽ xây dựng một quy trình:\nTạo repo Debian chuẩn bằng reprepro. Cập nhật các gói .deb vào repo. Đồng bộ repo lên Amazon S3. Sinh ra file .list để client dễ cấu hình apt. Công cụ sử dụng: Công cụ Vai trò reprepro Tạo \u0026amp; quản lý cấu trúc Debian repo (conf/, pool/, dists/) aws s3 sync Đồng bộ thư mục repo lên Amazon S3 Shell Script Tự động hóa các bước thêm gói, build metadata, và đồng bộ hóa III. Thực hiện 1. update-repo.sh – Thêm .deb vào repository ✅ Nhiệm vụ: Kiểm tra và tạo cấu hình conf/distributions nếu chưa có. Thêm gói .deb vào đúng codename bằng reprepro. 🧩 Nội dung chính: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #!/bin/bash set -e REPO_DIR=\u0026#34;${REPO_DIR:-./repo}\u0026#34; # Thư mục chứa repo DEB_FILE=\u0026#34;$1\u0026#34; # File .deb đầu vào DIST=\u0026#34;$2\u0026#34; # Codename (vd: v1.0) ARCH=\u0026#34;${ARCH:-amd64}\u0026#34; COMPONENT=\u0026#34;${COMPONENT:-main}\u0026#34; if [[ -z \u0026#34;$DEB_FILE\u0026#34; || -z \u0026#34;$DIST\u0026#34; ]]; then echo \u0026#34;Usage: $0 path/to/package.deb \u0026lt;codename\u0026gt;\u0026#34; exit 1 fi if [[ ! -f \u0026#34;$DEB_FILE\u0026#34; ]]; then echo \u0026#34;❌ File not exist: $DEB_FILE\u0026#34; exit 2 fi mkdir -p \u0026#34;$REPO_DIR/conf\u0026#34; DIST_FILE=\u0026#34;$REPO_DIR/conf/distributions\u0026#34; if ! grep -q \u0026#34;Codename: $DIST\u0026#34; \u0026#34;$DIST_FILE\u0026#34; 2\u0026gt;/dev/null; then echo \u0026#34;➕ Adding new codename: $DIST\u0026#34; cat \u0026gt;\u0026gt; \u0026#34;$DIST_FILE\u0026#34; \u0026lt;\u0026lt;EOF Origin: LocalCompany Label: LocalRepo Codename: $DIST Architectures: $ARCH Components: $COMPONENT Description: Auto-generated distribution $DIST EOF fi echo \u0026#34;📦 Adding package: $DEB_FILE → codename: $DIST\u0026#34; reprepro -b \u0026#34;$REPO_DIR\u0026#34; includedeb \u0026#34;$DIST\u0026#34; \u0026#34;$DEB_FILE\u0026#34; echo \u0026#34;✅ Completed!\u0026#34; 🛠️ Cách chạy: 1 2 ./update-repo.sh ./incoming/myapp_1.0.0.deb v1.0 2. generate-sources-list.sh – Tạo file sources.list cho client ✅ Nhiệm vụ: Duyệt file conf/distributions để lấy danh sách các Codename và Component. Sinh ra dòng cấu hình repo chuẩn cho apt. 🧩 Nội dung chính: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash REPO_URL=${1:-\u0026#34;http://localhost/repo\u0026#34;} # URL repo OUTPUT=${2:-\u0026#34;localrepo.list\u0026#34;} # Tên file output DISTRIBUTIONS_FILE=\u0026#34;repo/conf/distributions\u0026#34; \u0026gt; \u0026#34;$OUTPUT\u0026#34; # Clear file grep -E \u0026#39;^Codename:\u0026#39; \u0026#34;$DISTRIBUTIONS_FILE\u0026#34; | awk \u0026#39;{print $2}\u0026#39; | while read -r codename; do component=$(grep -A 10 \u0026#34;Codename: $codename\u0026#34; \u0026#34;$DISTRIBUTIONS_FILE\u0026#34; | grep -E \u0026#39;^Components:\u0026#39; | awk \u0026#39;{$1=\u0026#34;\u0026#34;; print $0}\u0026#39; | xargs -n1 | sort -u | xargs) if [[ -n \u0026#34;$component\u0026#34; ]]; then echo \u0026#34;deb [trusted=yes,arch=amd64] $REPO_URL $codename $component\u0026#34; \u0026gt;\u0026gt; \u0026#34;$OUTPUT\u0026#34; else echo \u0026#34;⚠️ Warning: No components found for Codename: $codename\u0026#34; fi done echo \u0026#34;✅ File $OUTPUT created:\u0026#34; cat \u0026#34;$OUTPUT\u0026#34; 🛠️ Cách chạy: 1 2 ./generate-sources-list.sh https://my-s3-bucket.s3.amazonaws.com/repo my-repo.list File output my-repo.list có dạng:\n1 2 deb [trusted=yes,arch=amd64] https://my-s3-bucket.s3.amazonaws.com/repo v1.0 main 3. publish.sh – Đồng bộ hóa toàn bộ repo lên S3 ✅ Nhiệm vụ: Lấy cấu hình từ S3 về local. Duyệt và thêm tất cả file .deb hiện có vào repo. Xóa repo/db để tránh sync dữ liệu cache không cần thiết. Sync toàn bộ repo lên S3. Tạo file .list và upload nó lên S3. 🧩 Nội dung chính: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash set -e S3_BUCKET=\u0026#34;$1\u0026#34; REPO_NAME=\u0026#34;$2\u0026#34; VERSION=\u0026#34;$3\u0026#34; PUBLIC_HOST_URL=\u0026#34;$4\u0026#34; if [[ -z \u0026#34;$S3_BUCKET\u0026#34; || -z \u0026#34;$REPO_NAME\u0026#34; || -z \u0026#34;$VERSION\u0026#34; || -z \u0026#34;$PUBLIC_HOST_URL\u0026#34; ]]; then echo \u0026#34;Usage: $0 \u0026lt;S3_BUCKET\u0026gt; \u0026lt;REPO_NAME\u0026gt; \u0026lt;VERSION\u0026gt; \u0026lt;PUBLIC_HOST_URL\u0026gt;\u0026#34; exit 1 fi aws s3 sync s3://$S3_BUCKET/repo/conf ./repo/conf --exact-timestamps for file in ./*.deb; do ./update-repo.sh \u0026#34;$file\u0026#34; \u0026#34;$VERSION\u0026#34; done rm -rf ./repo/db aws s3 sync ./repo s3://$S3_BUCKET/repo ./generate-sources-list.sh \u0026#34;$PUBLIC_HOST_URL\u0026#34; \u0026#34;$REPO_NAME.list\u0026#34; aws s3 cp ./$REPO_NAME.list s3://$S3_BUCKET/source/$REPO_NAME.list 🛠️ Cách chạy: 1 ./publish.sh my-s3-bucket my-repo v1.0 https://my-s3-bucket.s3.amazonaws.com/repo 4. Thử nghiêm Client có thể cấu hình APT như sau:\n1 2 3 sudo curl -o /etc/apt/sources.list.d/my-repo.list https://my-s3-bucket.s3.amazonaws.com/source/my-repo.list sudo apt update V. Kết luận Việc sử dụng reprepro kết hợp với S3 là một giải pháp:\nNhẹ, đơn giản Không cần web server Dễ tích hợp CI/CD ","date":"2025-06-14T00:00:00Z","permalink":"https://phongthien99.github.io/posts/hosting-a-debian-repository-on-s3-using-reprepro-and-aws-cli/","title":"Hosting a Debian Repository on S3 using Reprepro and AWS CLI"},{"content":"Đặt Vấn Đề Khi làm việc với các hệ thống lớn sử dụng MongoDB, việc quản lý migration dữ liệu (tạo collection, thêm field, thay đổi schema logic\u0026hellip;) thường không được quan tâm đúng mức. Điều này dẫn đến:\nDữ liệu thiếu đồng nhất giữa các môi trường. Khó rollback hoặc kiểm soát phiên bản dữ liệu. Không theo kịp tốc độ phát triển CI/CD khi cần thay đổi schema thường xuyên. Cách Giải Quyết Flyway gần đây đã hỗ trợ MongoDB thông qua các JavaScript-based migration. Dù MongoDB là NoSQL, ta vẫn có thể định nghĩa các thao tác migration dưới dạng .js file (giống shell script của MongoDB) và quản lý bằng Flyway như:\nGhi log migration vào collection. Chạy tuần tự từng script. Cho phép rollback bằng cách viết script ngược lại. Trong bài viết này, ta sẽ triển khai Flyway sử dụng Docker để migrate MongoDB.\nThực Hiện 1. Cấu Trúc Thư Mục 1 2 3 4 5 6 ├── docker-compose.yml ├── config.cfg # Cấu hình Flyway └── migrations/ ├── V1__init_collection.js └── V2__add_index.js 2. Nội Dung docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#39;3.8\u0026#39; services: flyway: image: redgate/flyway entrypoint: [\u0026#34;\u0026#34;] command: \u0026gt; sh -c \u0026#34;flyway migrate \u0026amp;\u0026amp; flyway info\u0026#34; volumes: - ./migrations:/migrations - ./config.cfg:/flyway/conf/flyway.conf # environment: # - FLYWAY_NATIVE_CONNECTORS=true networks: - traefik-ingress volumes: flyway_data: networks: traefik-ingress: external: true # Sử dụng mạng traefik đã được tạo sẵn Lưu ý: entrypoint: [\u0026quot;\u0026quot;] để bỏ entrypoint mặc định trong image redgate/flyway.\n3. Cấu Hình config.cfg 1 2 3 4 5 6 7 8 flyway.url=xxx flyway.user=xxx flyway.password=xxx flyway.schemas=xxx flyway.baselineOnMigrate=true flyway.sqlMigrationSuffixes=.js flyway.locations=filesystem:/migrations Flyway sẽ tìm các file .js trong thư mục /migrations và chạy theo thứ tự V1__\u0026hellip;, V2__\u0026hellip;,\u0026hellip;\n4. Ví Dụ Migration Script migrations/V1__init_collection.js\n1 2 3 4 5 db.createCollection(\u0026#34;videos\u0026#34;); db.videos.insertOne({ title: \u0026#34;Flyway Introduction\u0026#34;, uploaded_at: new Date() }); migrations/V2__add_index.js\n1 db.videos.createIndex({ title: 1 }, { unique: true }); 5. Chạy Migration 1 docker compose up Flyway sẽ:\nKết nối tới MongoDB . Tìm và chạy các file .js chưa được áp dụng. Log thông tin migration (tên file, thời gian, trạng thái). Kết Luận Việc sử dụng Flyway với MongoDB là một bước tiến giúp chuẩn hóa việc migration dữ liệu NoSQL, vốn trước đây chủ yếu là thủ công. Với Flyway, bạn có thể:\n✅ Kiểm soát được lịch sử migration\n✅ Dễ dàng tích hợp vào CI/CD pipelines\n✅ Giảm thiểu rủi ro khi deploy schema/data changes\nViệc chạy Flyway qua Docker còn giúp môi trường dev/test dễ dàng tiếp cận và cấu hình nhất quán. Với những hệ thống cần tính ổn định và có quy trình release chặt chẽ, đây là lựa chọn nên cân nhắc.\n","date":"2025-06-08T00:00:00Z","permalink":"https://phongthien99.github.io/posts/migration-mongodb-with-flyway/","title":"Migration MongoDB With Flyway"},{"content":"Effective Management of Multiple Kubernetes Environments with Helmfile 1. Đặt Vấn Đề Khi sử dụng Helm để triển khai ứng dụng lên Kubernetes, bạn sẽ sớm nhận ra một số vấn đề phổ biến:\n🔁 Cần quản lý nhiều chart cho các dịch vụ khác nhau. 🌍 Cần giữ cấu hình nhất quán giữa các môi trường (dev, staging, production). ⚙️ Cần khả năng diff trước khi deploy, cập nhật đồng loạt dễ kiểm soát. Việc dùng Helm thuần (helm install, helm upgrade) cho từng chart rất thủ công, dễ lỗi và khó mở rộng khi team hoặc dự án lớn lên.\n2. Giải Pháp: Helmfile – Helm For The Real World Helmfile là một công cụ mã nguồn mở giúp bạn quản lý nhiều Helm chart một cách có tổ chức và nhất quán giữa các môi trường.\n🔍 Tính năng nổi bật: 📦 Triển khai nhiều Helm chart với một file YAML duy nhất. 🌐 Hỗ trợ đa môi trường (dev, staging, production, v.v.). 🔄 Tích hợp sẵn diff, template, sync, apply — cực kỳ tiện cho CI/CD và GitOps. 🧠 Hỗ trợ biến động (env), template Go, kế thừa giá trị cấu hình, dễ tái sử dụng. 3. Hiện Thực Hóa: Cài Đặt Và Sử Dụng Helmfile 🔧 Script Cài Đặt Helmfile Mới Nhất 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/bin/bash set -e # Lấy phiên bản mới nhất từ GitHub API LATEST_VERSION=$(curl -s https://api.github.com/repos/helmfile/helmfile/releases/latest | grep \u0026#39;\u0026#34;tag_name\u0026#34;:\u0026#39; | sed -E \u0026#39;s/.*\u0026#34;([^\u0026#34;]+)\u0026#34;.*/\\1/\u0026#39;) echo \u0026#34;Phiên bản helmfile mới nhất: $LATEST_VERSION\u0026#34; # Tạo tên file tải về FILE_TAR=\u0026#34;helmfile_${LATEST_VERSION#v}_linux_amd64.tar.gz\u0026#34; # URL tải về DOWNLOAD_URL=\u0026#34;https://github.com/helmfile/helmfile/releases/download/${LATEST_VERSION}/${FILE_TAR}\u0026#34; echo \u0026#34;URL tải về: $DOWNLOAD_URL\u0026#34; # Tải file tar.gz curl -LO \u0026#34;$DOWNLOAD_URL\u0026#34; # Giải nén tar -xzf \u0026#34;$FILE_TAR\u0026#34; # Cấp quyền thực thi và di chuyển chmod +x helmfile sudo mv helmfile /usr/local/bin/ # Xóa file tar.gz rm \u0026#34;$FILE_TAR\u0026#34; # Kiểm tra phiên bản echo \u0026#34;Cài đặt thành công. Phiên bản helmfile hiện tại:\u0026#34; helmfile --version 📁 Cấu Trúc Thư Mục Helmfile Nhiều Môi Trường 1 2 3 4 5 6 7 8 9 10 11 12 . ├── helmfile.yaml ├── environments/ │ ├── dev.yaml │ ├── staging.yaml │ └── production.yaml ├── values/ │ └── shared-values.yaml └── charts/ ├── redis/ └── my-app/ 4. Triển Khai Nhiều Môi Trường Với Helmfile 🧩 helmfile.yaml Mẫu 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 environments: dev: values: - environments/dev.yaml staging: values: - environments/staging.yaml production: values: - environments/production.yaml --- releases: - name: redis namespace: {{ .Environment.Name }} chart: charts/redis values: - values/shared-values.yaml - name: my-app namespace: {{ .Environment.Name }} chart: charts/my-app needs: - redis values: - values/shared-values.yaml - environments/{{ .Environment.Name }}.yaml 📌 Lưu ý: dùng \u0026mdash; để phân tách environments: và releases: đúng cú pháp Helmfile.\n📄 Ví Dụ File environments/dev.yaml 1 2 3 4 replicaCount: 1 image: tag: dev-latest 🚀 Lệnh Triển Khai Theo Môi Trường 1 2 3 4 5 bash CopyEdit helmfile -e dev apply # Triển khai môi trường dev helmfile -e staging diff # Xem diff môi trường staging helmfile -e production apply # Triển khai production 5. Kết Luận Helmfile là trợ thủ đắc lực nếu bạn đang triển khai ứng dụng với nhiều dịch vụ và môi trường:\n✅ Giảm rủi ro khi deploy thủ công ✅ Quản lý môi trường rõ ràng, tách biệt ✅ Tích hợp CI/CD dễ dàng ✅ Hỗ trợ đầy đủ triết lý GitOps ","date":"2025-06-01T00:00:00Z","permalink":"https://phongthien99.github.io/posts/effective-management-of-multiple-kubernetes-environments-with-helmfile/","title":"Effective Management of Multiple Kubernetes Environments with Helmfile"},{"content":"Guide to Installing and Deploying Helm Chart from a Git Repository Trong bài viết này, chúng ta sẽ tìm hiểu cách sử dụng plugin helm-git để cài đặt và triển khai Helm chart trực tiếp từ Git repository. Cách làm này giúp bạn linh hoạt hơn trong việc quản lý các chart, đặc biệt khi cần triển khai từ nguồn Git riêng thay vì Helm repository thông thường. Bài viết sẽ hướng dẫn từ bước cài đặt plugin, thêm Git repo, chỉ định phiên bản chart với ref, cho đến cách sử dụng đường dẫn @charts/....\n🔧 Bước 1: Cài Đặt Plugin helm-git Plugin helm-git giúp Helm xử lý Git repository như một nguồn Helm chart. Để cài đặt, chạy lệnh sau:\n1 2 helm plugin install https://github.com/aslafy-z/helm-git --version 1.3.0 💡 Nếu plugin đã được cài trước đó, bạn có thể thêm \u0026ndash;force để cài lại:\n1 2 helm plugin install https://github.com/aslafy-z/helm-git --version 1.3.0 --force 🗂️ Bước 2: Thêm Helm Repository Từ Git Trước khi thêm repo mới, bạn nên xóa repo cũ nếu cần để tránh xung đột:\n1 2 helm repo remove cert-manager || true Thêm repository Helm từ Git bằng cú pháp:\n1 2 helm repo add cert-manager git+https://github.com/jetstack/cert-manager@deploy/charts?ref=v0.6.2 ✅ Giải Thích Tham Số: @deploy/charts: Chỉ định đường dẫn đến thư mục chart con trong repo Git. ref=v0.6.2: Chỉ định phiên bản cụ thể — có thể là tag, branch hoặc commit hash. 🚀 Bước 3: Cài Đặt hoặc Cập Nhật Helm Chart Giờ bạn có thể triển khai chart từ repo Git bằng lệnh:\n1 2 3 4 5 helm upgrade --install cert-manager cert-manager/cert-manager \\ -f prod-values.yaml \\ -n cert-manager \\ --create-namespace 🔍 Giải Thích Tham Số: upgrade --install: Cài đặt nếu chưa có, hoặc nâng cấp nếu đã tồn tại. f prod-values.yaml: Sử dụng file cấu hình cho môi trường production. n cert-manager: Chạy trong namespace cert-manager. -create-namespace: Tạo namespace nếu chưa tồn tại. ✅ Kết Luận Plugin helm-git mở rộng khả năng triển khai Helm chart từ Git, giúp bạn dễ dàng kiểm soát phiên bản, đặc biệt khi cần thử nghiệm các phiên bản cụ thể hoặc chưa được publish lên Helm repo. Việc sử dụng tham số ref và chỉ định đường dẫn chart con (@...) giúp bạn triển khai chính xác phiên bản mong muốn một cách an toàn và linh hoạt.\n","date":"2025-04-30T10:40:00+08:00","permalink":"https://phongthien99.github.io/posts/guide-to-installing-and-deploying-helm-chart-from-a-git-repository/","title":"Guide to Installing and Deploying Helm Chart from a Git Repository"},{"content":"Lightweight and Fast Real-Time Log Viewer Đặt Vấn Đề Trong quá trình vận hành hệ thống, việc nhanh chóng tra cứu log để xác định lỗi hoặc xác minh các sự kiện là cực kỳ quan trọng\nThông thường, chúng ta hay sử dụng các lệnh như:\n1 2 3 tail -f /var/log/server.log | grep -E \u0026#34;ERROR|WARN\u0026#34; grep -i \u0026#34;timeout\u0026#34; /var/log/server.log grep -E \u0026#34;ERROR|WARN\u0026#34; /var/log/server.log Tuy nhiên, cách làm này tồn tại nhiều hạn chế:\nPhải SSH vào server. Phải thao tác thủ công, mất thời gian. Khó theo dõi realtime với nhiều server hoặc nhiều file log. Hạn chế khả năng lọc, tìm kiếm nâng cao hoặc lưu trữ kết quả. Giải Pháp Xây dựng một hệ thống xem log trực tiếp từ trình duyệt, hỗ trợ:\nTìm kiếm từ khóa nhanh chóng. Lọc log nâng cao. Xem realtime trên nhiều file log. Công Nghệ Sử Dụng Promtail: Thu thập log từ file hệ thống. VictoriaLogs: Lưu trữ và phục vụ truy vấn log với hiệu suất cao. Hướng Dẫn Triển Khai Chi Tiết Hệ thống triển khai trên môi trường Ubuntu để theo dõi log của Sigma Media Server, với các file log có pattern: /var/log/sigma-machine/now.*\n1. Cài Đặt và Cấu Hình VictoriaLogs Bước 1: Tải và Cài Đặt VictoriaLogs 1 2 3 4 5 wget https://github.com/VictoriaMetrics/VictoriaMetrics/releases/download/v1.21.0-victorialogs/victoria-logs-linux-amd64-v1.21.0-victorialogs.tar.gz tar -xzf victoria-logs-linux-amd64-v1.21.0-victorialogs.tar.gz chmod +x victoria-logs-prod sudo mv victoria-logs-prod /usr/local/bin/victoria-logs sudo mkdir /var/lib/victorialogs-data Bước 2: Tạo service cho VictoriaLogs Tạo file /etc/systemd/system/victorialogs.service với nội dung:\n1 2 3 4 5 6 7 8 9 10 11 12 13 [Unit] Description=VictoriaLogs Service After=network.target [Service] User=root Group=root ExecStart=/usr/local/bin/victoria-logs --storageDataPath=/var/lib/victorialogs-data Restart=always RestartSec=5 [Install] WantedBy=multi-user.target Bước 3: Khởi Động VictoriaLogs 1 2 3 sudo systemctl daemon-reload sudo systemctl enable victorialogs sudo systemctl start victorialogs VictoriaLogs sẽ lắng nghe trên port 9428, lưu dữ liệu tại /var/lib/victorialogs-data.\n2. Cài Đặt và Cấu Hình Promtail Bước 1: Tải và Cài Đặt Promtail 1 2 3 4 wget https://github.com/grafana/loki/releases/latest/download/promtail-linux-amd64.zip unzip promtail-linux-amd64.zip chmod +x promtail-linux-amd64 sudo mv promtail-linux-amd64 /usr/local/bin/promtail Bước 2: Tạo File Cấu Hình Promtail Tạo thư mục và file cấu hình:\n1 2 mkdir -p /etc/promtail touch /etc/promtail/promtal-config.yaml Nội dung /etc/promtail/promtail-config.yaml:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 server: http_listen_port: 9080 grpc_listen_port: 0 positions: filename: /tmp/positions.yaml clients: - url: http://localhost:9428/insert/loki/api/v1/push scrape_configs: - job_name: sigma_media_server_logs static_configs: - targets: - localhost labels: job: sigma __path__: /var/log/sigma-machine/now.* Bước 3: Tạo service cho Promtail Tạo file /etc/systemd/system/promtail.service với nội dung:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [Unit] Description=Promtail Service After=network.target [Service] User=root Group=root ExecStart=/usr/local/bin/promtail -config.file=/etc/promtail/promtail-config.yaml Restart=always RestartSec=5 [Install] WantedBy=multi-user.target Bước 4: Khởi Động Promtail 1 2 3 4 sudo systemctl daemon-reload sudo systemctl enable promtail sudo systemctl start promtail Xem và Truy Vấn Log Qua Trình Duyệt Giờ đây, bạn có thể mở trình duyệt và truy cập địa chỉ:\n1 2 http://localhost:9428 Một số ví dụ truy vấn log:\nTìm kiếm log với từ khóa: 1 2 {filename=\u0026#34;/var/log/sigma-machine/now.sys\u0026#34;} |~ \u0026#34;(?i)dataDir\u0026#34; Giải thích:\n|~ dùng để lọc theo regex. (?i) trong regex là bật chế độ ignore case (không phân biệt hoa thường). \u0026quot;dataDir\u0026quot; là từ khóa bạn tìm. Kết Luận Với giải pháp này, bạn có thể:\nTruy cập log mọi lúc, mọi nơi mà không cần SSH vào server. Tìm kiếm và lọc log nhanh chóng. Theo dõi realtime nhiều file log từ server. Dễ dàng mở rộng và tích hợp với các hệ thống phân tích log hoặc cảnh báo chuyên sâu trong tương lai. ","date":"2025-04-27T12:40:00+08:00","permalink":"https://phongthien99.github.io/posts/lightweight-and-fast-real-time-log-viewer/","title":"Lightweight and Fast Real-Time Log Viewer"},{"content":"Deploying Sigma Media Server with Ansible Trong bài viết này, chúng ta sẽ cùng nhau triển khai Sigma Media Server lên máy chủ từ xa thông qua Ansible — công cụ tự động hóa cấu hình và triển khai phần mềm phổ biến. Bằng cách sử dụng Ansible, bạn có thể tự động hóa quá trình cài đặt và cấu hình phần mềm trên nhiều máy chủ, giúp tiết kiệm thời gian và giảm thiểu lỗi.\n1. Cấu Trúc Dự Án Dự án được tổ chức theo chuẩn Ansible Role, giúp mã dễ bảo trì và mở rộng. Cấu trúc thư mục của dự án như sau:\n1 2 3 4 5 6 7 8 9 10 devops ├── inventory.ini ├── playbook.yml └── roles └── sigma/ ├── handlers/ │ └── main.yml └── tasks/ └── main.yml inventory.ini: Định nghĩa các máy chủ mục tiêu và thông tin kết nối. playbook.yml: Playbook chính chứa các bước triển khai. roles/sigma/handlers/main.yml: Định nghĩa các hành động cần thực hiện sau khi có thay đổi. roles/sigma/tasks/main.yml: Các task thực thi như cài đặt phần mềm, cấu hình hệ thống. 2. File inventory.ini Đây là nơi khai báo máy chủ đích (target host), nơi mà Ansible sẽ thực hiện các thao tác từ xa. Nội dung file inventory.ini như sau:\n1 2 3 [sigma_servers] 172.16.60.123 ansible_user=dev ansible_password= ansible_become=true ansible_user: tài khoản đăng nhập từ xa. ansible_password: mật khẩu đăng nhập. ansible_become: cho phép nâng quyền sudo nếu cần. 3. File playbook.yml Playbook chính mô tả quá trình triển khai, bao gồm các tác vụ từ việc cài đặt phần mềm cho đến khởi động dịch vụ. Nội dung file playbook.yml như sau:\n1 2 3 4 5 6 - name: Deploy Sigma Media Server hosts: sigma_servers become: yes roles: - sigma Playbook này sẽ áp dụng toàn bộ vai trò sigma lên nhóm máy chủ sigma_servers.\n4. Tác vụ triển khai (roles/sigma/tasks/main.yml) Trong phần này, các tác vụ chính được định nghĩa để cài đặt Sigma Media Server và thực hiện các thao tác cần thiết như thêm repository, cài đặt gói phần mềm, và ghi nhận phiên bản.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 --- - name: Download Sigma software repository configuration file get_url: url: https://repo.sigma.video/debian/sigma-media-server.list dest: /etc/apt/sources.list.d/sigma-media-server.list mode: \u0026#39;0644\u0026#39; - name: Update apt package list apt: update_cache: yes cache_valid_time: 3600 - name: Install Sigma Media Server apt: name: sigma-media-server state: present changed_when: true notify: - Start Sigma Media Server service - Query Sigma Media Server API - Show version running - name: Create certificate directory if not exists file: path: /etc/pki/tls/certs state: directory mode: \u0026#39;0755\u0026#39; - name: Copy CA certificates copy: src: /etc/ssl/certs/ca-certificates.crt dest: /etc/pki/tls/certs/ca-bundle.crt mode: \u0026#39;0644\u0026#39; backup: yes - name: Get installed version of Sigma Media Server command: dpkg -s sigma-media-server register: sigma_version_info changed_when: false - name: Log version debug: msg: \u0026gt;- sigma-media-server: {{ sigma_version_info.stdout_lines | select(\u0026#39;search\u0026#39;, \u0026#39;^Version:\u0026#39;) | map(\u0026#39;regex_replace\u0026#39;, \u0026#39;^Version \\\\s*\u0026#39;, \u0026#39;\u0026#39;) | first }} Tóm lược các bước:\nThêm repo Sigma vào hệ thống. Cập nhật danh sách gói (apt update). Cài đặt sigma-media-server. Kiểm tra và copy CA vào thư mục phục vụ cho hệ thống. Ghi nhận phiên bản của phần mềm Sigma đã cài đặt. 5. Handler khởi động và kiểm tra (roles/sigma/handlers/main.yml) Sau khi các task có thay đổi, handler sẽ thực hiện các hành động như khởi động lại dịch vụ và kiểm tra trạng thái API của Sigma. Nội dung file handlers/main.yml như sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 - name: Start Sigma Media Server service systemd: name: sigma-media-server state: started enabled: true - name: Query Sigma Media Server API uri: url: http://localhost:9999 method: GET return_content: yes status_code: 200 register: sigma_api_response retries: 5 delay: 2 until: sigma_api_response.status == 200 - name: Show version running debug: msg: \u0026#34;Sigma Media Server run version: {{ sigma_api_response.json.version }}\u0026#34; Mối Quan Hệ Giữa notify và handler Trong Ansible, notify và handler có mối quan hệ mật thiết, hỗ trợ quá trình tự động hóa một cách hiệu quả.\nnotify là thuộc tính trong các task, dùng để thông báo cho Ansible khi có thay đổi. Khi một task thay đổi trạng thái (ví dụ: cài đặt thành công), nó sẽ \u0026ldquo;thông báo\u0026rdquo; cho các handler đã được chỉ định trong phần notify của task. handler là các tác vụ đặc biệt được định nghĩa trong phần handlers. Chúng chỉ được thực thi khi có sự \u0026ldquo;thông báo\u0026rdquo; từ task. Handler thường được sử dụng để thực hiện các thao tác như khởi động lại dịch vụ, kiểm tra trạng thái hệ thống, hoặc các hành động bổ sung khác mà chỉ cần thực thi khi có thay đổi. Ví dụ trong bài viết:\nKhi task cài đặt sigma-media-server thành công, các handler sẽ được thông báo và thực thi: Start Sigma Media Server service: Khởi động dịch vụ Sigma. Query Sigma Media Server API: Kiểm tra xem API của Sigma có đang hoạt động chính xác không. Show version running: In ra phiên bản của Sigma Media Server hiện đang chạy. Nhờ vào cơ chế notify và handler, các tác vụ bổ sung chỉ được thực thi khi có sự thay đổi thực sự, giúp tiết kiệm tài nguyên và giảm thiểu việc thực thi không cần thiết.\n6. Triển Khai Thực Tế Sau khi cấu hình xong, bạn có thể chạy lệnh dưới đây để triển khai:\n1 ansible-playbook -i inventory.ini playbook.yml --ask-pass --ask-become-pass - i inventory.ini: Chỉ định tệp inventory chứa thông tin máy chủ đích. playbook.yml: Chỉ định tệp playbook chứa các task cần thực hiện. -ask-pass: Yêu cầu nhập mật khẩu để kết nối SSH đến máy chủ đích. -ask-become-pass: Yêu cầu nhập mật khẩu sudo để thực hiện các tác vụ yêu cầu quyền quản trị. Nếu thiết lập đúng, hệ thống sẽ cài đặt và khởi động Sigma Media Server, đồng thời in ra phiên bản đang chạy.\nKết Luận Với việc đóng gói cấu hình Ansible thành role sigma, bạn có thể dễ dàng:\nTự động hóa triển khai trên nhiều máy chủ. Kiểm tra trạng thái hoạt động dịch vụ. Ghi lại version nhằm phục vụ giám sát và audit. ","date":"2025-04-20T12:40:00+08:00","permalink":"https://phongthien99.github.io/posts/deploying-sigma-media-server-with-ansible/","title":"Deploying Sigma Media Server with Ansible"},{"content":"Monkey Patch In TypeScript Trong quá trình phát triển ứng dụng, đôi lúc bạn muốn thêm một method mới vào class có sẵn – đặc biệt khi class đó đến từ thư viện bên ngoài hoặc framework, và bạn không thể sửa trực tiếp mã nguồn gốc.\nGiải pháp? 👉 Monkey patch.\nTuy nhiên, monkey patch nếu dùng không cẩn thận dễ gây ra:\nGhi đè nhầm method Gây xung đột trong nhiều nơi cùng patch Khó trace bug vì method \u0026ldquo;tự nhiên mà có\u0026rdquo; Trong bài viết này, mình sẽ hướng dẫn cách monkey patch một cách có kiểm soát, rõ ràng, và tương thích TypeScript.\n❓ Monkey Patch Là Gì? Monkey patch là kỹ thuật cho phép bổ sung hoặc ghi đè method vào prototype của class đang tồn tại.\nVí dụ:\n1 2 3 4 UserService.prototype.countActiveUsers = function () { return 42; }; Cách này đơn giản nhưng rủi ro cao. Vậy nên, ta sẽ xây dựng một tiện ích nhỏ để làm việc này an toàn hơn.\n🧱 Tạo Hàm patchService() – Monkey Patch Có Kiểm Soát 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // patchService.ts type PatchMap\u0026lt;T\u0026gt; = { [K in keyof Partial\u0026lt;T\u0026gt;]: T[K]; }; const globalPatchFlag = Symbol.for(\u0026#39;__patched_methods__\u0026#39;); export function patchService\u0026lt;T extends object\u0026gt;( target: { prototype: T }, methods: PatchMap\u0026lt;T\u0026gt;, ) { if (!(target.prototype as any)[globalPatchFlag]) { (target.prototype as any)[globalPatchFlag] = new Set\u0026lt;string\u0026gt;(); } const patched: Set\u0026lt;string\u0026gt; = (target.prototype as any)[globalPatchFlag]; for (const [key, fn] of Object.entries(methods)) { if (patched.has(key)) { console.warn(`[patchService] Bỏ qua vì đã patch: ${key}`); continue; } if (typeof fn === \u0026#39;function\u0026#39;) { if (key in target.prototype) { console.warn(`[patchService] Ghi đè method đã có: ${key}`); } (target.prototype as any)[key] = fn; patched.add(key); } } } 📦 Định Nghĩa Class Gốc UserService 1 2 3 4 5 6 7 8 9 // user.service.ts export class UserService { private name = \u0026#39;DemoService\u0026#39;; sayHello() { return `Hello from ${this.name}`; } } 🔧 Thêm Method Mới Bằng Patch 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // user-patch.ts import { patchService } from \u0026#39;./patchService\u0026#39;; import { UserService } from \u0026#39;./user.service\u0026#39;; // Mở rộng interface với TypeScript declare module \u0026#39;./user.service\u0026#39; { interface UserService { countActiveUsers(): Promise\u0026lt;number\u0026gt;; } } // Patch method mới patchService(UserService, { async countActiveUsers(this: UserService): Promise\u0026lt;number\u0026gt; { return 42; // Trả về số cố định cho demo }, }); 🚀 Chạy Thử 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // main.ts import \u0026#39;./user-patch\u0026#39;; import { UserService } from \u0026#39;./user.service\u0026#39;; async function main() { const service = new UserService(); console.log(service.sayHello()); // ✅ method gốc const count = await service.countActiveUsers(); // ✅ method mới console.log(\u0026#39;Số user active:\u0026#39;, count); // Kết quả: Số user active: 42 } main(); ✅ Kết Quả Khi Chạy 1 2 3 Hello from DemoService Số user active: 42 ✨ Lợi Ích Khi Dùng patchService() Tính năng Lợi ích 🧠 Gắn cờ đã patch Tránh patch lặp lại 🧾 Có log rõ ràng Dễ debug 🔒 Kiểm soát ghi đè Giảm rủi ro 🧩 Hỗ trợ interface mở rộng Tương thích hoàn toàn TypeScript 📌 Kết Luận Monkey patch không phải là kỹ thuật nên lạm dụng, nhưng khi dùng đúng cách, bạn có thể mở rộng hệ thống mà không cần sửa class gốc. Với patchService(), bạn có thể:\nBổ sung method một cách rõ ràng Kiểm soát và hạn chế xung đột Viết TypeScript chuẩn, dễ maintain về sau Hãy xem monkey patch như một con dao sắc – dùng đúng lúc, đúng chỗ, sẽ cực kỳ hữu dụng.\n","date":"2025-04-06T00:00:00+08:00","permalink":"https://phongthien99.github.io/posts/monkey-patch-in-typescript/","title":"Monkey Patch In TypeScript"},{"content":"Implementing i18n in NestJS Using In-Memory Storage 1. Giới thiệu Quốc tế hóa (i18n) là một phần quan trọng trong việc phát triển ứng dụng đa ngôn ngữ. Trong bài viết này, chúng ta sẽ tìm hiểu cách triển khai i18n trong NestJS sử dụng in-memory storage thay vì tải dữ liệu từ file JSON hoặc database.\n2. Cài đặt NestJS và các thư viện cần thiết Trước tiên, bạn cần có một dự án NestJS. Nếu chưa có, bạn có thể tạo mới bằng lệnh:\n1 2 npx @nestjs/cli new my-nestjs-app cd my-nestjs-app Cài đặt thư viện nestjs-i18n để hỗ trợ i18n:\n1 npm install --save @nestjs/i18n 3. Cấu hình i18n với In-Memory Storage 3.1. Tạo I18nMemoryLoader Chúng ta sẽ tạo một loader để lưu trữ bản dịch trong bộ nhớ:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import { Inject } from \u0026#39;@nestjs/common\u0026#39;; import { I18N_LOADER_OPTIONS, I18nLoader, I18nTranslation } from \u0026#39;nestjs-i18n\u0026#39;; export class I18nMemoryLoader extends I18nLoader { private readonly _translations: I18nTranslation; private readonly _languages: string[]; constructor( @Inject(I18N_LOADER_OPTIONS) private options: any, ) { super(); const mergeI18n = (...objects) =\u0026gt; { return objects.reduce((acc, obj) =\u0026gt; { Object.keys(obj).forEach((lang) =\u0026gt; { acc[lang] = { ...(acc[lang] || {}), ...obj[lang] }; }); return acc; }, {}); }; this._translations = mergeI18n(...options.translations); this._languages = Object.keys(this._translations); } async load(): Promise\u0026lt;I18nTranslation\u0026gt; { return this._translations; } async languages(): Promise\u0026lt;string[]\u0026gt; { return this._languages; } } 3.2. Tạo I18nMemoryModule Chúng ta sẽ tạo một module để sử dụng loader này và hỗ trợ thêm bản dịch từ từng module riêng:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import { DynamicModule, Module } from \u0026#39;@nestjs/common\u0026#39;; import { I18nAsyncOptions, I18nModule, I18nTranslation } from \u0026#39;nestjs-i18n\u0026#39;; import { I18nMemoryLoader } from \u0026#39;./i18n-memory\u0026#39;; const I18nTranslationFactory = \u0026#39;I18nTranslationFactory\u0026#39;; @Module({}) export class I18nMemoryModule { private static translations: I18nTranslation[] = []; static forRootAsync(options: I18nAsyncOptions): DynamicModule { options.inject = [I18nTranslationFactory]; options.loader = I18nMemoryLoader; return { module: I18nMemoryModule, imports: [I18nModule.forRootAsync(options)], }; } static forFeature(translation: I18nTranslation): DynamicModule { I18nMemoryModule.translations.push(translation); return { module: I18nMemoryModule, global: true, providers: [ { provide: I18nTranslationFactory, useFactory: () =\u0026gt; I18nMemoryModule.translations, }, ], exports: [I18nTranslationFactory], }; } } 3.3. Đăng ký module trong AppModule Thêm I18nMemoryModule vào module chính:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { Module } from \u0026#39;@nestjs/common\u0026#39;; import { I18nMemoryModule } from \u0026#39;./i18n-memory.module\u0026#39;; import { QueryResolver, AcceptLanguageResolver } from \u0026#39;nestjs-i18n\u0026#39;; @Module({ imports: [ I18nMemoryModule.forRootAsync({ useFactory: (translationsFactory: I18nTranslation[]) =\u0026gt; ({ fallbackLanguage: \u0026#39;en\u0026#39;, loaderOptions: { translations: translationsFactory, }, }), resolvers: [ { use: QueryResolver, options: [\u0026#39;lang\u0026#39;] }, AcceptLanguageResolver, ], }), ], }) export class AppModule {} 3.4. Thêm bản dịch từ mỗi module riêng Mỗi module có thể sử dụng forFeature để thêm bản dịch riêng của nó:\n1 2 3 4 5 6 7 8 9 10 11 12 import { Module } from \u0026#39;@nestjs/common\u0026#39;; import { I18nMemoryModule } from \u0026#39;../i18n-memory.module\u0026#39;; const userTranslations = { en: { user: \u0026#39;User\u0026#39; }, vi: { user: \u0026#39;Người dùng\u0026#39; }, }; @Module({ imports: [I18nMemoryModule.forFeature(userTranslations)], }) export class UserModule {} 3.5. Sử dụng i18n trong controller Tạo một controller để sử dụng i18n:\n1 2 3 4 5 6 7 8 9 10 11 12 import { Controller, Get, Headers } from \u0026#39;@nestjs/common\u0026#39;; import { I18nService } from \u0026#39;nestjs-i18n\u0026#39;; @Controller(\u0026#39;i18n\u0026#39;) export class I18nController { constructor() {} @Get(\u0026#39;translate\u0026#39;) translate(@I18n() i18n: I18nContext): string { return await i18n.t(\u0026#39;user\u0026#39;); } } 4. Kiểm tra API Chạy ứng dụng bằng lệnh:\n1 npm run start Gọi API để kiểm tra:\n1 curl -H \u0026#34;Accept-Language: vi-VN\u0026#34; \u0026#34;http://localhost:3000/i18n/translate\u0026#34; Kết quả:\n1 \u0026#34;Người dùng\u0026#34; 5. Kết luận Chúng ta đã triển khai thành công i18n trong NestJS sử dụng in-memory storage. Ngoài ra, chúng ta có thể thêm bản dịch từ từng module riêng bằng forFeature, giúp hệ thống linh hoạt hơn mà không cần tải lại toàn bộ ứng dụng.\n","date":"2025-04-05T10:17:00+08:00","permalink":"https://phongthien99.github.io/posts/implementing-i18n-in-nestjs-using-in-memory-storage/","title":"Implementing i18n in NestJS Using In-Memory Storage"},{"content":"Context-Aware Request Logger with Async Context for NestJS 1. The Problem Một hệ thống logging tốt không chỉ ghi nhận sự kiện mà còn cung cấp đủ thông tin để phân tích và truy vết lỗi. Trong NestJS, việc sử dụng context-aware logger giúp gắn kết dữ liệu như requestId, userAgent hoặc thông tin người dùng vào mỗi log, đảm bảo khả năng theo dõi và nhóm các request cụ thể một cách hiệu quả.\nTheo nguyên tắc 12-Factor App, logging đóng vai trò quan trọng trong giám sát và duy trì ứng dụng. Cụ thể:\nỨng dụng nên ghi log ở dạng văn bản đơn giản (stdout / stderr). Không lưu trữ log trong ứng dụng, mà để môi trường vận hành xử lý. Mỗi log cần có đủ ngữ cảnh để dễ dàng truy vết. 2. The Solution Sử dụng async_hooks để gán ngữ cảnh .async_hooks là một module trong Node.js giúp theo dõi vòng đời của các tác vụ bất đồng bộ như Promise, setTimeout, HTTP request. Một trong những ứng dụng quan trọng của nó là quản lý ngữ cảnh request, đặc biệt hữu ích khi logging hoặc theo dõi truy vết lỗi.\nTrong NestJS, có thể sử dụngasync_hooks thông qua AsyncLocalStorage để gán và duy trì dữ liệu theo từng request mà không cần truyền thủ công. Điều này giúp:\nTự động gán requestId vào logger, hỗ trợ truy vết request dễ dàng. Lưu thông tin người dùng trong vòng đời request, không cần global state. Duy trì trace ID để debugging hệ thống phân tán. Cách triển khai phổ biến là dùng Middleware để khởi tạo ngữ cảnh request, kết hợp với Custom Logger để tự động lấy thông tin từ AsyncLocalStorage.\n3. Implement Trước tiên, hãy cài đặt NestJS và các thư viện cần thiết:\n1 npm install @nestjs/common @nestjs/core @nestjs/platform-express uuid 1. LoggerStorageService (Lưu trữ ngữ cảnh logging) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ts CopyEdit import { Injectable } from \u0026#39;@nestjs/common\u0026#39;; import { AsyncLocalStorage } from \u0026#39;async_hooks\u0026#39;; @Injectable() export class LoggerStorageService { private readonly _storage: AsyncLocalStorage\u0026lt;Record\u0026lt;string, any\u0026gt;\u0026gt;; constructor() { this._storage = new AsyncLocalStorage\u0026lt;Record\u0026lt;string, any\u0026gt;\u0026gt;(); } getStore(): Record\u0026lt;string, any\u0026gt; | undefined { return this._storage.getStore(); } run(store: Record\u0026lt;string, any\u0026gt;, callback: () =\u0026gt; any) { return this._storage.run(store, callback); } } AsyncLocalStorage giúp lưu trữ ngữ cảnh của mỗi request một cách riêng biệt. getStore() lấy dữ liệu hiện tại trong ngữ cảnh bất đồng bộ. run(store, callback) thiết lập một ngữ cảnh mới và thực thi callback bên trong nó. 2. GestLogger (Logger có ngữ cảnh) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import { Injectable, Logger, LoggerService } from \u0026#39;@nestjs/common\u0026#39;; import { LoggerStorageService } from \u0026#39;./storage.service\u0026#39;; export class GestLogger implements LoggerService { private readonly _logger: Logger; constructor( private readonly _storageService: LoggerStorageService, context?: string, options?: { timestamp?: boolean }, ) { this._logger = new Logger(context, options); } contextDetail(...fields: string[]): string { const context = this._storageService.getStore(); if (!context) return \u0026#39;\u0026#39;; // If fields are specified, only include those fields if (fields \u0026amp;\u0026amp; fields.length \u0026gt; 0) { return fields .filter((field) =\u0026gt; field in context) .map((field) =\u0026gt; `[${field}:${context[field]}]`) .join(\u0026#39;\u0026#39;); } // Otherwise include all fields return Object.entries(context) .map(([key, value]) =\u0026gt; `[${key}:${value}]`) .join(\u0026#39;\u0026#39;); } log(message: any, ...optionalParams: any[]): void { this._logger.log(message, ...optionalParams); } error(message: any, stack?: string, ...optionalParams: any[]): void { this._logger.error(message, ...optionalParams); } warn(message: any, ...optionalParams: any[]): void { this._logger.warn(message, ...optionalParams); } debug(message: any, ...optionalParams: any[]): void { this._logger.debug(message, ...optionalParams); } verbose(message: any, ...optionalParams: any[]): void { this._logger.verbose(message, ...optionalParams); } } @Injectable() export class GestLoggerFactory { constructor(private readonly _storageService: LoggerStorageService) {} create(context?: string, options?: { timestamp?: boolean }): GestLogger { return new GestLogger(this._storageService, context, options); } } contextDetail(): Lấy thông tin từ AsyncLocalStorage và định dạng dưới dạng [key:value]. 3. GestLoggerFactory (Factory để tạo logger) 1 2 3 4 5 6 7 8 9 @Injectable() export class GestLoggerFactory { constructor(private readonly _storageService: LoggerStorageService) {} create(context?: string, options?: { timestamp?: boolean }): GestLogger { return new GestLogger(this._storageService, context, options); } } Factory Pattern giúp tạo các instance của GestLogger. 4. GestLoggerModule (Module Logging) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 import { Global, MiddlewareConsumer, Module, DynamicModule, } from \u0026#39;@nestjs/common\u0026#39;; import { GestLoggerFactory } from \u0026#39;./logger.service\u0026#39;; import { LoggerStorageService } from \u0026#39;./storage.service\u0026#39;; import { HttpContextMiddlewareFactory } from \u0026#39;../middleware/http-context.middleware\u0026#39;; import { v4 as uuidv4 } from \u0026#39;uuid\u0026#39;; export interface LoggerModuleAsyncOptions { httpMiddleware?: { enabled?: boolean; getContext?: (req: any, res: any) =\u0026gt; any; }; } @Global() @Module({}) export class GestLoggerModule { private static _options: LoggerModuleAsyncOptions; static forRoot(options: LoggerModuleAsyncOptions): DynamicModule { this._options = options; return { module: GestLoggerModule, providers: [GestLoggerFactory, LoggerStorageService], exports: [GestLoggerFactory, LoggerStorageService], }; } configure(consumer: MiddlewareConsumer) { const enabled = GestLoggerModule._options?.httpMiddleware?.enabled ?? true; if (!enabled) return; const getContext = GestLoggerModule._options?.httpMiddleware?.getContext || ((req, res) =\u0026gt; ({ requestId: req.headers[\u0026#39;x-request-id\u0026#39;] || uuidv4(), userAgent: req.headers[\u0026#39;user-agent\u0026#39;] || null, })); consumer.apply(HttpContextMiddlewareFactory(getContext)).forRoutes(\u0026#39;*\u0026#39;); } } forRoot() cấu hình module với middleware tùy chỉnh. configure() tự động thêm requestId vào mỗi request. 5. Sử dụng trong AppModule 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ts CopyEdit import { Module } from \u0026#39;@nestjs/common\u0026#39;; import { GestLoggerModule } from \u0026#39;./logger/logger.module\u0026#39;; import { AppService } from \u0026#39;./app.service\u0026#39;; @Module({ imports: [ GestLoggerModule.forRoot({ httpMiddleware: { enabled: true, getContext: (req, res) =\u0026gt; ({ requestId: req.headers[\u0026#39;x-request-id\u0026#39;] || uuidv4(), userAgent: req.headers[\u0026#39;user-agent\u0026#39;] || null, }), }, }), ], providers: [AppService], }) export class AppModule {} Import GestLoggerModule vào ứng dụng chính. Kích hoạt middleware tự động thêm requestId. 6. Sử dụng trong AppService 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import { Injectable } from \u0026#39;@nestjs/common\u0026#39;; import { GestLoggerFactory } from \u0026#39;./logger/logger.service\u0026#39;; import { GestLogger } from \u0026#39;./logger/gest-logger\u0026#39;; @Injectable() export class AppService { private _logger: GestLogger; constructor(private readonly gestLoggerFactory: GestLoggerFactory) { this._logger = gestLoggerFactory.create(AppService.name); } getHello(): string { this._logger.log(`${this._logger.contextDetail(\u0026#39;requestId\u0026#39;)} Hello World!`); return \u0026#39;Hello World!\u0026#39;; } } this._logger.log() sẽ tự động kèm theo requestId từ AsyncLocalStorage. Kết quả:\n1 [Nest] 800395 - 22/03/2025, 03:28:44 LOG [AppService] [requestId:c003fca7-4d48-4ce3-ae3d-979a693eaf0d] Hello World! 4. The conclusion Với việc sử dụng async_hooks và AsyncLocalStorage, chúng ta có thể duy trì ngữ cảnh logging xuyên suốt các request trong NestJS. Điều này giúp việc debug trở nên dễ dàng hơn và tăng cường khả năng theo dõi request trong hệ thống.\n","date":"2025-03-22T10:17:00+08:00","permalink":"https://phongthien99.github.io/posts/context-aware-request-logger-with-async-context-for-nestjs/","title":"Context-Aware Request Logger with Async Context for NestJS"},{"content":"Efficient Configuration Management in NestJS 1. Problem Trong NestJS, nếu bạn đang sử dụng cấu hình theo môi trường nhưng lại load vào một biến global và import khắp nơi, thì sẽ gặp các vấn đề sau:\nKhó kiểm soát và quản lý: Biến global có thể bị thay đổi hoặc được sử dụng không nhất quán trong nhiều module. Khó tái sử dụng module: Nếu module phụ thuộc trực tiếp vào biến global, việc tái sử dụng module đó ở nơi khác sẽ khó khăn hoặc không thể thay đổi config một cách linh hoạt. Khó kiểm thử (testability kém): Khi config được load trực tiếp từ biến global, việc mock dữ liệu trong unit test trở nên phức tạp, ảnh hưởng đến khả năng kiểm thử và bảo trì code. Để giải quyết những vấn đề trên, chúng ta có thể sử dụng mô hình forRoot và forRootAsync để quản lý config một cách linh hoạt và dễ kiểm soát hơn.\n2. Solution Bước 1: Khởi tạo AppModule theo dạng forRoot Thay vì sử dụng biến global, ta có thể truyền config qua forRoot, giúp module có thể nhận cấu hình từ bên ngoài.\napp.module.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import { DynamicModule, Module } from \u0026#39;@nestjs/common\u0026#39;; import { AppController } from \u0026#39;./app.controller\u0026#39;; import { AppService } from \u0026#39;./app.service\u0026#39;; @Module({}) export class AppModule { static forRoot(config: Record\u0026lt;string, any\u0026gt;): DynamicModule { return { module: AppModule, providers: [], controllers: [], }; } } main.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 const loadConfig = () =\u0026gt; { return { http: { port: 5000, }, }; }; const conf = loadConfig(); async function bootstrap(config: Record\u0026lt;string, any\u0026gt;) { const app = await NestFactory.create(AppModule.forRoot(config)); await app.listen(config.http.port, () =\u0026gt; { console.log(`Listening on port ${config.http.port}`); }); } bootstrap(conf); Cách làm này giúp chúng ta quản lý cấu hình tập trung và dễ dàng thay đổi.\nBước 2: Sử dụng ConfigModule của NestJS NestJS có sẵn @nestjs/config, giúp quản lý cấu hình theo môi trường dễ dàng hơn.\napp.module.ts (cập nhật thêm ConfigModule) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import { DynamicModule, Module } from \u0026#39;@nestjs/common\u0026#39;; import { ConfigModule } from \u0026#39;@nestjs/config\u0026#39;; @Module({}) export class AppModule { static forRoot(config: Record\u0026lt;string, any\u0026gt;): DynamicModule { return { module: AppModule, imports: [ ConfigModule.forRoot({ isGlobal: true, // Đảm bảo module có thể được sử dụng ở bất kỳ đâu load: [() =\u0026gt; config], // Load config từ biến config }), ], }; } } Việc sử dụng ConfigModule giúp dễ dàng inject config vào bất kỳ module nào trong ứng dụng mà không cần dùng biến global.\nBước 3: Sử dụng forRootAsync để inject config vào từng module Nếu một module cần sử dụng biến môi trường, ta nên inject thông qua dependency injection thay vì sử dụng biến global trực tiếp.\nsome.module.ts 1 2 3 4 5 6 7 8 9 10 11 import { DynamicModule, Module, Provider } from \u0026#39;@nestjs/common\u0026#39;; @Module({}) export class SomeModule { static forRootAsync(...configProviders: Provider[]): DynamicModule { return { module: SomeModule, providers: [...configProviders], }; } } Bằng cách này, chúng ta có thể truyền config vào từng module một cách linh hoạt và kiểm soát tốt hơn.\nCập nhật app.module.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import { ConfigModule, ConfigService } from \u0026#39;@nestjs/config\u0026#39;; import { SomeModule } from \u0026#39;./some.module\u0026#39;; @Module({}) export class AppModule { static forRoot(config: Record\u0026lt;string, any\u0026gt;): DynamicModule { return { module: AppModule, imports: [ ConfigModule.forRoot({ isGlobal: true, // Đảm bảo module có thể được sử dụng ở bất kỳ đâu load: [() =\u0026gt; config], // Load config từ biến config }), SomeModule.forRootAsync({ provide: \u0026#39;DATABASE_HOST\u0026#39;, useFactory: (configService: ConfigService) =\u0026gt; configService.get\u0026lt;string\u0026gt;(\u0026#39;mongo.host\u0026#39;), inject: [ConfigService], }), ], }; } } Sử dụng forRootAsync giúp module tự động lấy được config phù hợp mà không phụ thuộc vào biến global, làm tăng tính linh hoạt và dễ bảo trì.\n3. Conclusion Việc quản lý cấu hình trong NestJS một cách khoa học sẽ giúp ứng dụng dễ mở rộng, bảo trì và kiểm thử hơn. Dưới đây là một số điểm quan trọng:\nTránh sử dụng biến global để lưu trữ config, vì nó gây khó khăn trong kiểm soát và tái sử dụng module. Sử dụng forRoot hoặc forRootAsync để truyền config vào module thay vì hardcode giá trị. Tận dụng ConfigModule của NestJS để quản lý biến môi trường một cách chuyên nghiệp. Sử dụng forRootAsync để inject config vào từng module giúp module linh hoạt và dễ dàng kiểm thử hơn. Bằng cách làm theo phương pháp trên, bạn sẽ có một hệ thống quản lý config tốt hơn, giúp ứng dụng của bạn trở nên bền vững và dễ dàng phát triển về sau.\n","date":"2025-03-15T10:17:00+08:00","permalink":"https://phongthien99.github.io/posts/efficient-configuration-management-in-nestjs/","title":"Efficient Configuration Management in NestJS"},{"content":"Unit Testing the Controller Layer in Web Applications Unit test là một phần quan trọng trong phát triển phần mềm, giúp đảm bảo từng thành phần nhỏ của hệ thống hoạt động chính xác. Trong ứng dụng web, controller xử lý request và response, gọi service để lấy dữ liệu, kiểm tra đầu vào, và trả về mã trạng thái HTTP phù hợp. Viết unit test cho controller giúp phát hiện lỗi sớm và đảm bảo logic hoạt động đúng.\n1. Lợi ích của unit test cho controller Xác minh logic xử lý trong controller hoạt động đúng. Phát hiện lỗi sớm trước khi triển khai. Tăng độ tin cậy cho ứng dụng. Cô lập lỗi dễ dàng bằng cách sử dụng mock service. 2. Xác định phạm vi test hợp lý Chỉ kiểm tra logic trong controller, không test service hoặc database. Kiểm tra các trường hợp quan trọng, gồm cả thành công và thất bại. Viết test tối giản nhưng đầy đủ. Dùng mock service để cô lập controller. 2.1. Thiết lập môi trường Ví dụ, một ứng dụng Go dùng echo framework có controller như sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package example import ( \u0026#34;net/http\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;github.com/labstack/echo/v4\u0026#34; ) type User struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } type IUserService interface { GetUserId(id int) (*User, error) } type IExampleController interface { GetUser() } type exampleController struct { router *echo.Group service IUserService } func NewExampleController(router *echo.Group, service IUserService) IExampleController { return \u0026amp;exampleController{ router: router.Group(\u0026#34;/example\u0026#34;), service: service, } } func (e *exampleController) GetUser() { e.router.GET(\u0026#34;/:id\u0026#34;, func(c echo.Context) error { id := c.Param(\u0026#34;id\u0026#34;) idInt, err := strconv.Atoi(id) if err != nil { return c.JSON(http.StatusBadRequest, map[string]string{\u0026#34;error\u0026#34;: \u0026#34;Invalid user ID\u0026#34;}) } user, err := e.service.GetUserId(idInt) if err != nil { return c.JSON(http.StatusInternalServerError, map[string]string{\u0026#34;error\u0026#34;: err.Error()}) } return c.JSON(http.StatusOK, user) }) } 2.2. Viết unit test 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 package example_test import ( \u0026#34;example/transport/http/example\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/httptest\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/labstack/echo/v4\u0026#34; . \u0026#34;github.com/onsi/ginkgo/v2\u0026#34; . \u0026#34;github.com/onsi/gomega\u0026#34; \u0026#34;github.com/stretchr/testify/mock\u0026#34; ) type MockUserService struct { mock.Mock } func (m *MockUserService) GetUserId(id int) (*example.User, error) { args := m.Called(id) if args.Error(1) != nil { return nil, args.Error(1) } return args.Get(0).(*example.User), nil } var _ = Describe(\u0026#34;ExampleController\u0026#34;, func() { var ( e *echo.Echo rec *httptest.ResponseRecorder mockService *MockUserService controller example.IExampleController ) BeforeEach(func() { e = echo.New() rec = httptest.NewRecorder() mockService = new(MockUserService) controller = example.NewExampleController(e.Group(\u0026#34;\u0026#34;), mockService) controller.GetUser() }) Describe(\u0026#34;GetUser\u0026#34;, func() { Context(\u0026#34;when the user ID is valid\u0026#34;, func() { It(\u0026#34;should return the user\u0026#34;, func() { user := \u0026amp;example.User{Id: 1, Name: \u0026#34;John Doe\u0026#34;} mockService.On(\u0026#34;GetUserId\u0026#34;, 1).Return(user, nil) req := httptest.NewRequest(http.MethodGet, \u0026#34;/example/1\u0026#34;, nil) e.ServeHTTP(rec, req) Expect(rec.Code).To(Equal(http.StatusOK)) Expect(rec.Body.String()).To(ContainSubstring(\u0026#34;John Doe\u0026#34;)) }) }) Context(\u0026#34;when the user ID is invalid\u0026#34;, func() { It(\u0026#34;should return a bad request error\u0026#34;, func() { req := httptest.NewRequest(http.MethodGet, \u0026#34;/example/invalid\u0026#34;, nil) e.ServeHTTP(rec, req) Expect(rec.Code).To(Equal(http.StatusBadRequest)) Expect(rec.Body.String()).To(ContainSubstring(\u0026#34;Invalid user ID\u0026#34;)) }) }) Context(\u0026#34;when the service returns an error\u0026#34;, func() { It(\u0026#34;should return an internal server error\u0026#34;, func() { mockService.On(\u0026#34;GetUserId\u0026#34;, 1).Return(nil, echo.NewHTTPError(http.StatusInternalServerError, \u0026#34;Service error\u0026#34;)) req := httptest.NewRequest(http.MethodGet, \u0026#34;/example/1\u0026#34;, nil) e.ServeHTTP(rec, req) Expect(rec.Code).To(Equal(http.StatusInternalServerError)) Expect(rec.Body.String()).To(ContainSubstring(\u0026#34;Service error\u0026#34;)) }) }) }) }) func TestService(t *testing.T) { RegisterFailHandler(Fail) RunSpecs(t, \u0026#34;Example Suite\u0026#34;) } 3. Kết luận Viết unit test cho controller giúp đảm bảo logic xử lý đúng, phát hiện lỗi sớm và dễ dàng bảo trì. Bằng cách sử dụng mocking, ta có thể cô lập controller khỏi các thành phần khác. Việc tối ưu số lượng test case giúp tiết kiệm thời gian mà vẫn đảm bảo chất lượng. Sử dụng framework như ginkgo và gomega giúp test dễ đọc và duy trì hơn.\n","date":"2025-02-21T23:17:00+08:00","permalink":"https://phongthien99.github.io/posts/unit-testing-the-controller-layer-in-web-applications/","title":"Unit Testing the Controller Layer in Web Applications"},{"content":"Understanding and applying the SOLID Principles in Programming Trong lập trình hướng đối tượng (OOP), SOLID là tập hợp năm nguyên lý giúp viết mã nguồn dễ bảo trì, mở rộng và tránh những vấn đề phổ biến như mã lặp (code duplication) hoặc liên kết chặt chẽ (tight coupling). SOLID là viết tắt của:\nSingle Responsibility Principle (Nguyên lý trách nhiệm duy nhất) Open/Closed Principle (Nguyên lý mở/đóng) Liskov Substitution Principle (Nguyên lý thay thế Liskov) Interface Segregation Principle (Nguyên lý phân tách giao diện) Dependency Inversion Principle (Nguyên lý đảo ngược phụ thuộc) Hãy cùng tìm hiểu chi tiết từng nguyên lý và cách áp dụng chúng trong thực tế.\n1. Nguyên Lý Trách Nhiệm Duy Nhất (Single Responsibility Principle - SRP) Định nghĩa: Mỗi lớp chỉ nên có một lý do để thay đổi, tức là chỉ đảm nhận một nhiệm vụ duy nhất.\nVí dụ sai: Một lớp xử lý cả logic nghiệp vụ và giao tiếp với cơ sở dữ liệu:\n1 2 3 4 5 6 7 8 9 type Report struct {} func (r *Report) Generate() string { return \u0026#34;Báo cáo doanh thu tháng\u0026#34; } func (r *Report) SaveToFile() { fmt.Println(\u0026#34;Lưu báo cáo vào file\u0026#34;) } Cách cải thiện: Chia thành hai lớp, một lớp chịu trách nhiệm tạo báo cáo và một lớp khác lo lưu trữ:\n1 2 3 4 5 6 7 8 9 10 11 type Report struct {} func (r *Report) Generate() string { return \u0026#34;Báo cáo doanh thu tháng\u0026#34; } type ReportStorage struct {} func (s *ReportStorage) SaveToFile(report string) { fmt.Println(\u0026#34;Lưu báo cáo vào file\u0026#34;) } Ứng dụng trong kiến trúc phần mềm:\nKhi xây dựng ứng dụng, chúng ta có thể áp dụng nguyên lý SRP bằng cách phân chia các tầng như Controller, Service, Repository, Model:\nController: Chỉ xử lý yêu cầu HTTP và gọi đến Service. Service: Chứa logic nghiệp vụ, không liên quan đến dữ liệu trực tiếp. Repository: Chịu trách nhiệm truy xuất dữ liệu từ cơ sở dữ liệu. Model: Chỉ đại diện cho dữ liệu, không chứa logic nghiệp vụ hoặc truy vấn. Điều này giúp mã nguồn dễ bảo trì, thay đổi một tầng mà không ảnh hưởng đến các tầng khác.\n2. Nguyên Lý Mở/Đóng (Open/Closed Principle - OCP) Định nghĩa: Một module nên mở để mở rộng nhưng đóng để chỉnh sửa, tức là có thể thêm tính năng mới mà không thay đổi mã nguồn hiện có.\nVí dụ sai:\n1 2 3 4 5 6 7 8 func CalculateBonus(role string, salary float64) float64 { if role == \u0026#34;Manager\u0026#34; { return salary * 0.2 } else if role == \u0026#34;Employee\u0026#34; { return salary * 0.1 } return 0 } Mỗi lần thêm loại nhân viên mới, chúng ta phải sửa đổi hàm CalculateBonus.\nCách cải thiện: Sử dụng Strategy Pattern để mở rộng:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 type BonusCalculator interface { CalculateBonus(salary float64) float64 } type ManagerBonus struct {} func (m ManagerBonus) CalculateBonus(salary float64) float64 { return salary * 0.2 } type EmployeeBonus struct {} func (e EmployeeBonus) CalculateBonus(salary float64) float64 { return salary * 0.1 } type Context struct { bonusCalculator BonusCalculator } func (c *Context) SetStrategy(b BonusCalculator) { c.bonusCalculator = b } func (c *Context) ExecuteStrategy(salary float64) float64 { return c.bonusCalculator.CalculateBonus(salary) } Bây giờ, chúng ta có thể dễ dàng thêm loại nhân viên mới mà không cần thay đổi hàm CalculateBonus.\n3. Nguyên Lý Thay Thế Liskov (Liskov Substitution Principle - LSP) Định nghĩa: Các lớp con có thể thay thế lớp cha mà không làm thay đổi hành vi mong đợi của chương trình.\nVí dụ sai:\n1 2 3 4 5 6 7 8 type Bird struct {} func (b Bird) Fly() { fmt.Println(\u0026#34;Chim bay trên trời\u0026#34;) } type Penguin struct { Bird } Chim cánh cụt không thể bay, nhưng kế thừa Bird khiến nó có phương thức Fly(), dẫn đến lỗi.\nCách cải thiện:\nCách 1: Sử dụng Interface để nhóm hành vi thay vì kế thừa trực tiếp\n1 2 3 4 5 6 7 8 9 10 11 12 13 type Bird interface { Move() } type FlyingBird struct{} func (f FlyingBird) Move() { fmt.Println(\u0026#34;Bay trên trời\u0026#34;) } type Penguin struct{} func (p Penguin) Move() { fmt.Println(\u0026#34;Đi bộ trên băng\u0026#34;) } Tách hành vi di chuyển thành một interface chung để các loài chim có thể triển khai theo đúng đặc điểm của chúng.\nCách 2: Dùng Composition Thay Vì Kế Thừa\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 type Mover interface { Move() } type CanFly struct{} func (f CanFly) Move() { fmt.Println(\u0026#34;Bay trên trời\u0026#34;) } type CanWalk struct{} func (w CanWalk) Move() { fmt.Println(\u0026#34;Đi bộ trên băng\u0026#34;) } type Sparrow struct { Mover } type Penguin struct { Mover } Sử dụng composition giúp phân tách rõ hành vi Fly và Walk, tránh kế thừa sai và giúp mở rộng dễ dàng.\nNote: Khi thiết kế hệ thống, cần xác định rõ liệu lớp mới có thực sự là con của lớp cũ hay chỉ là một lớp mới hoàn toàn với các hành vi khác biệt. Điều này giúp tránh việc kế thừa sai và đảm bảo tuân thủ nguyên lý Liskov.\n4. Nguyên Lý Phân Tách Giao Diện (Interface Segregation Principle - ISP) Định nghĩa: Một interface lớn không nên ép các lớp triển khai những phương thức mà chúng không sử dụng.\nVí dụ sai:\n1 2 3 4 type Worker interface { Work() Eat() } Robot không cần phương thức Eat(), nhưng vẫn phải triển khai nó.\nCách cải thiện:\n1 2 3 4 5 6 7 type Workable interface { Work() } type Eatable interface { Eat() } Robot chỉ cần triển khai Workable, còn con người triển khai cả Workable và Eatable.\n5. Nguyên Lý Đảo Ngược Phụ Thuộc (Dependency Inversion Principle - DIP) Định nghĩa: Các module cấp cao không nên phụ thuộc vào module cấp thấp, cả hai nên phụ thuộc vào abstraction(interface).\nVí dụ sai:\n1 2 3 4 5 6 7 8 9 10 11 12 type MySQLDatabase struct {} func (db MySQLDatabase) SaveData(data string) { fmt.Println(\u0026#34;Lưu dữ liệu vào MySQL\u0026#34;) } type Service struct { db MySQLDatabase } func (s Service) Store(data string) { s.db.SaveData(data) } Service bị phụ thuộc vào MySQL, gây khó khăn khi chuyển sang PostgreSQL.\nCách cải thiện:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type Database interface { SaveData(data string) } type MySQLDatabase struct {} func (db MySQLDatabase) SaveData(data string) { fmt.Println(\u0026#34;Lưu dữ liệu vào MySQL\u0026#34;) } type Service struct { db Database } func (s Service) Store(data string) { s.db.SaveData(data) } Bây giờ có thể dễ dàng thay thế MySQL bằng một cơ sở dữ liệu khác.\nKết Luận Việc áp dụng SOLID giúp mã nguồn dễ bảo trì, mở rộng và tái sử dụng hơn. Khi thiết kế hệ thống, hãy luôn nghĩ về các nguyên lý này để tránh những vấn đề về kiến trúc và đảm bảo code chất lượng cao.\n","date":"2025-02-08T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/understanding-and-applying-the-solid-principles-in-programming/","title":"Understanding and Applying the SOLID Principles in Programming"},{"content":"Comparing Decorator Pattern and Proxy Pattern in Programming Giới thiệu Trong lập trình hướng đối tượng, Decorator Pattern và Proxy Pattern đều là những mẫu thiết kế thuộc nhóm Structural Pattern (mẫu thiết kế cấu trúc). Tuy nhiên, chúng có mục đích sử dụng khác nhau. Nếu bạn đang phân vân khi nào nên dùng Decorator và khi nào nên dùng Proxy, bài viết này sẽ giúp bạn hiểu rõ hơn.\n1. Định nghĩa và Mục đích Decorator Pattern – Mở rộng hành vi của đối tượng một cách linh hoạt Decorator Pattern cho phép bạn thêm hoặc thay đổi hành vi của một đối tượng mà không cần chỉnh sửa mã nguồn của nó. Điều này đặc biệt hữu ích khi bạn muốn mở rộng tính năng mà không làm thay đổi cấu trúc bên trong.\nỨng dụng thực tế:\nThêm logging, caching cho một class mà không sửa đổi class gốc. Mở rộng UI component trong các framework frontend như React hoặc Vue. Proxy Pattern – Kiểm soát truy cập đến đối tượng thật Proxy Pattern cung cấp một lớp thay thế để kiểm soát cách truy cập vào một đối tượng. Mục đích chính là bảo vệ, caching, hoặc lazy loading đối tượng thực.\nỨng dụng thực tế:\nLazy loading hình ảnh trong UI. Proxy database để kiểm soát quyền truy cập. Remote Proxy để gọi API từ xa. 2. So sánh chi tiết Tiêu chí Decorator Pattern Proxy Pattern Mục đích Thêm hoặc mở rộng chức năng mà không thay đổi code gốc. Kiểm soát quyền truy cập, caching, lazy-loading. Cách hoạt động Gói (wrap) đối tượng ban đầu bằng một lớp mới. Cung cấp một đối tượng thay thế để kiểm soát truy cập. Tính năng chính - Cho phép mở rộng hành vi linh hoạt. - Có thể kết hợp nhiều decorator. - Có thể chặn truy cập, lazy load đối tượng thật. - Dùng để bảo vệ tài nguyên. Ví dụ thực tế - Thêm logging, caching, thay đổi giao diện UI. - Proxy database, API Gateway, Virtual Proxy. 3. Ví dụ minh họa trong Go Decorator Pattern – Thêm SMS Notification vào hệ thống Email 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;fmt\u0026#34; ) // Interface gốc type Notifier interface { Send(msg string) } // Cấu trúc gốc type EmailNotifier struct{} func (e *EmailNotifier) Send(msg string) { fmt.Println(\u0026#34;Sending Email:\u0026#34;, msg) } // Decorator thêm chức năng SMS type SMSDecorator struct { Notifier Notifier } func (s *SMSDecorator) Send(msg string) { s.Notifier.Send(msg) // Gọi chức năng gốc fmt.Println(\u0026#34;Sending SMS:\u0026#34;, msg) } func main() { email := \u0026amp;EmailNotifier{} notifier := \u0026amp;SMSDecorator{Notifier: email} notifier.Send(\u0026#34;Hello, Robin!\u0026#34;) // Gửi cả email và SMS } Proxy Pattern – Kiểm soát quyền truy cập vào Server 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package main import ( \u0026#34;fmt\u0026#34; ) // Interface gốc type Server interface { HandleRequest(url string) } // Đối tượng thực type RealServer struct{} func (r *RealServer) HandleRequest(url string) { fmt.Println(\u0026#34;Real server processing:\u0026#34;, url) } // Proxy kiểm soát quyền truy cập type ProxyServer struct { realServer *RealServer } func (p *ProxyServer) HandleRequest(url string) { if url == \u0026#34;/restricted\u0026#34; { fmt.Println(\u0026#34;Access Denied!\u0026#34;) return } p.realServer.HandleRequest(url) // Gọi server thật nếu được phép } func main() { proxy := \u0026amp;ProxyServer{realServer: \u0026amp;RealServer{}} proxy.HandleRequest(\u0026#34;/public\u0026#34;) proxy.HandleRequest(\u0026#34;/restricted\u0026#34;) } 4. Khi nào nên sử dụng? Sử dụng Decorator khi bạn muốn mở rộng hành vi của một đối tượng mà không thay đổi mã nguồn.\nVí dụ: Thêm logging, caching, hoặc định dạng lại dữ liệu đầu ra. Sử dụng Proxy khi bạn muốn kiểm soát cách truy cập vào một đối tượng.\nVí dụ: Chặn truy cập tài nguyên, proxy cho API, hoặc lazy-load đối tượng nặng. 5. Kết luận Decorator Pattern và Proxy Pattern đều là những công cụ hữu ích trong lập trình, nhưng chúng phục vụ những mục đích khác nhau:\nDecorator Pattern giúp mở rộng hành vi của một đối tượng một cách linh hoạt. Proxy Pattern giúp kiểm soát cách truy cập vào đối tượng thực. Tùy vào yêu cầu của dự án mà bạn có thể chọn mẫu thiết kế phù hợp nhất! 🚀\n","date":"2025-02-02T00:40:00+08:00","permalink":"https://phongthien99.github.io/posts/comparing-decorator-pattern-and-proxy-pattern-in-programming/","title":"Comparing Decorator Pattern and Proxy Pattern in Programming"},{"content":"Fundamental Characteristics of OOP in Rust Rust là một ngôn ngữ lập trình mạnh mẽ và an toàn, được thiết kế để mang lại hiệu suất cao và kiểm soát bộ nhớ mạnh mẽ mà không cần sự trợ giúp của garbage collector. Mặc dù Rust không phải là một ngôn ngữ hoàn toàn hướng đối tượng (OOP), nhưng nó vẫn hỗ trợ các tính năng của OOP thông qua các khái niệm như struct, trait và ownership. Trong bài viết này, chúng ta sẽ khám phá bốn tính chất cơ bản của lập trình hướng đối tượng trong Rust.\n1. Encapsulation (Đóng gói) Đóng gói là một trong những tính chất cốt lõi của lập trình hướng đối tượng, cho phép ẩn đi chi tiết nội bộ của đối tượng và chỉ cung cấp các phương thức hoặc giao diện công khai để tương tác với đối tượng đó. Trong Rust, điều này được thực hiện thông qua visibility modifiers và sự kết hợp giữa struct và impl.\nVisibility modifiers: Rust sử dụng các từ khóa như pub để kiểm soát phạm vi truy cập của các trường và phương thức. Mặc định, các trường trong struct là private và chỉ có thể được truy cập từ bên trong module nơi chúng được định nghĩa. Impl blocks: Cung cấp cách triển khai các phương thức để tương tác với dữ liệu được đóng gói. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 struct Person { name: String, age: u32, } impl Person { // Phương thức tạo mới đối tượng Person pub fn new(name: String, age: u32) -\u0026gt; Self { Person { name, age } } // Phương thức công khai để lấy tên pub fn get_name(\u0026amp;self) -\u0026gt; \u0026amp;str { \u0026amp;self.name } // Phương thức công khai để tăng tuổi pub fn increment_age(\u0026amp;mut self) { self.age += 1; } // Phương thức riêng tư để kiểm tra nếu tuổi vượt quá giá trị cụ thể fn is_eligible_for_discount(\u0026amp;self) -\u0026gt; bool { self.age \u0026gt; 60 } } fn main() { let mut person = Person::new(\u0026#34;Alice\u0026#34;.to_string(), 30); // Truy cập thông qua phương thức công khai println!(\u0026#34;Name: {}\u0026#34;, person.get_name()); person.increment_age(); // Không thể truy cập trực tiếp trường hoặc phương thức riêng tư // person.age = 40; // Lỗi: private field // println!(\u0026#34;{}\u0026#34;, person.is_eligible_for_discount()); // Lỗi: private method } Ở đây, các trường của Person được ẩn và chỉ có thể truy cập thông qua các phương thức được định nghĩa trong impl.\n2. Inheritance (Kế thừa) Mặc dù Rust không hỗ trợ kế thừa theo kiểu truyền thống của OOP (như trong Java hay C++), nhưng chúng ta vẫn có thể mô phỏng tính kế thừa bằng cách sử dụng Deref. Deref cho phép chúng ta chuyển hướng các phương thức và thuộc tính của một đối tượng sang đối tượng khác, tạo ra một cách tiếp cận linh hoạt để mô phỏng kế thừa.\nĐầu tiên, chúng ta định nghĩa một cấu trúc Person, đại diện cho một người với trường name và một phương thức greet để trả về lời chào.\n1 2 3 4 5 6 7 8 9 10 11 rust Copy code struct Person { name: String, } impl Person { fn greet(\u0026amp;self) -\u0026gt; String { format!(\u0026#34;Hello, {}\u0026#34;, self.name) } } Cấu trúc Person có một trường name và một phương thức greet để in ra lời chào với tên của người đó.\nTiếp theo, chúng ta tạo một cấu trúc Employee, trong đó bao gồm một trường person kiểu Person. Chúng ta sẽ sử dụng Deref để cho phép Employee sử dụng các phương thức của Person.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 use std::ops::Deref; struct Employee { person: Person, job_title: String, } impl Deref for Employee { type Target = Person; fn deref(\u0026amp;self) -\u0026gt; \u0026amp;Self::Target { \u0026amp;self.person } } fn main() { let employee = Employee { person: Person { name: \u0026#34;Alice\u0026#34;.to_string(), }, job_title: \u0026#34;Engineer\u0026#34;.to_string(), }; // Sử dụng phương thức greet từ Employee println!(\u0026#34;{}\u0026#34;, employee.greet()); } Ở đây, chúng ta triển khai Deref cho Employee để chuyển hướng các lời gọi đến đối tượng Person. Điều này có nghĩa là, khi chúng ta gọi các phương thức như greet() từ Employee, Rust sẽ tự động gọi phương thức đó trên đối tượng Person bên tro\n3. Polymorphism (Đa hình) Polymorphism trong OOP cho phép các đối tượng khác nhau có thể sử dụng chung một giao diện mà không cần phải biết loại cụ thể của đối tượng. Trong Rust, polymorphism được thực hiện thông qua trait objects và dynamic dispatch.\nDưới đây là ví dụ về đa hình trong Rust:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 trait Speak { fn speak(\u0026amp;self); } struct Dog; struct Cat; impl Speak for Dog { fn speak(\u0026amp;self) { println!(\u0026#34;Woof!\u0026#34;); } } impl Speak for Cat { fn speak(\u0026amp;self) { println!(\u0026#34;Meow!\u0026#34;); } } fn make_speak(speaker: \u0026amp;dyn Speak) { speaker.speak(); } fn main() { let dog = Dog; let cat = Cat; make_speak(\u0026amp;dog); // Prints \u0026#34;Woof!\u0026#34; make_speak(\u0026amp;cat); // Prints \u0026#34;Meow!\u0026#34; } Ở đây, make_speak có thể nhận bất kỳ đối tượng nào thực hiện trait Speak, cho phép đa hình hoạt động mà không cần biết trước loại đối tượng.\n4. Abstraction (Trừu tượng hóa) Trừu tượng hóa giúp ẩn các chi tiết cài đặt và chỉ lộ ra giao diện cần thiết. Rust hỗ trợ trừu tượng hóa thông qua việc sử dụng trait và các kiểu dữ liệu như Option và Result, cho phép xử lý các tình huống mà không cần phải biết chi tiết cài đặt.\nVí dụ về trừu tượng hóa với trait:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 trait Draw { fn draw(\u0026amp;self); } struct Circle; struct Square; impl Draw for Circle { fn draw(\u0026amp;self) { println!(\u0026#34;Drawing a circle\u0026#34;); } } impl Draw for Square { fn draw(\u0026amp;self) { println!(\u0026#34;Drawing a square\u0026#34;); } } fn draw_all(shapes: \u0026amp;Vec\u0026lt;Box\u0026lt;dyn Draw\u0026gt;\u0026gt;) { for shape in shapes { shape.draw(); } } fn main() { let circle = Circle; let square = Square; // Bọc các đối tượng trong Box\u0026lt;dyn Draw\u0026gt; để sử dụng tính đa hình let shapes: Vec\u0026lt;Box\u0026lt;dyn Draw\u0026gt;\u0026gt; = vec![Box::new(circle), Box::new(square)]; // Vòng lặp qua các đối tượng và gọi hàm `draw` draw_all(\u0026amp;shapes); } Trong ví dụ này, các chi tiết triển khai cụ thể như cách vẽ hình tròn hay hình vuông được ẩn đi. Thay vào đó, ta chỉ làm việc với giao diện draw, giúp mã nguồn trở nên rõ ràng và dễ bảo trì. Thông qua việc bọc đối tượng trong Box\u0026lt;dyn Draw\u0026gt;, chúng ta có thể lưu trữ và xử lý các kiểu dữ liệu khác nhau sử dụng cùng một giao diện chung mà không cần quan tâm đến kiểu cụ thể.\nKết luận Rust cung cấp đầy đủ các tính chất của lập trình hướng đối tượng thông qua các cấu trúc như struct, trait và các tính năng mạnh mẽ của hệ thống kiểu. Mặc dù Rust không hoàn toàn hướng đối tượng như một số ngôn ngữ khác, nhưng những khái niệm trên giúp chúng ta xây dựng các chương trình dễ bảo trì, tái sử dụng và mở rộng. Nếu bạn muốn làm việc với OOP trong Rust, các tính năng này cung cấp sự linh hoạt để giải quyết các vấn đề lập trình với phong cách OOP trong khi vẫn giữ được các lợi ích của Rust về hiệu suất và an toàn bộ nhớ.\n","date":"2024-12-12T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/fundamental-characteristics-of-oop-in-rust/","title":"Fundamental Characteristics of OOP in Rust"},{"content":"Live Reload for Go Applications in Docker Compose 1. Vấn Đề Khi phát triển ứng dụng Go, việc phải dừng ứng dụng, biên dịch lại, và khởi động lại mỗi khi thay đổi mã nguồn là một quy trình tốn thời gian và làm gián đoạn luồng làm việc. Vậy làm thế nào để giảm thiểu công đoạn này và cải thiện hiệu quả phát triển? Giải pháp chính là live reload, cho phép ứng dụng tự động cập nhật mà không cần thao tác thủ công.\n2. Giải Pháp Live reload giúp tự động phát hiện thay đổi trong mã nguồn, biên dịch và khởi động lại ứng dụng. Trong Go, một công cụ phổ biến hỗ trợ tính năng này là Air. Air đơn giản, mạnh mẽ, và dễ tích hợp, giúp lập trình viên tiết kiệm thời gian.\n3. Cách Thực Hiện Bước 1: Tạo ứng dụng mẫu Tạo một ứng dụng Go đơn giản để thử nghiệm:\n1 2 3 mkdir air-example \u0026amp;\u0026amp; cd ./ go mod init example/air touch main.go Thêm đoạn mã sau vào file main.go:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func helloHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello, World!\u0026#34;) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, helloHandler) fmt.Println(\u0026#34;Starting server at port 8080\u0026#34;) if err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil); err != nil { fmt.Println(err) } } Bước 2: Tích hợp Air vào Docker Cấu hình Dockerfile.dev với Air để hỗ trợ live reload:\n1 2 3 4 5 6 7 8 9 10 11 12 # Stage 1: Base image FROM golang:1.22.3 as base # Stage 2: Development environment FROM base as dev # Cài đặt Air RUN curl -sSfL https://raw.githubusercontent.com/cosmtrek/air/master/install.sh | sh -s -- -b $(go env GOPATH)/bin # Lệnh mặc định để chạy Air CMD [\u0026#34;air\u0026#34;] Bước 3: Cấu hình Docker-Compose Kết hợp Air với Docker Compose để tự động tải lại ứng dụng:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version: \u0026#34;3.9\u0026#34; services: demo-air: container_name: air-demo build: context: . target: dev working_dir: /opt/app command: air --build.cmd \u0026#34;go build -o build/app main.go\u0026#34; --build.bin \u0026#34;build/app\u0026#34; volumes: - ./:/opt/app networks: - app-network networks: app-network: external: true Giải thích:\ncommand: Chạy Air với tham số tùy chỉnh để build và chạy ứng dụng. volumes: Mount mã nguồn từ máy vào container để theo dõi thay đổi. networks: Tạo hoặc sử dụng mạng Docker để kết nối các container. Bước 4: Chạy Ứng Dụng Khởi động ứng dụng với lệnh:\n1 docker-compose up Mỗi khi thay đổi mã nguồn trong thư mục dự án, Air sẽ tự động phát hiện và tải lại ứng dụng.\n4. Kết Luận Sử dụng Air cùng Docker-Compose giúp tối ưu hóa quá trình phát triển ứng dụng Go. Quy trình live reload giúp giảm thiểu thao tác thủ công, tăng tốc độ phát triển và mang lại trải nghiệm làm việc liền mạch.\n","date":"2024-11-28T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/live-reload-for-go-applications-in-docker-compose/","title":"Live Reload for Go Applications in Docker Compose"},{"content":"Development environment with Docker and Nginx Đặt Vấn Đề Việc phát triển cục bộ với Docker đã trở thành một phương pháp phổ biến trong quy trình phát triển phần mềm hiện đại. Việc khởi tạo container và ánh xạ các cổng là bước cơ bản để bắt đầu công việc. Tuy nhiên, khi làm việc với nhiều dự án đồng thời, việc xung đột cổng giữa các container trên cùng một máy chủ Docker có thể gây khó khăn. Điều này làm giảm hiệu quả công việc và khiến bạn khó quản lý các cổng đang sử dụng.\nGiải Pháp Một giải pháp đơn giản là sử dụng reverse proxy cục bộ để quản lý các dự án. Nginx là một lựa chọn lý tưởng để định tuyến và quản lý các dự án qua các tên miền, giúp giảm thiểu xung đột cổng và tăng tính linh hoạt khi phát triển.\nCách Thực Hiện Bước 1: Tạo Mạng Docker Trước khi triển khai reverse proxy, bạn cần tạo một mạng Docker để các dịch vụ có thể giao tiếp với nhau.\n1 docker network create traefik-ingress Bước 2: Cài Đặt Nginx Chúng ta sẽ sử dụng Docker Compose để cài đặt Nginx cùng với các dịch vụ thử nghiệm. Dưới đây là cấu hình docker-compose.yml để cài đặt Nginx và các dịch vụ mẫu:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 services: nginx: image: docker.io/bitnami/nginx:1.23 ports: - \u0026#39;8085:5001\u0026#39; # Ánh xạ cổng ngoài vào cổng dịch vụ bên trong volumes: - ./nginx.conf:/opt/bitnami/nginx/conf/server_blocks/my_server_block.conf # Cấu hình Nginx tùy chỉnh networks: - traefik-ingress origin-01: container_name: origin-01 image: traefik/whoami command: - --port=8080 - --name=origin-01 networks: - traefik-ingress origin-02: container_name: origin-02 image: traefik/whoami command: - --port=8080 - --name=origin-02 networks: - traefik-ingress networks: traefik-ingress: external: true Bước 3: Cấu Hình Nginx Cấu hình Nginx cần định tuyến lưu lượng truy cập dựa trên tên miền. Dưới đây là cấu hình Nginx giúp chuyển tiếp yêu cầu tới các container tương ứng.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 server { listen 5001; listen [::]:5001; location / { # Sử dụng DNS resolver của Docker resolver 127.0.0.11; # Định tuyến theo tên miền if ($host ~* ^([a-zA-Z0-9\\-]+)-([0-9]+)\\.lh$) { proxy_pass http://$1:$2; break; } # Trả về lỗi nếu tên miền không hợp lệ return 404 \u0026#34;Domain not found\u0026#34;; } } Trong cấu hình Nginx này:\nNginx sẽ lắng nghe trên cổng 5001 và chuyển tiếp yêu cầu tới các dịch vụ như origin-01 hoặc origin-02 dựa trên tên miền phụ (ví dụ: origin-01.lh). DNS resolver 127.0.0.11 là DNS nội bộ của Docker, giúp Nginx có thể nhận diện và định tuyến các yêu cầu tới các container. Bước 4: Khởi Chạy Dịch Vụ Sau khi đã cấu hình docker-compose.yml và nginx.conf, bạn có thể khởi chạy dịch vụ bằng lệnh:\n1 2 docker-compose up -d Lệnh này sẽ khởi động Nginx như một reverse proxy, cùng với các dịch vụ origin-01 và origin-02, mỗi dịch vụ chạy trên cổng riêng nhưng đều được truy cập qua Nginx.\nBước 5: Kiểm Tra Thực Tế Để kiểm tra, bạn cần thêm tên miền giả vào tệp /etc/hosts:\n1 2 127.0.0.1 origin-01-8080.lh Sau đó, bạn có thể thử truy cập dịch vụ bằng lệnh curl:\n1 2 curl http://origin-01-8080.lh:8085/test Kết Luận Việc sử dụng Nginx làm reverse proxy cục bộ giúp bạn dễ dàng quản lý các container Docker mà không gặp phải xung đột cổng. Với phương pháp định tuyến theo tên miền, bạn có thể truy cập nhiều dịch vụ khác nhau thông qua một cổng duy nhất. Giải pháp này đơn giản hóa môi trường phát triển, đặc biệt khi làm việc với nhiều dự án cần sự tách biệt nhưng lại chia sẻ cùng một máy chủ Docker.\n","date":"2024-11-23T23:40:00+07:00","permalink":"https://phongthien99.github.io/posts/development-environment-with-docker-and-nginx/","title":"Development environment with Docker and Nginx"},{"content":"Effective Code Quality Management with SonarSource: A Solution for Tackling Technical Debt in Software Development Đặt vấn đề Trong quá trình phát triển phần mềm, có những giai đoạn dự án chạy với tốc độ \u0026ldquo;như ăn cướp\u0026rdquo;, khi các nhà phát triển buộc phải tập trung giải quyết các vấn đề trước mắt mà không có thời gian tuân thủ các tiêu chuẩn chất lượng. Điều này dẫn đến mã nguồn có thể trở nên lộn xộn, thiếu cấu trúc và khó bảo trì – tạo thành một \u0026ldquo;đống rác\u0026rdquo; chứa các đoạn mã lỗi, không nhất quán, và tiềm ẩn nhiều rủi ro bảo mật.\nNhững giải pháp tạm thời này có thể giúp dự án tiến triển trong ngắn hạn, nhưng về lâu dài sẽ làm tăng nợ kỹ thuật, khiến mã trở nên cồng kềnh và khó bảo trì. Chính vì vậy, cần một công cụ để phân tích và quản lý chất lượng mã, giúp phát hiện và xử lý các vấn đề này kịp thời, nhằm duy trì tính ổn định và bền vững cho dự án.\nGiải pháp SonarSource là một công cụ phân tích mã nguồn mạnh mẽ, giúp đội ngũ phát triển kiểm soát chất lượng mã một cách toàn diện. Nó không chỉ phát hiện \u0026ldquo;đống rác\u0026rdquo; ẩn trong mã nguồn mà còn cung cấp các giải pháp cụ thể để dọn dẹp một cách hệ thống. Sử dụng SonarSource giúp giảm thiểu nợ kỹ thuật, duy trì hiệu suất mã ổn định, và giảm thiểu rủi ro bảo mật, ngay cả khi dự án phải phát triển nhanh chóng trong những thời điểm gấp gáp.\nThực hiện Dưới đây là các bước để triển khai SonarSource thực nghiệm thông qua Docker Compose:\nBước 1: Tạo file Docker Compose File Docker Compose cấu hình các dịch vụ chính như sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 yaml Copy code services: sonarqube: image: sonarqube:community read_only: true volumes: - sonarqube_data:/opt/sonarqube/data - sonarqube_extensions:/opt/sonarqube/extensions - sonarqube_logs:/opt/sonarqube/logs - sonarqube_temp:/opt/sonarqube/temp ports: - \u0026#34;9000:9000\u0026#34; volumes: sonarqube_data: sonarqube_extensions: sonarqube_logs: sonarqube_temp: Bước 2: Đăng nhập vào SonarQube Truy cập giao diện SonarQube qua http://localhost:9000. Đăng nhập bằng tài khoản admin hoặc tài khoản cá nhân của bạn. Bước 3: Tạo Project Mới Chọn Projects và nhấp vào Create Project. Bạn có thể chọn tạo dự án từ một repository (GitHub, GitLab, Bitbucket) hoặc tạo thủ công. Bước 4: Cấu hình Project Nhập tên và key duy nhất cho project. Nếu sử dụng SonarCloud, bạn có thể chọn hoặc tạo tổ chức để quản lý. Bước 5: Tạo Token Xác Thực Tạo token để thực hiện quá trình quét mã. Lưu token này để dùng trong các bước sau. Bước 6: Cấu hình công cụ phân tích mã Tạo file sonar-project.properties trong project của bạn:\n1 2 sonar.projectKey=\u0026lt;\u0026lt;key đã tạo ở project\u0026gt;\u0026gt; Sau đó, chạy lệnh quét mã bằng cách sử dụng Docker:\n1 2 docker run --rm --net=host -e SONAR_HOST_URL=\u0026#34;http://localhost:9000\u0026#34; -e SONAR_TOKEN=\u0026#34;\u0026lt;\u0026lt;token đã tạo ở project\u0026gt;\u0026gt;\u0026#34; -e SONAR_PROJECT_KEY=\u0026#34;key đã tạo ở project\u0026#34; -v \u0026#34;$(pwd):/usr/src\u0026#34; sonarsource/sonar-scanner-cli Kết luận SonarSource là một công cụ mạnh mẽ giúp các đội phát triển phần mềm duy trì chất lượng mã nguồn ngay cả trong những giai đoạn phát triển khẩn trương. Bằng cách tích hợp SonarSource vào quy trình phát triển, chúng ta có thể phát hiện sớm các vấn đề về mã, tối ưu hóa hiệu suất và giảm thiểu rủi ro bảo mật. Kết quả là mã nguồn trở nên dễ quản lý hơn, giảm bớt nợ kỹ thuật và đảm bảo dự án có thể phát triển bền vững hơn về lâu dài.\n","date":"2024-10-12T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/effective-code-quality-management-with-sonarsource-a-solution-for-tackling-technical-debt-in-software-development/","title":"Effective Code Quality Management with SonarSource: A Solution for Tackling Technical Debt in Software Development"},{"content":"Log Monitoring for Sigma Media Server Using Promtail, Loki, and Grafana Đặt vấn đề Trong quá trình vận hành Sigma Media Server, việc kiểm tra log là một nhiệm vụ quan trọng để đảm bảo hệ thống hoạt động ổn định. Tuy nhiên, các log này thường được lưu trữ tại thư mục /var/log/sigma-machine, và việc phải thường xuyên truy cập vào thư mục, sử dụng lệnh cat hoặc tail để theo dõi log không chỉ tốn thời gian mà còn gây khó khăn khi cần giám sát liên tục và xử lý log từ nhiều dịch vụ khác nhau. Điều này đặt ra nhu cầu cho một giải pháp giám sát log tập trung, giúp theo dõi và phân tích log nhanh chóng, hiệu quả hơn.\nGiải pháp Để giải quyết vấn đề giám sát log của Sigma Media Server một cách hiệu quả, chúng ta sẽ triển khai một log monitoring stack gồm ba thành phần chính: Promtail, Loki, và Grafana.\nPromtail: Đây là agent dùng để thu thập log từ Sigma Media Server. Promtail sẽ đọc các file log tại đường dẫn /var/log/sigma-machine/, sau đó chuyển chúng đến Loki để lưu trữ và xử lý. Việc này giúp tự động hóa quá trình lấy log, không cần truy cập thủ công vào thư mục log nữa. Loki: Loki là hệ thống lưu trữ log được thiết kế tối ưu cho việc lưu trữ và truy vấn dữ liệu log. Với kiến trúc nhẹ và tích hợp tốt với Promtail, Loki cho phép lưu trữ log một cách có tổ chức và hiệu quả. Dữ liệu log từ nhiều dịch vụ khác nhau trong Sigma Media Server sẽ được lưu tại một nơi, dễ dàng quản lý và truy vấn. Grafana: Để trực quan hóa log, Grafana sẽ kết nối với Loki như một nguồn dữ liệu. Từ đây, bạn có thể tạo các dashboard tùy chỉnh để theo dõi log theo thời gian thực, thiết lập cảnh báo, và phân tích log một cách nhanh chóng. Grafana cung cấp giao diện trực quan giúp dễ dàng tìm kiếm, lọc và giám sát log mà không cần lệnh dòng lệnh phức tạp Thực hiện Triển khai thực nghiệm qua docker-compose\nBước 1: Tạo file Docker Compose File Docker Compose cấu hình các dịch vụ chính gồm Sigma Media Server, Promtail, Loki và Grafana:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 version: \u0026#34;3.8\u0026#34; services: server-01: image: registry.gviet.vn:5000/sigma-livestream/sigma-media-server:4.1.35 privileged: true user: root volumes: - var-log:/var/log/sigma-machine:rw networks: - traefik-ingress promtail: image: grafana/promtail:2.8.2 volumes: - ./promtail-config.yml:/etc/promtail/promtail-config.yml - var-log:/var/log/sigma-media-server-01:ro - var-log-02:/var/log/sigma-media-server-02:ro command: -config.file=/etc/promtail/promtail-config.yml networks: - traefik-ingress depends_on: - loki loki: image: grafana/loki:2.8.2 volumes: - ./loki-config.yml:/etc/loki/local-config.yaml command: -config.file=/etc/loki/local-config.yaml networks: - traefik-ingress grafana: image: grafana/grafana ports: - 3000:3000 networks: - traefik-ingress volumes: var-log: networks: traefik-ingress: external: true Bước 2: Cấu hình Promtail Promtail được cấu hình để thu thập log từ các file cụ thể của Sigma Media Server:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 server: http_listen_port: 9080 grpc_listen_port: 0 positions: filename: /tmp/positions.yaml clients: - url: http://loki:3100/loki/api/v1/push scrape_configs: - job_name: log-service-01 static_configs: - targets: - localhost labels: container_name: sigma-media-server-01 __path__: /var/log/sigma-media-server-01/now.* - targets: - localhost labels: container_name: sigma-media-server-02 __path__: /var/log/sigma-media-server-02/now.* Bước 3: Cấu hình Loki Loki sẽ lưu trữ và quản lý log, được cấu hình như sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 auth_enabled: false server: http_listen_port: 3100 grpc_listen_port: 9096 common: instance_addr: 127.0.0.1 path_prefix: /tmp/loki storage: filesystem: chunks_directory: /tmp/loki/chunks rules_directory: /tmp/loki/rules replication_factor: 1 ring: kvstore: store: inmemory query_range: results_cache: cache: embedded_cache: enabled: true max_size_mb: 100 schema_config: configs: - from: 2024-10-01 store: tsdb object_store: filesystem schema: v12 index: prefix: index_ period: 24h Bước 5: Cấu Hình Grafana Truy cập Grafana tại http://localhost:3000 trên trình duyệt. Đăng nhập với thông tin mặc định: Username: admin Password: admin Sau khi đăng nhập, thêm Loki làm data source: Vào Configuration \u0026gt; Data Sources \u0026gt; Add data source. Chọn Loki. Trong phần URL, nhập http://loki:3100. Nhấn Save \u0026amp; Test để xác minh kết nối. Bạn có thể sử dụng json model này để sử dụng:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 { \u0026#34;annotations\u0026#34;: { \u0026#34;list\u0026#34;: [ { \u0026#34;builtIn\u0026#34;: 1, \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;datasource\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;grafana\u0026#34; }, \u0026#34;enable\u0026#34;: true, \u0026#34;hide\u0026#34;: true, \u0026#34;iconColor\u0026#34;: \u0026#34;rgba(0, 211, 255, 1)\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Annotations \u0026amp; Alerts\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;dashboard\u0026#34; } ] }, \u0026#34;description\u0026#34;: \u0026#34;Universal and flexible dashboard for logging\u0026#34;, \u0026#34;editable\u0026#34;: true, \u0026#34;fiscalYearStartMonth\u0026#34;: 0, \u0026#34;gnetId\u0026#34;: 18042, \u0026#34;graphTooltip\u0026#34;: 0, \u0026#34;id\u0026#34;: 3, \u0026#34;links\u0026#34;: [], \u0026#34;panels\u0026#34;: [ { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;Live logs is a like \u0026#39;tail -f\u0026#39; in a real time\u0026#34;, \u0026#34;gridPos\u0026#34;: { \u0026#34;h\u0026#34;: 9, \u0026#34;w\u0026#34;: 24, \u0026#34;x\u0026#34;: 0, \u0026#34;y\u0026#34;: 0 }, \u0026#34;id\u0026#34;: 6, \u0026#34;options\u0026#34;: { \u0026#34;dedupStrategy\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;enableLogDetails\u0026#34;: true, \u0026#34;prettifyLogMessage\u0026#34;: false, \u0026#34;showCommonLabels\u0026#34;: false, \u0026#34;showLabels\u0026#34;: true, \u0026#34;showTime\u0026#34;: false, \u0026#34;sortOrder\u0026#34;: \u0026#34;Descending\u0026#34;, \u0026#34;wrapLogMessage\u0026#34;: false }, \u0026#34;targets\u0026#34;: [ { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;editorMode\u0026#34;: \u0026#34;code\u0026#34;, \u0026#34;expr\u0026#34;: \u0026#34;{filename=\\\u0026#34;/var/log/${container_name}/now.debug\\\u0026#34;}\u0026#34;, \u0026#34;hide\u0026#34;: false, \u0026#34;queryType\u0026#34;: \u0026#34;range\u0026#34;, \u0026#34;refId\u0026#34;: \u0026#34;A\u0026#34; } ], \u0026#34;title\u0026#34;: \u0026#34;Debug log\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;logs\u0026#34; }, { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;Live logs is a like \u0026#39;tail -f\u0026#39; in a real time\u0026#34;, \u0026#34;gridPos\u0026#34;: { \u0026#34;h\u0026#34;: 9, \u0026#34;w\u0026#34;: 24, \u0026#34;x\u0026#34;: 0, \u0026#34;y\u0026#34;: 9 }, \u0026#34;id\u0026#34;: 4, \u0026#34;options\u0026#34;: { \u0026#34;dedupStrategy\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;enableLogDetails\u0026#34;: true, \u0026#34;prettifyLogMessage\u0026#34;: false, \u0026#34;showCommonLabels\u0026#34;: false, \u0026#34;showLabels\u0026#34;: true, \u0026#34;showTime\u0026#34;: false, \u0026#34;sortOrder\u0026#34;: \u0026#34;Descending\u0026#34;, \u0026#34;wrapLogMessage\u0026#34;: false }, \u0026#34;targets\u0026#34;: [ { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;editorMode\u0026#34;: \u0026#34;code\u0026#34;, \u0026#34;expr\u0026#34;: \u0026#34;{filename=\\\u0026#34;/var/log/${container_name}/now.nginx\\\u0026#34;}\u0026#34;, \u0026#34;hide\u0026#34;: false, \u0026#34;queryType\u0026#34;: \u0026#34;range\u0026#34;, \u0026#34;refId\u0026#34;: \u0026#34;A\u0026#34; } ], \u0026#34;title\u0026#34;: \u0026#34;Nginx log\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;logs\u0026#34; }, { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;Live logs is a like \u0026#39;tail -f\u0026#39; in a real time\u0026#34;, \u0026#34;gridPos\u0026#34;: { \u0026#34;h\u0026#34;: 9, \u0026#34;w\u0026#34;: 24, \u0026#34;x\u0026#34;: 0, \u0026#34;y\u0026#34;: 18 }, \u0026#34;id\u0026#34;: 3, \u0026#34;options\u0026#34;: { \u0026#34;dedupStrategy\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;enableLogDetails\u0026#34;: true, \u0026#34;prettifyLogMessage\u0026#34;: false, \u0026#34;showCommonLabels\u0026#34;: false, \u0026#34;showLabels\u0026#34;: true, \u0026#34;showTime\u0026#34;: false, \u0026#34;sortOrder\u0026#34;: \u0026#34;Descending\u0026#34;, \u0026#34;wrapLogMessage\u0026#34;: false }, \u0026#34;targets\u0026#34;: [ { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;editorMode\u0026#34;: \u0026#34;code\u0026#34;, \u0026#34;expr\u0026#34;: \u0026#34;{filename=~\\\u0026#34;/var/log/${container_name}/now\\\\\\\\.origin\\\u0026#34;}\u0026#34;, \u0026#34;hide\u0026#34;: false, \u0026#34;queryType\u0026#34;: \u0026#34;range\u0026#34;, \u0026#34;refId\u0026#34;: \u0026#34;A\u0026#34; } ], \u0026#34;title\u0026#34;: \u0026#34;Origin log\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;logs\u0026#34; }, { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;Live logs is a like \u0026#39;tail -f\u0026#39; in a real time\u0026#34;, \u0026#34;gridPos\u0026#34;: { \u0026#34;h\u0026#34;: 9, \u0026#34;w\u0026#34;: 24, \u0026#34;x\u0026#34;: 0, \u0026#34;y\u0026#34;: 27 }, \u0026#34;id\u0026#34;: 5, \u0026#34;options\u0026#34;: { \u0026#34;dedupStrategy\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;enableLogDetails\u0026#34;: true, \u0026#34;prettifyLogMessage\u0026#34;: false, \u0026#34;showCommonLabels\u0026#34;: false, \u0026#34;showLabels\u0026#34;: true, \u0026#34;showTime\u0026#34;: false, \u0026#34;sortOrder\u0026#34;: \u0026#34;Descending\u0026#34;, \u0026#34;wrapLogMessage\u0026#34;: false }, \u0026#34;targets\u0026#34;: [ { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;editorMode\u0026#34;: \u0026#34;code\u0026#34;, \u0026#34;expr\u0026#34;: \u0026#34;{filename=\\\u0026#34;/var/log/${container_name}/now.srs\\\u0026#34;}\u0026#34;, \u0026#34;hide\u0026#34;: false, \u0026#34;queryType\u0026#34;: \u0026#34;range\u0026#34;, \u0026#34;refId\u0026#34;: \u0026#34;A\u0026#34; } ], \u0026#34;title\u0026#34;: \u0026#34;Srs log\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;logs\u0026#34; }, { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;Live logs is a like \u0026#39;tail -f\u0026#39; in a real time\u0026#34;, \u0026#34;gridPos\u0026#34;: { \u0026#34;h\u0026#34;: 9, \u0026#34;w\u0026#34;: 24, \u0026#34;x\u0026#34;: 0, \u0026#34;y\u0026#34;: 36 }, \u0026#34;id\u0026#34;: 2, \u0026#34;options\u0026#34;: { \u0026#34;dedupStrategy\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;enableLogDetails\u0026#34;: true, \u0026#34;prettifyLogMessage\u0026#34;: false, \u0026#34;showCommonLabels\u0026#34;: false, \u0026#34;showLabels\u0026#34;: true, \u0026#34;showTime\u0026#34;: false, \u0026#34;sortOrder\u0026#34;: \u0026#34;Descending\u0026#34;, \u0026#34;wrapLogMessage\u0026#34;: false }, \u0026#34;targets\u0026#34;: [ { \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;editorMode\u0026#34;: \u0026#34;code\u0026#34;, \u0026#34;expr\u0026#34;: \u0026#34;{filename=~\\\u0026#34;/var/log/${container_name}/now\\\\\\\\.portal-local\\\u0026#34;}\u0026#34;, \u0026#34;hide\u0026#34;: false, \u0026#34;queryType\u0026#34;: \u0026#34;range\u0026#34;, \u0026#34;refId\u0026#34;: \u0026#34;A\u0026#34; } ], \u0026#34;title\u0026#34;: \u0026#34;Portal log\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;logs\u0026#34; } ], \u0026#34;refresh\u0026#34;: \u0026#34;10s\u0026#34;, \u0026#34;schemaVersion\u0026#34;: 39, \u0026#34;tags\u0026#34;: [], \u0026#34;templating\u0026#34;: { \u0026#34;list\u0026#34;: [ { \u0026#34;current\u0026#34;: { \u0026#34;isNone\u0026#34;: true, \u0026#34;selected\u0026#34;: false, \u0026#34;text\u0026#34;: \u0026#34;None\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, \u0026#34;definition\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;hide\u0026#34;: 0, \u0026#34;includeAll\u0026#34;: false, \u0026#34;label\u0026#34;: \u0026#34;Container\u0026#34;, \u0026#34;multi\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;container_name\u0026#34;, \u0026#34;options\u0026#34;: [], \u0026#34;query\u0026#34;: { \u0026#34;label\u0026#34;: \u0026#34;container_name\u0026#34;, \u0026#34;refId\u0026#34;: \u0026#34;LokiVariableQueryEditor-VariableQuery\u0026#34;, \u0026#34;stream\u0026#34;: \u0026#34;{container_name=~\\\u0026#34;.+\\\u0026#34;}\u0026#34;, \u0026#34;type\u0026#34;: 1 }, \u0026#34;refresh\u0026#34;: 1, \u0026#34;regex\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;skipUrlSync\u0026#34;: false, \u0026#34;sort\u0026#34;: 0, \u0026#34;tagValuesQuery\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;tagsQuery\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;query\u0026#34;, \u0026#34;useTags\u0026#34;: false }, { \u0026#34;current\u0026#34;: { \u0026#34;selected\u0026#34;: false, \u0026#34;text\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;hide\u0026#34;: 0, \u0026#34;name\u0026#34;: \u0026#34;search\u0026#34;, \u0026#34;options\u0026#34;: [ { \u0026#34;selected\u0026#34;: true, \u0026#34;text\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;query\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;skipUrlSync\u0026#34;: false, \u0026#34;type\u0026#34;: \u0026#34;textbox\u0026#34; } ] }, \u0026#34;time\u0026#34;: { \u0026#34;from\u0026#34;: \u0026#34;now-15m\u0026#34;, \u0026#34;to\u0026#34;: \u0026#34;now\u0026#34; }, \u0026#34;timepicker\u0026#34;: { \u0026#34;refresh_intervals\u0026#34;: [ \u0026#34;10s\u0026#34;, \u0026#34;30s\u0026#34;, \u0026#34;1m\u0026#34;, \u0026#34;5m\u0026#34;, \u0026#34;15m\u0026#34;, \u0026#34;30m\u0026#34;, \u0026#34;1h\u0026#34;, \u0026#34;2h\u0026#34;, \u0026#34;1d\u0026#34; ] }, \u0026#34;timezone\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Monitor sigma server\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;cdzv1t37ajzeoc\u0026#34;, \u0026#34;version\u0026#34;: 15, \u0026#34;weekStart\u0026#34;: \u0026#34;\u0026#34; } Thay đổi các uid của datasource tương ứng\n1 2 3 4 \u0026#34;datasource\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;loki\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;adzuilqytpp1cc\u0026#34; }, Kết luận Việc sử dụng stack Promtail-Loki-Grafana giúp giám sát log của Sigma Media Server một cách tập trung, hiệu quả và trực quan. Nó giải quyết được bài toán theo dõi log từ nhiều dịch vụ khác nhau mà không cần thao tác thủ công phức tạp\n","date":"2024-10-05T12:40:00+08:00","permalink":"https://phongthien99.github.io/posts/log-monitoring-for-sigma-media-server-using-promtail-loki-and-grafana/","title":"Log Monitoring for Sigma Media Server Using Promtail, Loki, and Grafana"},{"content":"Mastering Dynamic Base Path Management in Dockerized Vue 3 + Vite Đặt vấn đề Trong phát triển ứng dụng web hiện đại, việc thiết lập đường dẫn build động (dynamic build path) là một yếu tố quan trọng để đảm bảo tính linh hoạt và khả năng mở rộng của ứng dụng. Đối với các ứng dụng Vue 3 sử dụng Vite, việc quản lý đường dẫn build không chỉ ảnh hưởng đến việc truy cập tài nguyên mà còn quyết định cách mà ứng dụng tương tác với các dịch vụ khác, như API.\nMột trong những thách thức lớn là việc thay đổi base path của ứng dụng trong các môi trường khác nhau mà không cần phải rebuild lại toàn bộ. Khi ứng dụng được triển khai trong các môi trường như development, staging hoặc production, yêu cầu về base path có thể khác nhau, và việc không có cơ chế để điều chỉnh chúng một cách linh hoạt có thể dẫn đến:\nKhó khăn trong triển khai: Cần phải duy trì nhiều cấu hình hoặc bản build riêng cho từng môi trường, gây tốn thời gian và công sức. Giải Pháp Để giải quyết vấn đề dynamic base path trong Vue 3 + Vite, chúng ta kết hợp ba kỹ thuật chính:\n1. Dynamic Environment Variables Sử dụng file như /env.js để chứa các biến môi trường (ví dụ: BASE_PATH, API_ENDPOINT). Tải các biến này vào ứng dụng tại runtime thông qua đoạn script trong index.html. 2. Nginx Configuration Generation Sử dụng script hoặc template engine để tự động sinh file cấu hình nginx dựa trên các biến môi trường hiện tại. Áp dụng các thay đổi base path động trong cấu hình nginx để tương thích với các môi trường khác nhau. 3. Tạo Template Cho index.html Sinh index.html cuối cùng dựa trên template và các biến môi trường tại runtime. Việc kết hợp các kỹ thuật này giúp thay đổi base path linh hoạt mà không cần build lại ứng dụng, đảm bảo khả năng thích ứng và tối ưu hóa quá trình triển khai.\nThực hiện Thực hiện trên project github.com/wei-zone/vue3-quick-start.git\nBước 1: Chỉnh sửa file index.html Thêm đoạn script để tải env.js từ BASE_PATH vào trong thẻ \u0026lt;head\u0026gt; của file index.html. 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Thêm đoạn này vào --\u0026gt; \u0026lt;script src=\u0026#34;${BASE_PATH}/env.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Bước 2: Tạo file env.template.js trong thư mục public Tạo file env.template.js để định nghĩa biến BASE_PATH và các biến môi trường khác nếu cần. 1 2 3 4 5 6 (function(window) { window.env = { BASE_PATH: \u0026#39;${BASE_PATH}\u0026#39; // Biến môi trường sẽ được thay thế khi build }; })(this); Bước 3: Cài đặt và cấu hình vite-plugin-dynamic-base Cài đặt thư viện vite-plugin-dynamic-base vào devDependencies. 1 2 pnpm add vite-plugin-dynamic-base --save-dev Cấu hình plugin vite-plugin-dynamic-base trong file vite.config.ts: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import { defineConfig } from \u0026#39;vite\u0026#39;; import vue from \u0026#39;@vitejs/plugin-vue\u0026#39;; import { dynamicBase } from \u0026#39;vite-plugin-dynamic-base\u0026#39;; export default defineConfig({ plugins: [ vue(), dynamicBase({ publicPath: \u0026#39;window.env.BASE_PATH\u0026#39;, // Sử dụng biến BASE_PATH từ env.js transformIndexHtml: true, // Biến đổi file index.html để sử dụng BASE_PATH }), ], }); Thực hiện build dự án: 1 2 3 bash Copy code pnpm build Bước 4: Tạo file nginx.template.conf Tạo file nginx.template.conf để cấu hình Nginx với BASE_PATH động. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 nginx Copy code user nginx; worker_processes 1; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location ${BASE_PATH} { # Sử dụng BASE_PATH được thay thế khi chạy script alias /app/; # Thư mục chứa file build của ứng dụng Vue index index.html; try_files $uri $uri/ /index.html; # Hỗ trợ cho SPA } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } } Bước 5: Tạo script gen-template.sh để sinh file từ các template Tạo script gen-template.sh để thay thế các biến môi trường trong file template. 1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash # Thay thế biến trong env.template.js và tạo file env.js envsubst \u0026lt; /app/env.template.js \u0026gt; /app/env.js # Thay thế biến trong index.html và ghi đè lại file envsubst \u0026lt; /app/index.html | tee /app/index.html \u0026gt; /dev/null # Thay thế biến trong nginx.template.conf và tạo file nginx.conf envsubst \u0026lt; /nginx.template.conf \u0026gt; /etc/nginx/nginx.conf Bước 6: Cấu hình docker-compose.yml để chạy thử Cấu hình file docker-compose.yml để chạy Nginx với BASE_PATH đã được thay thế. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 version: \u0026#39;3.8\u0026#39; services: nginx: image: nginx:latest ports: - \u0026#34;8086:80\u0026#34; # Mở cổng 8086 để truy cập Nginx từ bên ngoài command: [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;/init.sh \u0026amp;\u0026amp; nginx-debug -g \u0026#39;daemon off;\u0026#39;\u0026#34;] environment: - BASE_PATH=/test-app # Biến môi trường sẽ được sử dụng trong script gen-template.sh volumes: - ./nginx.template.conf:/nginx.template.conf # Ánh xạ file nginx.template.conf vào container - ./dist:/app # Thư mục chứa file build của ứng dụng Vue - ./gen-template.sh:/init.sh # Ánh xạ file script init.sh vào container Kết luận Thiết lập dynamic build path cho Vue 3 với Vite giúp điều chỉnh cấu hình ứng dụng linh hoạt mà không cần rebuild. Giải pháp này tối ưu hóa triển khai, giảm thiểu sai sót và dễ dàng thích ứng với thay đổi môi trường.\nTài liệu tham khảo Read Dynamic Environment Variables in Angular\n","date":"2024-09-21T12:40:00+08:00","permalink":"https://phongthien99.github.io/posts/mastering-dynamic-base-path-management-in-dockerized-vue-3--vite/","title":"Mastering Dynamic Base Path Management in Dockerized Vue 3 + Vite"},{"content":"Guide to Using Uberfx and Ginkgo for Building Unit Testing Workflow in Go Đặt vấn đề Để đảm bảo chất lượng mã nguồn trong phát triển phần mềm, unit testing là một yếu tố không thể thiếu. Việc viết và tổ chức các bài kiểm tra đơn vị một cách hiệu quả là điều quan trọng, đặc biệt khi làm việc với các ứng dụng phức tạp. Tuy nhiên, việc này thường gặp khó khăn trong việc quản lý các phụ thuộc và duy trì cấu trúc kiểm tra rõ ràng..\nGiải pháp Khi làm việc với Go, việc kết hợp Uberfx (framework DI) và Ginkgo (thư viện BDD) cung cấp một phương pháp hiệu quả để giải quyết các vấn đề trên. Uberfx giúp quản lý các phụ thuộc của ứng dụng, trong khi Ginkgo hỗ trợ viết các bài kiểm tra đơn vị theo cách dễ đọc và rõ ràng.\nBài viết này sẽ hướng dẫn bạn cách sử dụng Uberfx để quản lý phụ thuộc và Ginkgo để viết các bài kiểm tra, nhằm xây dựng một quy trình phát triển mạnh mẽ và dễ bảo trì.\nThực hiện Bước 1: Tạo module với Uberfx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 package example import ( \u0026#34;errors\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;go.uber.org/fx\u0026#34; ) type User struct { ID int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Email string `json:\u0026#34;email\u0026#34;` } type UserService interface { Create(user *User) (*User, error) Get(id int) (*User, error) Update(id int, user *User) (*User, error) Delete(id int) error } type userService struct { users map[int]*User lock sync.RWMutex idSeq int } func NewUserService() UserService { return \u0026amp;userService{ users: make(map[int]*User), idSeq: 1, } } func (s *userService) Create(user *User) (*User, error) { s.lock.Lock() defer s.lock.Unlock() user.ID = s.idSeq s.idSeq++ s.users[user.ID] = user return user, nil } func (s *userService) Get(id int) (*User, error) { s.lock.RLock() defer s.lock.RUnlock() user, ok := s.users[id] if !ok { return nil, errors.New(\u0026#34;user not found\u0026#34;) } return user, nil } func (s *userService) Update(id int, updatedUser *User) (*User, error) { s.lock.Lock() defer s.lock.Unlock() user, ok := s.users[id] if !ok { return nil, errors.New(\u0026#34;user not found\u0026#34;) } user.Name = updatedUser.Name user.Email = updatedUser.Email return user, nil } func (s *userService) Delete(id int) error { s.lock.Lock() defer s.lock.Unlock() if _, ok := s.users[id]; !ok { return errors.New(\u0026#34;user not found\u0026#34;) } delete(s.users, id) return nil } func Module() fx.Option { var Module = fx.Provide(NewUserService) return Module } Giải thích\nModule() fx.Option: Hàm này sử dụng fx.Provide của Uberfx để cung cấp một thể hiện của userService như là một dịch vụ cho các phần khác của ứng dụng. Đây là cách để Uberfx quản lý và cung cấp dịch vụ thông qua DI. Cách Hoạt Động\nKhởi tạo: Khi ứng dụng khởi động, Module() sẽ được gọi để cung cấp userService qua Uberfx. Điều này cho phép các phần khác của ứng dụng có thể yêu cầu dịch vụ này mà không cần phải khởi tạo nó trực tiếp. Quản lý Người Dùng: Các phương thức trong userService cho phép tạo, lấy, cập nhật và xóa người dùng trong một bản đồ, với sự đồng bộ hóa cần thiết để xử lý nhiều yêu cầu đồng thời. Dependency Injection: Uberfx sẽ quản lý việc cung cấp và chia sẻ userService trong toàn bộ ứng dụng, giúp cải thiện cấu trúc mã và quản lý các phụ thuộc. Bước 2: Viết testcase với ginkgo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 package example_test import ( \u0026#34;context\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;unit-test-example/module/example\u0026#34; model \u0026#34;unit-test-example/module/example\u0026#34; service \u0026#34;unit-test-example/module/example\u0026#34; . \u0026#34;github.com/onsi/ginkgo/v2\u0026#34; . \u0026#34;github.com/onsi/gomega\u0026#34; \u0026#34;go.uber.org/fx\u0026#34; ) var _ = Describe(\u0026#34;UserService with Fx\u0026#34;, func() { var ( userService service.UserService ) BeforeEach(func() { // Create a new Fx application to initialize dependencies app := fx.New( example.Module(), // Register the UserService module fx.Populate(\u0026amp;userService), // Automatically inject UserService into the variable ) // Start the Fx application and ensure it starts without errors Expect(app.Start(context.Background())).To(Succeed()) }) AfterEach(func() { // Stop the Fx application after each test to release resources app := fx.New() Expect(app.Stop(context.TODO())).To(Succeed()) }) Describe(\u0026#34;UserService\u0026#34;, func() { It(\u0026#34;should not be nil\u0026#34;, func() { Expect(userService).NotTo(BeNil()) }) }) Describe(\u0026#34;Create User\u0026#34;, func() { It(\u0026#34;should create a new user successfully\u0026#34;, func() { // Define a new user user := \u0026amp;model.User{Name: \u0026#34;John Doe\u0026#34;, Email: \u0026#34;john@example.com\u0026#34;} // Call the Create method from UserService createdUser, err := userService.Create(user) // Verify that there are no errors Expect(err).To(BeNil()) // Verify that the created user has the expected values Expect(createdUser.ID).To(Equal(1)) Expect(createdUser.Name).To(Equal(\u0026#34;John Doe\u0026#34;)) Expect(createdUser.Email).To(Equal(\u0026#34;john@example.com\u0026#34;)) }) }) // Additional test cases for Get, Update, and Delete can be added similarly }) func TestService(t *testing.T) { RegisterFailHandler(Fail) RunSpecs(t, \u0026#34;UserService Suite\u0026#34;) } Giải thích\nfunc TestService(t *testing.T): Đây là hàm điểm vào (entry point) cho các bài kiểm tra trong Go. Khi bạn chạy lệnh go test, Go sẽ tìm các hàm có tên bắt đầu bằng Test và thực thi chúng. Hàm TestService là một hàm đặc biệt được sử dụng để khởi động Ginkgo và chạy các bài kiểm tra đã được định nghĩa bằng Ginkgo. RegisterFailHandler(Fail): Đăng ký một hàm xử lý lỗi. Trong trường hợp có lỗi trong các bài kiểm tra, hàm Fail của Ginkgo sẽ được gọi, dẫn đến việc báo cáo lỗi và dừng quá trình kiểm tra. RunSpecs(t, \u0026quot;UserService Suite\u0026quot;): Khởi động Ginkgo và thực hiện tất cả các bài kiểm tra đã được định nghĩa. Tham số đầu tiên là đối tượng testing.T để Ginkgo có thể tích hợp với hệ thống kiểm tra của Go. Tham số thứ hai là tên của suite kiểm tra, dùng để tổ chức và báo cáo các bài kiểm tra. fx.Populate(\u0026amp;userService) yêu cầu Uberfx cung cấp một instance của UserService và gán nó cho biến userService. Làm thế nào fx.Populate hoạt động: Khi ứng dụng Uberfx khởi động, nó tìm các dịch vụ hoặc phụ thuộc đã được đăng ký (trong ví dụ này là UserService thông qua example.Module()) và tự động cung cấp chúng cho các biến được chỉ định thông qua fx.Populate. Điều này giúp tách biệt việc khởi tạo các đối tượng khỏi logic của bài kiểm tra, làm cho mã nguồn trở nên sạch sẽ và dễ bảo trì hơn\nBước 3: Chạy test Chạy test bằng go test\n1 go run test -v Kết quả:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 === RUN TestService Running Suite: UserService Suite - /home/phongthien/Desktop/start-up/unit-test/module/example ============================================================================================= Random Seed: 1726234713 Will run 2 of 2 specs [Fx] PROVIDE fx.Lifecycle \u0026lt;= go.uber.org/fx.New.func1() [Fx] PROVIDE fx.Shutdowner \u0026lt;= go.uber.org/fx.(*App).shutdowner-fm() [Fx] PROVIDE fx.DotGraph \u0026lt;= go.uber.org/fx.(*App).dotGraph-fm() [Fx] PROVIDE example.UserService \u0026lt;= unit-test-example/module/example.NewUserService() [Fx] INVOKE reflect.makeFuncStub() [Fx] RUN provide: unit-test-example/module/example.NewUserService() [Fx] RUNNING [Fx] PROVIDE fx.Lifecycle \u0026lt;= go.uber.org/fx.New.func1() [Fx] PROVIDE fx.Shutdowner \u0026lt;= go.uber.org/fx.(*App).shutdowner-fm() [Fx] PROVIDE fx.DotGraph \u0026lt;= go.uber.org/fx.(*App).dotGraph-fm() •[Fx] PROVIDE fx.Lifecycle \u0026lt;= go.uber.org/fx.New.func1() [Fx] PROVIDE fx.Shutdowner \u0026lt;= go.uber.org/fx.(*App).shutdowner-fm() [Fx] PROVIDE fx.DotGraph \u0026lt;= go.uber.org/fx.(*App).dotGraph-fm() [Fx] PROVIDE example.UserService \u0026lt;= unit-test-example/module/example.NewUserService() [Fx] INVOKE reflect.makeFuncStub() [Fx] RUN provide: unit-test-example/module/example.NewUserService() [Fx] RUNNING [Fx] PROVIDE fx.Lifecycle \u0026lt;= go.uber.org/fx.New.func1() [Fx] PROVIDE fx.Shutdowner \u0026lt;= go.uber.org/fx.(*App).shutdowner-fm() [Fx] PROVIDE fx.DotGraph \u0026lt;= go.uber.org/fx.(*App).dotGraph-fm() • Ran 2 of 2 Specs in 0.003 seconds SUCCESS! -- 2 Passed | 0 Failed | 0 Pending | 0 Skipped --- PASS: TestService (0.00s) PASS ok unit-test-example/module/example 0.012s Kết Luận Bằng cách sử dụng Uberfx để quản lý phụ thuộc và Ginkgo để viết các bài kiểm tra, bạn có thể xây dựng một quy trình phát triển mã nguồn mạnh mẽ và dễ bảo trì hơn. Việc tổ chức mã nguồn và kiểm tra theo cách này giúp cải thiện chất lượng mã và dễ dàng phát hiện lỗi hơn trong các ứng dụng phức tạp.\nTài liệu tham khảo Uberfx Documentation Ginkgo Documentation ","date":"2024-09-13T21:17:00+08:00","permalink":"https://phongthien99.github.io/posts/guide-to-using-uberfx-and-ginkgo-for-building-unit-testing-workflow-in-go/","title":"Guide to Using Uberfx and Ginkgo for Building Unit Testing Workflow in Go"},{"content":"Building an Efficient Data Synchronization System: Combining Rclone and Temporal to Ensure High Availability and Avoid Data Duplication Đặt Vấn Đề Trong một hệ thống cần đảm bảo tính sẵn sàng cao (High Availability - HA), bạn có ba máy chủ hoạt động trong một cụm. Các máy chủ này cùng chia sẻ một volume lưu trữ dữ liệu chung. Yêu cầu của hệ thống là phải đồng bộ dữ liệu từ volume chia sẻ này lên nhiều hệ lưu trữ khác nhau như AWS S3, Google Cloud Storage (GCS), và FTP.\nTuy nhiên, việc đảm bảo đồng bộ dữ liệu lên các hệ lưu trữ này mà vẫn giữ được tính HA và tránh trùng lặp dữ liệu lại đặt ra một thách thức không nhỏ.\nTriển khai cron job trên một máy chủ duy nhất: Nếu bạn chọn một máy chủ duy nhất để thực hiện đồng bộ hóa bằng cách sử dụng cron job, hệ thống sẽ gặp rủi ro nếu máy chủ này gặp sự cố. Trong trường hợp đó, việc đồng bộ dữ liệu sẽ bị gián đoạn, dẫn đến khả năng mất mát dữ liệu. Triển khai cron job trên nhiều máy chủ: Để đảm bảo tính HA, nếu bạn triển khai cron job trên cả ba máy chủ, có khả năng cả ba máy chủ sẽ thực hiện đồng bộ cùng một lúc. Điều này dẫn đến việc dữ liệu bị đồng bộ nhiều lần lên các hệ lưu trữ khác nhau, gây ra sự trùng lặp dữ liệu. Hệ quả là lãng phí băng thông và làm phức tạp hóa việc quản lý dữ liệu trên các hệ lưu trữ. Như vậy, hệ thống cần một giải pháp có thể vừa đảm bảo đồng bộ dữ liệu lên các hệ lưu trữ một cách nhất quán, vừa tránh được việc dữ liệu bị trùng lặp, đồng thời vẫn giữ được tính sẵn sàng cao trong trường hợp có sự cố xảy ra\nGiải pháp Để giải quyết vấn đề đảm bảo tính sẵn sàng cao (HA) và tránh trùng lặp dữ liệu khi đồng bộ từ 3 máy chủ chia sẻ volume lên các hệ lưu trữ như AWS S3, Google Cloud Storage (GCS), và FTP, chúng ta có thể kết hợp Rclone với Temporal. Đây là giải pháp không chỉ tối ưu hóa quá trình đồng bộ mà còn giúp quản lý hiệu quả và tự động hóa quy trình..\n1. Rclone: Công Cụ Đồng Bộ Dữ Liệu Linh Hoạt Rclone là một công cụ mạnh mẽ để đồng bộ hóa dữ liệu giữa nhiều hệ lưu trữ đám mây và máy chủ cục bộ. Rclone hỗ trợ nhiều giao thức và dịch vụ lưu trữ khác nhau như AWS S3, Google Cloud Storage, FTP, và nhiều dịch vụ khác. Đặc biệt, nó hỗ trợ các tính năng như:\nĐồng bộ hóa dữ liệu từ volume chia sẻ lên nhiều hệ lưu trữ. Kiểm tra sự khác biệt của dữ liệu trước khi đồng bộ để tránh tải lên các dữ liệu không cần thiết. Hỗ trợ nén và mã hóa dữ liệu khi cần thiết. 2. Temporal: Hệ Thống Quản Lý Workflow Đảm Bảo HA Temporal là một hệ thống quản lý workflow giúp bạn điều phối các quy trình phức tạp trong môi trường phân tán. Với Temporal, bạn có thể đảm bảo rằng các tác vụ đồng bộ dữ liệu chỉ được thực hiện bởi một máy chủ tại một thời điểm nhất định, và khi máy chủ đó gặp sự cố, một máy chủ khác sẽ tự động tiếp quản quá trình đồng bộ. Temporal giúp giải quyết các vấn đề liên quan đến tính HA và tránh trùng lặp dữ liệu bằng cách:\nQuản lý trạng thái: Temporal giữ trạng thái của các workflow và đảm bảo chỉ có một instance của workflow đang chạy tại một thời điểm. Failover tự động: Nếu máy chủ đang thực hiện workflow gặp sự cố, Temporal sẽ tự động chuyển trách nhiệm sang một máy chủ khác. Thực hiện Bước 1: Thiết lập cơ sở dữ liệu SQL chung Cài đặt MySQL/PostgreSQL. Tạo bảng Temporal và cấu hình Temporal server kết nối đến cơ sở dữ liệu này. Bước 2: Cài đặt Temporal trên 3 server Tải Temporal server trên mỗi server. Cấu hình Temporal để kết nối đến cơ sở dữ liệu SQL chung. Bước 3: Cài đặt và cấu hình Worker Cài đặt rclone và worker Temporal trên mỗi server. Cấu hình worker để sử dụng rclone đồng bộ dữ liệu lên S3. Bước 4: Quản lý đồng bộ và HA Sử dụng Temporal workflow để quản lý tiến trình đồng bộ, chỉ cho phép một server đồng bộ tại một thời điểm. Đảm bảo tính HA, nếu một server gặp sự cố, các server khác tiếp quản tiến trình đồng bộ. Bước 5: Chạy và kiểm tra Chạy Temporal server và worker trên cả 3 server. Kiểm tra tính đồng bộ và HA của hệ thống. Kết Luận Trong việc đảm bảo tính sẵn sàng cao (HA) và tránh trùng lặp dữ liệu khi đồng bộ từ một volume chia sẻ lên nhiều hệ lưu trữ như AWS S3, Google Cloud Storage (GCS), và FTP, việc sử dụng Rclone kết hợp với Temporal mang lại giải pháp tối ưu và hiệu quả. Ngoài ra chúng ta có thể thử nghiệm trên 1 máy duy nhất bằng cách sử dựng temporal kết hợp với sqlite3.\n","date":"2024-09-07T00:40:00+08:00","permalink":"https://phongthien99.github.io/posts/combining-rclone-and-temporal-to-ensure-high-availability-and-avoid-data-duplication/","title":"Combining Rclone and Temporal to Ensure High Availability and Avoid Data Duplication\""},{"content":"Development environment with Docker and Traefik Đặt vấn đề Phát triển cục bộ với Docker đã trở nên phổ biến trong các quy trình phát triển phần mềm. Thông thường, bạn chỉ cần chạy một container và ánh xạ các cổng cần thiết là có thể bắt đầu công việc. Tuy nhiên, khi làm việc với nhiều dự án đồng thời, việc xung đột cổng giữa các dự án trên cùng một máy chủ Docker có thể gây ra khó khăn trong việc quản lý. Điều này không chỉ làm giảm hiệu quả làm việc mà còn gây phiền toái khi bạn phải nhớ chính xác dự án nào sử dụng cổng nào.\nGiải pháp Sử dụng một reverse proxy cục bộ để quản lý các dự án sẽ giúp bạn giải quyết vấn đề xung đột cổng. Traefik là một lựa chọn phù hợp để định tuyến và quản lý các dự án cục bộ thông qua việc ánh xạ miền và base path tương ứng.\nThực hiện Bước 1: Khởi tạo mạng lưới (network) Trước khi cài đặt Traefik, bạn cần tạo một mạng lưới Docker để đảm bảo các dịch vụ của bạn có thể giao tiếp với nhau. 1 2 bashCopy code docker network create traefik-ingress Bước 2: Cài đặt Traefik Chúng ta sẽ cài đặt Traefik thông qua Docker Compose. File docker-compose.yml dưới đây sẽ cài đặt Traefik và thiết lập các cổng cần thiết.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 yamlCopy code version: \u0026#39;3.7\u0026#39; services: traefik: image: \u0026#34;traefik:v3.1\u0026#34; container_name: \u0026#34;traefik\u0026#34; command: - \u0026#34;--log.level=DEBUG\u0026#34; - \u0026#34;--api.insecure=true\u0026#34; - \u0026#34;--providers.docker=true\u0026#34; - \u0026#34;--providers.docker.exposedbydefault=false\u0026#34; - \u0026#34;--entryPoints.web.address=:80\u0026#34; ports: - \u0026#34;8080:80\u0026#34; # Định tuyến web (HTTP) - \u0026#34;8443:80\u0026#34; # Định tuyến cho HTTPS - \u0026#34;18080:8080\u0026#34; # Dashboard của Traefik volumes: - \u0026#34;/var/run/docker.sock:/var/run/docker.sock:ro\u0026#34; networks: - traefik-ingress restart: unless-stopped networks: traefik-ingress: external: true Bước 3: Thiết lập một dự án mới Sau khi Traefik đã được cài đặt, bạn có thể bắt đầu thêm các dự án của mình và cấu hình để chúng hoạt động qua Traefik. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 yamlCopy code version: \u0026#39;3.8\u0026#39; services: mam.svc: build: context: . dockerfile: Dockerfile.dev labels: - \u0026#34;traefik.enable=true\u0026#34; - \u0026#34;traefik.http.routers.mam-api-svc.rule=PathPrefix(`/api/library`)\u0026#34; - \u0026#34;traefik.http.routers.mam-api-svc.service=mam-api-svc\u0026#34; - \u0026#34;traefik.http.services.mam-api-svc.loadbalancer.server.port=8080\u0026#34; - \u0026#34;traefik.http.routers.mam-grpc-svc.rule=Host(`mam.lh`)\u0026#34; - \u0026#34;traefik.http.routers.mam-grpc-svc.service=mam-grpc-svc\u0026#34; - \u0026#34;traefik.http.services.mam-grpc-svc.loadbalancer.server.port=50051\u0026#34; - \u0026#34;traefik.http.services.mam-grpc-svc.loadbalancer.server.scheme=h2c\u0026#34; environment: - NODE_ENV=development volumes: - .:/src command: [\u0026#34;pnpm\u0026#34;, \u0026#34;run\u0026#34;, \u0026#34;start:dev\u0026#34;] networks: - traefik-ingress networks: traefik-ingress: external: true Giải thích cấu hình: traefik.enable=true: Kích hoạt Traefik cho dịch vụ này. traefik.http.routers.mam-api-svc.rule=PathPrefix(/api/library): Định tuyến các yêu cầu HTTP có đường dẫn bắt đầu bằng /api/library tới dịch vụ mam-api-svc. traefik.http.routers.mam-api-svc.service=mam-api-svc: Đặt tên dịch vụ HTTP là mam-api-svc. traefik.http.services.mam-api-svc.loadbalancer.server.port=8080: Định tuyến lưu lượng HTTP tới cổng 8080 của dịch vụ này. traefik.http.routers.mam-grpc-svc.rule=Host(mam.lh): Định tuyến các yêu cầu GRPC tới dịch vụ mam-grpc-svc khi host là mam.lh. traefik.http.services.mam-grpc-svc.loadbalancer.server.port=50051: Định tuyến lưu lượng GRPC tới cổng 50051. traefik.http.services.mam-grpc-svc.loadbalancer.server.scheme=h2c: Sử dụng HTTP/2 không bảo mật (h2c) cho GRPC. Kết luận Triển khai Traefik làm reverse proxy cục bộ giúp bạn quản lý các dự án một cách dễ dàng và tránh xung đột cổng. Với khả năng định tuyến theo miền và base path, bạn có thể dễ dàng phân biệt các dịch vụ mà không cần nhớ cổng của từng ứng dụng. Hơn nữa, Traefik hỗ trợ HTTP/2 và GRPC, mang lại sự linh hoạt và mạnh mẽ cho môi trường phát triển cục bộ, từ đó tăng hiệu suất làm việc.\nTài liệu tham khảo Traefik Documentation Development Environment with Docker and Traefik ","date":"2024-08-30T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/development-environment-with-docker-and-traefik/","title":"Development environment with Docker and Traefik"},{"content":"Fast Connection Localhost to Kubernetes with Telepresence Vấn đề gặp phải Trong quá trình phát triển với kiến trúc microservice, việc tương tác với các dịch vụ khác là điều không thể tránh khỏi. Thay vì phải triển khai toàn bộ các microservice trên máy local, bạn có thể tận dụng các dịch vụ đã được triển khai trên cụm Kubernetes (K8s). Một giải pháp thường được sử dụng là kubectl port-forward để chuyển tiếp các cổng từ cluster về máy local. Tuy nhiên, phương pháp này có thể trở nên phức tạp và tốn thời gian khi số lượng microservice tăng lên, đòi hỏi việc mở nhiều cổng cho từng dịch vụ.\nGiải pháp Để giải quyết vấn đề phức tạp khi phải mở nhiều cổng bằng kubectl port-forward, chúng ta có thể sử dụng Telepresence. Công cụ này cung cấp một cách tiếp cận đơn giản và hiệu quả hơn, loại bỏ nhu cầu mở từng cổng cho từng dịch vụ microservice.\nTelepresence cho phép bạn chạy ứng dụng trên máy local và kết nối trực tiếp với cụm Kubernetes. Thay vì phải thủ công mở cổng cho từng dịch vụ, Telepresence thiết lập một kết nối mạng toàn diện giữa máy local và cluster Kubernetes. Điều này cho phép bạn truy cập mọi dịch vụ trong cluster như thể chúng đang chạy trên chính máy local của bạn.\nThực hiện 1. Cài đặt trên Ubuntu Trước khi cài đặt Telepresence, hãy đảm bảo rằng máy của bạn đã cài đặt kubectl.\n1 2 3 4 5 # 1. Download the latest binary (~50 MB): sudo curl -fL https://app.getambassador.io/download/tel2/linux/amd64/latest/telepresence -o /usr/local/bin/telepresence # 2. Make the binary executable: sudo chmod a+x /usr/local/bin/telepresence 2. Thiết lập kết nối với cụm Kubernetes Để kết nối máy local với cụm Kubernetes, bạn chỉ cần chạy lệnh sau:\n1 telepresence connect 3. Cài đặt Traffic Manager Traffic Manager là thành phần quan trọng giúp Telepresence quản lý lưu lượng giữa máy local và cụm Kubernetes. Bạn có thể cài đặt Traffic Manager bằng cách sử dụng Helm:\n1 telepresence helm install 4. Thử nghiệm Sau khi cài đặt và kết nối thành công, bạn có thể thử nghiệm kết nối với các dịch vụ trong cụm Kubernetes:\n1 telnet \u0026lt;\u0026lt;service-name\u0026gt;\u0026gt;.\u0026lt;\u0026lt;namespace\u0026gt;\u0026gt; \u0026lt;\u0026lt;port\u0026gt;\u0026gt; Ví dụ: Nếu bạn muốn kết nối tới dịch vụ my-service trong namespace default tại cổng 8080, bạn có thể chạy:\n1 telnet my-service.default 8080 Kết luận Telepresence là một công cụ mạnh mẽ giúp đơn giản hóa việc phát triển và thử nghiệm các ứng dụng trong kiến trúc microservice với Kubernetes. Bằng cách loại bỏ nhu cầu mở cổng cho từng dịch vụ, Telepresence cho phép bạn tập trung vào việc phát triển và kiểm thử ứng dụng mà không cần lo lắng về cấu hình phức tạp.\nVới Telepresence, việc kết nối với cụm Kubernetes trở nên dễ dàng và liền mạch, giúp bạn tiết kiệm thời gian và nâng cao hiệu suất làm việc.\nTài liệu tham khảo Telepresence Quick Start Guide ","date":"2024-08-24T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/fast-connection-localhost-to-kubernetes-with-telepresence/","title":"Fast Connection Localhost to Kubernetes with Telepresence"},{"content":"Setting Up Fake Wildcard Domain with Coredns on Ubuntu Đặt vấn đề Trong quá trình phát triển phần mềm, việc sử dụng nhiều tên miền giả dạng *.lh là khá phổ biến. Thông thường, để xử lý các tên miền này, chúng ta phải thủ công sửa file /etc/hosts mỗi khi cần tạo một tên miền mới. Điều này không chỉ gây mất thời gian mà đôi khi còn dẫn tới các lỗi không mong muốn nếu quên cập nhật file.\nGiải pháp CoreDNS cung cấp khả năng định tuyến DNS mạnh mẽ và có thể dễ dàng cấu hình để xử lý các wildcard domain.\nThực hiện Triển khai thông qua Docker-compose\nBước 1: Tạo file Docker Compose Tạo một thư mục cho cấu hình Docker Compose:\n1 2 3 mkdir coredns-wildcard cd coredns-wildcard Tạo một file docker-compose.yml với nội dung sau:\n1 2 3 4 5 6 7 8 9 10 11 12 version: \u0026#39;3\u0026#39; services: coredns: image: coredns/coredns:latest container_name: coredns command: \u0026#34;-conf /Corefile\u0026#34; ports: - \u0026#34;53:53/udp\u0026#34; volumes: - ./Corefile:/etc/coredns/Corefile restart: unless-stopped Bước 2: Cấu hình CoreDNS Tạo một file cấu hình tên là Corefile trong thư mục coredns-wildcard với nội dung sau:\n1 2 3 4 5 6 7 8 9 10 .:53 { template IN ANY lh { match \u0026#34;\\w*\\.(lh\\.)$\u0026#34; answer \u0026#34;{{ .Name }} 3600 IN A 127.0.0.1\u0026#34; fallthrough } forward . 8.8.8.8 log } Cấu hình này sẽ chuyển hướng tất cả các tên miền dạng *.lh tới địa chỉ 127.0.0.1 và sử dụng Google DNS cho các yêu cầu khác.\nBước 3: Chạy Docker Compose Trong thư mục coredns-wildcard, chạy lệnh sau để khởi động CoreDNS:\n1 2 docker-compose up -d Bước 4: Cấu hình DNS trên máy tính cá nhân Để sử dụng CoreDNS, chỉnh sửa file /etc/resolv.conf để sử dụng CoreDNS làm DNS cục bộ:\n1 2 sudo nano /etc/resolv.conf Thêm dòng sau vào đầu file:\n1 2 nameserver 127.0.0.1 Bước 6: Kiểm tra cấu hình Kiểm tra xem cấu hình đã hoạt động hay chưa bằng cách sử dụng lệnh nslookup:\n1 2 nslookup test.lt Nếu cấu hình đúng, bạn sẽ nhận được phản hồi với địa chỉ IP 127.0.0.1.\nKết luận Với các bước trên, việc thiết lập wildcard domain với CoreDNS trên Ubuntu thông qua Docker Compose trở nên đơn giản và hiệu quả. Đây là một giải pháp tốt để quản lý các tên miền giả phục vụ cho quá trình phát triển phần mềm một cách linh hoạt.\n","date":"2024-08-17T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/setting-up-fake-wildcard-domain-with-coredns-on-local-ubuntu/","title":"Setting Up Fake Wildcard Domain with Coredns on Local Ubuntu"},{"content":"Bypass login Portainer Vấn đề gặp phải Khi sử dụng Portainer phiên bản 2.19.4, hệ thống yêu cầu người dùng phải đăng nhập bằng tài khoản và mật khẩu. Mặc dù đây là một tính năng quan trọng nhằm tăng cường bảo mật, nhưng trong môi trường làm việc local, việc này có thể trở nên không cần thiết và gây ra sự phiền toái cho người dùng.\nGiải pháp Để đơn giản hóa việc truy cập vào Potainer trong môi trường local mà không cần phải đăng nhập, bạn có thể:\nĐặt một proxy server trước Portainer và sử dụng access token để truy cập Portainer API. Tạo một JWT token giả dài hạn để tránh việc token hết hạn quá sớm khi client kiểm tra. Thực hiện 1. Lấy Access Token Theo hướng dẫn của Portainer: Portainer API Access.\n2. Cấu hình Traefik làm Proxy Server Cấu hình Traefik để làm proxy server với file cấu hình YAML sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 http: serversTransports: portainer-transport: insecureSkipVerify: true routers: portainer-local-router: rule: \u0026#34;Host(`portainer.lh`)\u0026#34; # Thay thế bằng domain hoặc quy tắc routing của bạn service: portainer-local middlewares: - portainerApiKeyHeaders middlewares: portainerApiKeyHeaders: headers: customRequestHeaders: X-API-Key: \u0026lt;\u0026lt;access token\u0026gt;\u0026gt; # Thay thế bằng access token của bạn services: portainer-local: loadBalancer: servers: - url: \u0026lt;\u0026lt;address portainer\u0026gt;\u0026gt; # Thay thế bằng địa chỉ IP của Portainer serversTransport: portainer-transport Sau đó, ánh xạ domain giả portainer.lh về địa chỉ IP local.\n3. Tạo JWT Token dài hạn Ví dụ về một JWT token dài hạn:\n1 2 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsInNjb3BlIjoiZGVmYXVsdCIsImZvcmNlQ2hhbmdlUGFzc3dvcmQiOmZhbHNlLCJleHAiOjM4MDYxNTA3OTIsImlhdCI6MTcyMzM5MjA3N30.49qEbdGLK39PgplVPUwsiDud_vgP1wyP19lAYic19Gs Set key portainer.JWT và giá trị trên vào localStorage của trang portainer.lh:8089, trong đó:\n8089 là cổng HTTP entry của Traefik. Có thể sử dụng script sau để thiết lập token:\n1 2 3 4 5 6 7 8 9 10 // Define your JWT token const jwtToken = \u0026#39;\u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJhZG1pbiIsInJvbGUiOjEsInNjb3BlIjoiZGVmYXVsdCIsImZvcmNlQ2hhbmdlUGFzc3dvcmQiOmZhbHNlLCJleHAiOjM4MDYxNTA3OTIsImlhdCI6MTcyMzM5MjA3N30.49qEbdGLK39PgplVPUwsiDud_vgP1wyP19lAYic19Gs\u0026#34;\u0026#39;; // Store the token in localStorage localStorage.setItem(\u0026#39;portainer.JWT\u0026#39;, jwtToken); // Verify by retrieving it const storedToken = localStorage.getItem(\u0026#39;portainer.JWT\u0026#39;); console.log(storedToken); // Should output the JWT token Kết luận Việc cấu hình Traefik làm proxy server và sử dụng JWT token dài hạn giúp đơn giản hóa việc truy cập vào Portainer trong môi trường local mà không cần phải đăng nhập liên tục. Hãy đảm bảo rằng bạn đã cấu hình chính xác và kiểm tra token để đảm bảo sự hoạt động trơn tru.\nTài liệu Traefik Routing Documentation ","date":"2024-08-12T01:17:00+08:00","permalink":"https://phongthien99.github.io/posts/bypass-login-portainer/","title":"Bypass login Portainer"},{"content":"Building an HTTP Server for Multi-Platform Data Storage Introduction In the deployment of Video On Demand (VOD) services, transcoding and storing video require a flexible and efficient system. To address this issue, we can build an HTTP server to manage the writing and retrieving of data from FFmpeg to various storage platforms such as S3, FTP, OS, and HTTP.\nSolution We will design an HTTP server with two main endpoints:\nPUT /origin/{config}/{filepath} Receive data from FFmpeg and save it to the configured storage platform. config is encoded in base64, decoded to determine the storage platform, and then save the data accordingly (S3, FTP, OS, HTTP). The request can store data on multiple platforms simultaneously. GET /origin/{config}/{filepath} Retrieve data from the configured storage platforms based on config. Configure FFmpeg to use the HTTP server for testing:\n1 2 3 4 5 6 7 8 9 10 11 ffmpeg -i video.mp4 \\ -c:a aac \\ -c:v h264 \\ -f hls \\ -force_key_frames expr:gte(t,n_forced*2) \\ -hls_base_url /origin/BASE64_ENCODED_CONFIG/segments/ \\ -hls_playlist_type vod \\ -hls_segment_filename http://localhost:8086/origin/BASE64_ENCODED_CONFIG/segments/segment_%03d.ts \\ -hls_time 2 \\ -vf scale=1280:-1 \\ http://localhost:8086/origin/BASE64_ENCODED_CONFIG/manifest/master.m3u8 -y Conclusion Building an HTTP server with the structure /origin/:config/:filePath helps manage and retrieve data efficiently and simplifies the storage process in a VOD system. This approach minimizes the complexity in data transmission and configuration handling, meeting the needs of a modern VOD system effectively.\n","date":"2024-06-24T00:40:00+08:00","permalink":"https://phongthien99.github.io/posts/building-an-http-server-for-multi-platform-data-storage/","title":"Building an HTTP Server for Multi-Platform Data Storage"},{"content":"Builder pattern Intent Builder is a creational design pattern that lets you construct complex objects step by step. The pattern allows you to produce different types and representations of an object using the same construction code Problem When an object has too many properties or optional properties, creating a constructor with all the parameters or using multiple constructors can become complex and difficult to maintain.. Solution The Builder pattern suggests that you extract the object construction code out of its own class and move it to separate objects called builders.\nDirector: Responsible for building an object using Builder. Builder: Interface or abstract class defines the steps necessary to construct an object. ConcreteBuilder: Concretizes the Builder, implements specific steps to build the object and provides a method to retrieve the final object. Product: Represents the built object. Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 package main import \u0026#34;log\u0026#34; // Product type User struct { Name string Age int } // ConcreteBuilder type UserBuilder struct { Name string Age int } // Director type IDiretor[T any] interface { Builder() T } // Builder type IUserBuilder interface { SetName(name string) IUserBuilder SetAge(age int) IUserBuilder IDiretor[*User] } func (u *UserBuilder) SetName(name string) IUserBuilder { u.Name = name return u } func (u *UserBuilder) SetAge(age int) IUserBuilder { u.Age = age return u } func (u *UserBuilder) Builder() *User { return \u0026amp;User{ Name: u.Name, Age: u.Age, } } func NewUserBuilder() IUserBuilder { return \u0026amp;UserBuilder{} } func main() { user := NewUserBuilder().SetName(\u0026#34;test\u0026#34;).SetAge(12).Builder() log.Print(user) } Pros and Cons ✅ You can construct objects step-by-step, defer construction steps or run steps recursively.\n✅ You can reuse the same construction code when building various representations of products.\n✅ Single Responsibility Principle. You can isolate complex construction code from the business logic of the product.\n❌ The overall complexity of the code increases since the pattern requires creating multiple new classes.\nConclusion Although the Option Pattern offers many benefits in terms of flexibility and readability, it also requires careful consideration when used, especially for cases with a large number of options.\n","date":"2024-05-04T00:40:00+08:00","permalink":"https://phongthien99.github.io/posts/builder-pattern/","title":"Builder Pattern"},{"content":"Options Pattern Intent helps solve the problem when a function or constructor has too many parameters, making calling the function or constructor complicated and confusing. instead of passing a series of parameters, we create an object containing optional parameters (options object), from which we can set the values for those parameters dynamically. Problem calling a function or constructor with too many parameters can result in code that is difficult to read, verbose, and confusing. additionally, when we need to change parameters, we must modify each function or constructor call. Solution Step 1: create an object containing options parameters (options object). Step 2: define methods in the options object to set the values for those parameters Step 3: When calling a function or constructor, instead of passing a series of parameters, we pass in the options object that was previously set. Step 4: In the function or constructor, we use the value set in the options object to perform the necessary tasks. Step 5: When calling a function or constructor, instead of passing a series of parameters, we pass in the options object that was previously set. Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main // step 1 create an object containing options parameters (options object). type Config struct { URL string DocExpansion string } // Step 2: define methods in the options object to set the values for those parameters func URL(url string) func(*Config) { return func(c *Config) { c.URL = url } } func DocExpansion(docExpansion string) func(*Config) { return func(c *Config) { c.DocExpansion = docExpansion } } // Step 3: When calling a function or constructor, instead of passing a series of parameters, we pass in the options object that was previously set. func newConfig(configFns ...func(*Config)) *Config { config := Config{ } // Step 4: In the function or constructor, we use the value set in the options object to perform the necessary tasks. for _, fn := range configFns { fn(\u0026amp;config) } return \u0026amp;config } // Step 5: When calling a function or constructor, instead of passing a series of parameters, we pass in the options object that was previously set. func main() { r := newConfig(URL(\u0026#34;http://test.com\u0026#34;),DocExpansion(\u0026#34;test\u0026#34;)) } Pros and Cons Pros Cons Flexible and extensible: Option Pattern allows adding or changing optional parameters without changing the structure of the function or constructor. This makes the code more extensible and flexible. Complexity with large number of options: When there are too many options, managing and using the Option Pattern can become complicated. This can lead to defining too many constructors and optional setters, making the code complex and confusing. Ease of reading and maintenance: When using the Option Pattern, function or constructor calls become more concise and easier to read. Instead of having a bunch of parameters, we just need to pass an options object, making the code easy to maintain. Unclear with required options: If there are parameters that are optional but necessary for use, using the Option Pattern can make the code unclear. In this case, using the Option Pattern may not be appropriate and one should consider other methods such as using default parameters or structured data types. Minimize errors: Option Pattern helps reduce the number of errors caused by confusion about the order or data type of parameters. Instead of having to remember the order or data type of each parameter, we just need to set the values for the fields in the options object. Conclusion Although the Option Pattern offers many benefits in terms of flexibility and readability, it also requires careful consideration when used, especially for cases with a large number of options.\n","date":"2024-05-03T00:40:00+08:00","permalink":"https://phongthien99.github.io/posts/options-pattern/","title":"Options Pattern"},{"content":"AWS DEA 1. Data Engineering Fundamentals Structured Data\nDefinition Data that is organized in a defined manner or schema, typically found in relational databases Unstructured Data\napiVersion: Phiên bản API.\nkind: Loại tài nguyên (Pod).\nmetadata: Thông tin (tên, nhãn).\nspec:\nContainers Ports Volumes Kiểu Pod\nSingle-container Pod: Chạy 1 container chính. Multi-container Pod: Mô hình: Sidecar, Ambassador, Adapter, init container Chia sẻ IP, Volume. 🚀 Vòng đời Pod Pending: Đang chờ tài nguyên. Running: Container đang hoạt động. Succeeded: Hoàn tất thành công. Failed: Container gặp lỗi. CrashLoopBackOff: Liên tục khởi động lại do lỗi. 🔍 Quản lý với kubectl Tạo Pod: kubectl apply -f pod.yaml Xem Pod: kubectl get pods Chi tiết Pod: kubectl describe pod \u0026lt;name\u0026gt; Xem log: kubectl logs \u0026lt;pod\u0026gt; -c \u0026lt;container\u0026gt; Truy cập Pod: kubectl exec -it \u0026lt;pod\u0026gt; -- /bin/bash 🗂️ Pod và Tính Hồi Phục Pod KHÔNG tự hồi phục khi lỗi. Sử dụng Controller để quản lý: Deployment (Stateless) StatefulSet (Stateful) DaemonSet (Chạy trên mọi node) ⚡ Ưu - Nhược điểm ✅ Đơn giản, dễ triển khai. ✅ Hiệu quả khi chia sẻ tài nguyên. ❌ Không tự phục hồi khi lỗi. ❌ Không tối ưu cho ứng dụng lớn. ReplicaSet: Đảm bảo số Pod mong muốn.\nDeployment: Quản lý ReplicaSet, hỗ trợ rolling updates.\nStatefulSet: Quản lý ứng dụng có trạng thái.\nDaemonSet: Chạy Pod trên tất cả các node.\nJob: Thực thi tác vụ một lần rồi dừng.\nCronJob: Chạy tác vụ định kỳ.\n2. Networking Resources Service: Expose Pod (ClusterIP, NodePort, LoadBalancer). Ingress: Quản lý HTTP/HTTPS traffic. NetworkPolicy: Kiểm soát lưu lượng mạng giữa các Pod. 3. Storage Resources PersistentVolume (PV): Định nghĩa lưu trữ vật lý. PersistentVolumeClaim (PVC): Yêu cầu sử dụng PV. StorageClass: Dynamic provisioning cho lưu trữ. Volume: Gắn vào Pod để chia sẻ dữ liệu. 4. Configuration \u0026amp; Secret Management ConfigMap: Lưu cấu hình dạng key-value. Secret: Lưu dữ liệu nhạy cảm (token, mật khẩu). ResourceQuota: Giới hạn tài nguyên theo namespace. LimitRange: Đặt giới hạn CPU, RAM cho Pod. 5. Cluster Resources Namespace: Phân chia tài nguyên logic. Node: Máy chủ vật lý/ảo trong cluster. Role/RoleBinding: Quản lý quyền trong namespace. ClusterRole/ClusterRoleBinding: Quản lý quyền toàn cụm. ServiceAccount: Cấp quyền cho Pod truy cập API. 6. Custom Resources CustomResourceDefinition (CRD): Định nghĩa tài nguyên tùy chỉnh. Operator: Tự động hóa quản lý ứng dụng phức tạp. ","date":"0001-01-01T00:00:00Z","permalink":"https://phongthien99.github.io/posts/","title":""},{"content":"Kubernetes Resources 1. Workload Resources Pod Định nghĩa\nĐơn vị nhỏ nhất trong Kubernetes. Chứa một hoặc nhiều container. Chia sẻ: Network, Storage, Namespace. Cấu trúc Pod\napiVersion: Phiên bản API. kind: Loại tài nguyên (Pod). metadata: Thông tin (tên, nhãn). spec: Containers Ports Volumes Kiểu Pod\nSingle-container Pod: Chạy 1 container chính. Multi-container Pod: Mô hình: Sidecar, Ambassador, Adapter, init container Chia sẻ IP, Volume. 🚀 Vòng đời Pod Pending: Đang chờ tài nguyên. Running: Container đang hoạt động. Succeeded: Hoàn tất thành công. Failed: Container gặp lỗi. CrashLoopBackOff: Liên tục khởi động lại do lỗi. 🔍 Quản lý với kubectl Tạo Pod: kubectl apply -f pod.yaml Xem Pod: kubectl get pods Chi tiết Pod: kubectl describe pod \u0026lt;name\u0026gt; Xem log: kubectl logs \u0026lt;pod\u0026gt; -c \u0026lt;container\u0026gt; Truy cập Pod: kubectl exec -it \u0026lt;pod\u0026gt; -- /bin/bash 🗂️ Pod và Tính Hồi Phục Pod KHÔNG tự hồi phục khi lỗi. Sử dụng Controller để quản lý: Deployment (Stateless) StatefulSet (Stateful) DaemonSet (Chạy trên mọi node) ⚡ Ưu - Nhược điểm ✅ Đơn giản, dễ triển khai. ✅ Hiệu quả khi chia sẻ tài nguyên. ❌ Không tự phục hồi khi lỗi. ❌ Không tối ưu cho ứng dụng lớn. ReplicaSet: Đảm bảo số Pod mong muốn. Deployment: Quản lý ReplicaSet, hỗ trợ rolling updates. StatefulSet: Quản lý ứng dụng có trạng thái. DaemonSet: Chạy Pod trên tất cả các node. Job: Thực thi tác vụ một lần rồi dừng. CronJob: Chạy tác vụ định kỳ. 2. Networking Resources Service: Expose Pod (ClusterIP, NodePort, LoadBalancer). Ingress: Quản lý HTTP/HTTPS traffic. NetworkPolicy: Kiểm soát lưu lượng mạng giữa các Pod. 3. Storage Resources PersistentVolume (PV): Định nghĩa lưu trữ vật lý. PersistentVolumeClaim (PVC): Yêu cầu sử dụng PV. StorageClass: Dynamic provisioning cho lưu trữ. Volume: Gắn vào Pod để chia sẻ dữ liệu. 4. Configuration \u0026amp; Secret Management ConfigMap: Lưu cấu hình dạng key-value. Secret: Lưu dữ liệu nhạy cảm (token, mật khẩu). ResourceQuota: Giới hạn tài nguyên theo namespace. LimitRange: Đặt giới hạn CPU, RAM cho Pod. 5. Cluster Resources Namespace: Phân chia tài nguyên logic. Node: Máy chủ vật lý/ảo trong cluster. Role/RoleBinding: Quản lý quyền trong namespace. ClusterRole/ClusterRoleBinding: Quản lý quyền toàn cụm. ServiceAccount: Cấp quyền cho Pod truy cập API. 6. Custom Resources CustomResourceDefinition (CRD): Định nghĩa tài nguyên tùy chỉnh. Operator: Tự động hóa quản lý ứng dụng phức tạp. ","date":"0001-01-01T00:00:00Z","permalink":"https://phongthien99.github.io/posts/","title":""}]